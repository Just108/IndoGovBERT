{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 05:58:05.301709: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-24 05:58:07.104709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, pipeline, AutoTokenizer, AutoModel\n",
    "from transformers import BertConfig, AutoConfig\n",
    "from datasets import load_dataset, load_from_disk, DatasetDict, Dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "import math\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForMaskedLM, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7f1a76bd5cd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_finetune(data,tokenizer_file, batch_size, model_checkpoint, model_name):\n",
    "\n",
    "    def group_texts_ds(examples):\n",
    "        # Concatenate all texts.\n",
    "        block_size = 512\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "            # customize this part to your needs.\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "        # Split by chunks of max_len.\n",
    "        result = {\n",
    "            k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "        return result\n",
    "    \n",
    "    #suffix\n",
    "    \n",
    "    dataset = load_dataset(path=\"/media/agus/DATA/DDALM/output/suffix_array/\",\n",
    "                        data_files = data) #load_dataset(path=data_dir)\n",
    "    dataset = dataset['train']\n",
    "    dataset = dataset.train_test_split(test_size=0.2)\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "    #BertTokenizerFast.from_pretrained(tokenizer_file)\n",
    "    \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    "    )\n",
    "    \n",
    "    print('original',dataset)\n",
    "    \n",
    "    num_proc = multiprocessing.cpu_count()\n",
    "    print(f\"The max length for the tokenizer is: {tokenizer.model_max_length}\")\n",
    "\n",
    "    def group_texts(examples):\n",
    "        tokenized_inputs = tokenizer(\n",
    "            examples[\"text\"], return_special_tokens_mask=True, truncation=False, max_length=tokenizer.model_max_length\n",
    "        )\n",
    "        return tokenized_inputs\n",
    "\n",
    "    # preprocess dataset\n",
    "    tokenized_datasets = dataset.map(group_texts, batched=True, remove_columns=[\"text\"], num_proc=num_proc)\n",
    "    \n",
    "     #Grouping\n",
    "    lm_datasets = tokenized_datasets.map(\n",
    "        group_texts_ds,\n",
    "        batched=True,\n",
    "        batch_size=1000,\n",
    "        num_proc=28,\n",
    "    )\n",
    "    print('lm_dataset',lm_datasets)\n",
    "\n",
    "    #Set Model and Training Args\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "    \n",
    "    #model_name = model_checkpoint.split(\"/\")[-1]\n",
    "    #data_name = data.split(\".\")[-1]\n",
    "    #model_name = f'{model_name}finetuned-all-{data_name}'\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'models/{model_name}',\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=25,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        #warmup_steps=2000,\n",
    "        #max_steps=100000,\n",
    "        warmup_ratio=0.1,\n",
    "        weight_decay=0.1,\n",
    "        max_grad_norm=10,\n",
    "        #lr_scheduler_type=\"cosine\",\n",
    "        learning_rate=2e-5,\n",
    "        save_steps=1000,\n",
    "        save_total_limit=2,\n",
    "        seed=42,\n",
    "        fp16=True,\n",
    "        prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=lm_datasets[\"train\"],\n",
    "        eval_dataset=lm_datasets[\"test\"],\n",
    "        #prediction_loss_only=True,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "     #Evaluate\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")\n",
    "    \n",
    "    #Save\n",
    "    trainer.save_model(f\"models/{model_name}\")\n",
    "    tokenizer.save_pretrained(f\"models/{model_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/suffix_array to /home/agus/.cache/huggingface/datasets/text/suffix_array-2d9aa0cc05fe1eab/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3fd93c13c54239871f44dd90d2c004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fef60d274042f79506ecf82102617e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047177ca898d445a8d3634a0ba28f100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /home/agus/.cache/huggingface/datasets/text/suffix_array-2d9aa0cc05fe1eab/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0af02adb26747d4891ec7c31b898a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 65533\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 16384\n",
      "    })\n",
      "})\n",
      "The max length for the tokenizer is: 1000000000000000019884624838656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13dedaf81bce4a718fe942c0c3d3d76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/65533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d810a93ec8f4ba2b0032fbee41868c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/16384 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd49f70ba13f4eabb9baa484d02c3b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/65533 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56718a8231094dfb907890d5fd22a76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/16384 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_dataset DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 577431\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 149883\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb7f705d47a4023a468dffc4cdced0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/802000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.6509, 'learning_rate': 1.2468827930174566e-07, 'epoch': 0.02}\n",
      "{'loss': 6.2946, 'learning_rate': 2.493765586034913e-07, 'epoch': 0.03}\n",
      "{'loss': 6.1042, 'learning_rate': 3.7406483790523695e-07, 'epoch': 0.05}\n",
      "{'loss': 6.0205, 'learning_rate': 4.987531172069826e-07, 'epoch': 0.06}\n",
      "{'loss': 5.9544, 'learning_rate': 6.234413965087283e-07, 'epoch': 0.08}\n",
      "{'loss': 5.8965, 'learning_rate': 7.481296758104739e-07, 'epoch': 0.09}\n",
      "{'loss': 5.8865, 'learning_rate': 8.728179551122195e-07, 'epoch': 0.11}\n",
      "{'loss': 5.8511, 'learning_rate': 9.975062344139653e-07, 'epoch': 0.12}\n",
      "{'loss': 5.8159, 'learning_rate': 1.1219451371571074e-06, 'epoch': 0.14}\n",
      "{'loss': 5.7906, 'learning_rate': 1.246633416458853e-06, 'epoch': 0.16}\n",
      "{'loss': 5.7563, 'learning_rate': 1.3713216957605985e-06, 'epoch': 0.17}\n",
      "{'loss': 5.7553, 'learning_rate': 1.4960099750623442e-06, 'epoch': 0.19}\n",
      "{'loss': 5.6998, 'learning_rate': 1.6206982543640897e-06, 'epoch': 0.2}\n",
      "{'loss': 5.7052, 'learning_rate': 1.745137157107232e-06, 'epoch': 0.22}\n",
      "{'loss': 5.6925, 'learning_rate': 1.8698254364089776e-06, 'epoch': 0.23}\n",
      "{'loss': 5.6793, 'learning_rate': 1.9945137157107233e-06, 'epoch': 0.25}\n",
      "{'loss': 5.6799, 'learning_rate': 2.119201995012469e-06, 'epoch': 0.26}\n",
      "{'loss': 5.6592, 'learning_rate': 2.2436408977556114e-06, 'epoch': 0.28}\n",
      "{'loss': 5.64, 'learning_rate': 2.368329177057357e-06, 'epoch': 0.3}\n",
      "{'loss': 5.6183, 'learning_rate': 2.4930174563591025e-06, 'epoch': 0.31}\n",
      "{'loss': 5.6363, 'learning_rate': 2.617705735660848e-06, 'epoch': 0.33}\n",
      "{'loss': 5.6015, 'learning_rate': 2.742394014962594e-06, 'epoch': 0.34}\n",
      "{'loss': 5.597, 'learning_rate': 2.8668329177057357e-06, 'epoch': 0.36}\n",
      "{'loss': 5.5773, 'learning_rate': 2.9915211970074816e-06, 'epoch': 0.37}\n",
      "{'loss': 5.5346, 'learning_rate': 3.116209476309227e-06, 'epoch': 0.39}\n",
      "{'loss': 5.5055, 'learning_rate': 3.2408977556109727e-06, 'epoch': 0.41}\n",
      "{'loss': 5.4776, 'learning_rate': 3.365586034912718e-06, 'epoch': 0.42}\n",
      "{'loss': 5.4588, 'learning_rate': 3.490274314214464e-06, 'epoch': 0.44}\n",
      "{'loss': 5.4548, 'learning_rate': 3.6149625935162097e-06, 'epoch': 0.45}\n",
      "{'loss': 5.4238, 'learning_rate': 3.739401496259352e-06, 'epoch': 0.47}\n",
      "{'loss': 5.4059, 'learning_rate': 3.864089775561097e-06, 'epoch': 0.48}\n",
      "{'loss': 5.3608, 'learning_rate': 3.988778054862843e-06, 'epoch': 0.5}\n",
      "{'loss': 5.3034, 'learning_rate': 4.113466334164588e-06, 'epoch': 0.51}\n",
      "{'loss': 5.2433, 'learning_rate': 4.238154613466334e-06, 'epoch': 0.53}\n",
      "{'loss': 5.1864, 'learning_rate': 4.3625935162094765e-06, 'epoch': 0.55}\n",
      "{'loss': 5.1213, 'learning_rate': 4.487281795511223e-06, 'epoch': 0.56}\n",
      "{'loss': 5.0227, 'learning_rate': 4.611970074812968e-06, 'epoch': 0.58}\n",
      "{'loss': 4.9453, 'learning_rate': 4.736658354114714e-06, 'epoch': 0.59}\n",
      "{'loss': 4.8653, 'learning_rate': 4.8613466334164594e-06, 'epoch': 0.61}\n",
      "{'loss': 4.7804, 'learning_rate': 4.986034912718205e-06, 'epoch': 0.62}\n",
      "{'loss': 4.6954, 'learning_rate': 5.1107231920199505e-06, 'epoch': 0.64}\n",
      "{'loss': 4.6085, 'learning_rate': 5.235411471321696e-06, 'epoch': 0.65}\n",
      "{'loss': 4.5128, 'learning_rate': 5.3598503740648386e-06, 'epoch': 0.67}\n",
      "{'loss': 4.4247, 'learning_rate': 5.484538653366585e-06, 'epoch': 0.69}\n",
      "{'loss': 4.3602, 'learning_rate': 5.6092269326683305e-06, 'epoch': 0.7}\n",
      "{'loss': 4.2635, 'learning_rate': 5.733665835411471e-06, 'epoch': 0.72}\n",
      "{'loss': 4.1795, 'learning_rate': 5.858354114713217e-06, 'epoch': 0.73}\n",
      "{'loss': 4.1006, 'learning_rate': 5.983042394014963e-06, 'epoch': 0.75}\n",
      "{'loss': 4.0356, 'learning_rate': 6.107730673316709e-06, 'epoch': 0.76}\n",
      "{'loss': 3.9463, 'learning_rate': 6.232418952618454e-06, 'epoch': 0.78}\n",
      "{'loss': 3.9042, 'learning_rate': 6.356857855361597e-06, 'epoch': 0.79}\n",
      "{'loss': 3.8171, 'learning_rate': 6.481546134663342e-06, 'epoch': 0.81}\n",
      "{'loss': 3.7549, 'learning_rate': 6.606234413965088e-06, 'epoch': 0.83}\n",
      "{'loss': 3.7177, 'learning_rate': 6.7309226932668334e-06, 'epoch': 0.84}\n",
      "{'loss': 3.6453, 'learning_rate': 6.855610972568579e-06, 'epoch': 0.86}\n",
      "{'loss': 3.5932, 'learning_rate': 6.980299251870325e-06, 'epoch': 0.87}\n",
      "{'loss': 3.5596, 'learning_rate': 7.104987531172071e-06, 'epoch': 0.89}\n",
      "{'loss': 3.5207, 'learning_rate': 7.229426433915212e-06, 'epoch': 0.9}\n",
      "{'loss': 3.4997, 'learning_rate': 7.354114713216958e-06, 'epoch': 0.92}\n",
      "{'loss': 3.4789, 'learning_rate': 7.478802992518704e-06, 'epoch': 0.94}\n",
      "{'loss': 3.4674, 'learning_rate': 7.603491271820449e-06, 'epoch': 0.95}\n",
      "{'loss': 3.4347, 'learning_rate': 7.728179551122195e-06, 'epoch': 0.97}\n",
      "{'loss': 3.3896, 'learning_rate': 7.852618453865336e-06, 'epoch': 0.98}\n",
      "{'loss': 3.3979, 'learning_rate': 7.977306733167083e-06, 'epoch': 1.0}\n",
      "{'loss': 3.3648, 'learning_rate': 8.101995012468829e-06, 'epoch': 1.01}\n",
      "{'loss': 3.3705, 'learning_rate': 8.226683291770574e-06, 'epoch': 1.03}\n",
      "{'loss': 3.338, 'learning_rate': 8.35137157107232e-06, 'epoch': 1.04}\n",
      "{'loss': 3.3222, 'learning_rate': 8.476059850374065e-06, 'epoch': 1.06}\n",
      "{'loss': 3.3093, 'learning_rate': 8.600498753117208e-06, 'epoch': 1.08}\n",
      "{'loss': 3.3099, 'learning_rate': 8.725187032418953e-06, 'epoch': 1.09}\n",
      "{'loss': 3.2794, 'learning_rate': 8.8498753117207e-06, 'epoch': 1.11}\n",
      "{'loss': 3.2767, 'learning_rate': 8.974563591022446e-06, 'epoch': 1.12}\n",
      "{'loss': 3.2815, 'learning_rate': 9.099002493765586e-06, 'epoch': 1.14}\n",
      "{'loss': 3.2455, 'learning_rate': 9.223690773067332e-06, 'epoch': 1.15}\n",
      "{'loss': 3.2473, 'learning_rate': 9.348379052369077e-06, 'epoch': 1.17}\n",
      "{'loss': 3.2152, 'learning_rate': 9.473067331670823e-06, 'epoch': 1.18}\n",
      "{'loss': 3.2199, 'learning_rate': 9.597506234413967e-06, 'epoch': 1.2}\n",
      "{'loss': 3.219, 'learning_rate': 9.722194513715711e-06, 'epoch': 1.22}\n",
      "{'loss': 3.1865, 'learning_rate': 9.846882793017458e-06, 'epoch': 1.23}\n",
      "{'loss': 3.1766, 'learning_rate': 9.971571072319202e-06, 'epoch': 1.25}\n",
      "{'loss': 3.1624, 'learning_rate': 1.0096259351620949e-05, 'epoch': 1.26}\n",
      "{'loss': 3.178, 'learning_rate': 1.0220947630922695e-05, 'epoch': 1.28}\n",
      "{'loss': 3.1608, 'learning_rate': 1.0345635910224441e-05, 'epoch': 1.29}\n",
      "{'loss': 3.1495, 'learning_rate': 1.0470074812967581e-05, 'epoch': 1.31}\n",
      "{'loss': 3.1423, 'learning_rate': 1.0594763092269326e-05, 'epoch': 1.32}\n",
      "{'loss': 3.1336, 'learning_rate': 1.0719451371571072e-05, 'epoch': 1.34}\n",
      "{'loss': 3.1086, 'learning_rate': 1.0844139650872819e-05, 'epoch': 1.36}\n",
      "{'loss': 3.1093, 'learning_rate': 1.0968827930174564e-05, 'epoch': 1.37}\n",
      "{'loss': 3.0974, 'learning_rate': 1.1093266832917707e-05, 'epoch': 1.39}\n",
      "{'loss': 3.0977, 'learning_rate': 1.1217955112219452e-05, 'epoch': 1.4}\n",
      "{'loss': 3.0851, 'learning_rate': 1.1342643391521198e-05, 'epoch': 1.42}\n",
      "{'loss': 3.0642, 'learning_rate': 1.1467331670822943e-05, 'epoch': 1.43}\n",
      "{'loss': 3.0628, 'learning_rate': 1.1592019950124689e-05, 'epoch': 1.45}\n",
      "{'loss': 3.0133, 'learning_rate': 1.1716708229426434e-05, 'epoch': 1.47}\n",
      "{'loss': 3.0277, 'learning_rate': 1.1841147132169577e-05, 'epoch': 1.48}\n",
      "{'loss': 3.0254, 'learning_rate': 1.1965835411471322e-05, 'epoch': 1.5}\n",
      "{'loss': 3.0325, 'learning_rate': 1.2090523690773068e-05, 'epoch': 1.51}\n",
      "{'loss': 3.0288, 'learning_rate': 1.2215211970074815e-05, 'epoch': 1.53}\n",
      "{'loss': 2.9892, 'learning_rate': 1.2339650872817956e-05, 'epoch': 1.54}\n",
      "{'loss': 3.0051, 'learning_rate': 1.2464339152119703e-05, 'epoch': 1.56}\n",
      "{'loss': 2.9752, 'learning_rate': 1.2589027431421447e-05, 'epoch': 1.57}\n",
      "{'loss': 2.9846, 'learning_rate': 1.2713715710723194e-05, 'epoch': 1.59}\n",
      "{'loss': 2.9828, 'learning_rate': 1.2838403990024938e-05, 'epoch': 1.61}\n",
      "{'loss': 2.9647, 'learning_rate': 1.2962842892768082e-05, 'epoch': 1.62}\n",
      "{'loss': 2.9495, 'learning_rate': 1.3087531172069826e-05, 'epoch': 1.64}\n",
      "{'loss': 2.9525, 'learning_rate': 1.3212219451371573e-05, 'epoch': 1.65}\n",
      "{'loss': 2.9483, 'learning_rate': 1.333690773067332e-05, 'epoch': 1.67}\n",
      "{'loss': 2.9386, 'learning_rate': 1.3461596009975064e-05, 'epoch': 1.68}\n",
      "{'loss': 2.9342, 'learning_rate': 1.358628428927681e-05, 'epoch': 1.7}\n",
      "{'loss': 2.927, 'learning_rate': 1.371072319201995e-05, 'epoch': 1.71}\n",
      "{'loss': 2.9225, 'learning_rate': 1.3835411471321695e-05, 'epoch': 1.73}\n",
      "{'loss': 2.9227, 'learning_rate': 1.3960099750623441e-05, 'epoch': 1.75}\n",
      "{'loss': 2.9251, 'learning_rate': 1.4084788029925188e-05, 'epoch': 1.76}\n",
      "{'loss': 2.9036, 'learning_rate': 1.4209476309226932e-05, 'epoch': 1.78}\n",
      "{'loss': 2.9218, 'learning_rate': 1.4334164588528679e-05, 'epoch': 1.79}\n",
      "{'loss': 2.9117, 'learning_rate': 1.4458852867830423e-05, 'epoch': 1.81}\n",
      "{'loss': 2.8853, 'learning_rate': 1.458354114713217e-05, 'epoch': 1.82}\n",
      "{'loss': 2.9175, 'learning_rate': 1.4707980049875312e-05, 'epoch': 1.84}\n",
      "{'loss': 2.8785, 'learning_rate': 1.4832418952618455e-05, 'epoch': 1.85}\n",
      "{'loss': 2.8638, 'learning_rate': 1.49571072319202e-05, 'epoch': 1.87}\n",
      "{'loss': 2.874, 'learning_rate': 1.5081795511221946e-05, 'epoch': 1.89}\n",
      "{'loss': 2.8601, 'learning_rate': 1.5206483790523692e-05, 'epoch': 1.9}\n",
      "{'loss': 2.8652, 'learning_rate': 1.533117206982544e-05, 'epoch': 1.92}\n",
      "{'loss': 2.8614, 'learning_rate': 1.545561097256858e-05, 'epoch': 1.93}\n",
      "{'loss': 2.865, 'learning_rate': 1.5580299251870327e-05, 'epoch': 1.95}\n",
      "{'loss': 2.8684, 'learning_rate': 1.570498753117207e-05, 'epoch': 1.96}\n",
      "{'loss': 2.8383, 'learning_rate': 1.5829675810473816e-05, 'epoch': 1.98}\n",
      "{'loss': 2.8501, 'learning_rate': 1.595436408977556e-05, 'epoch': 2.0}\n",
      "{'loss': 2.8276, 'learning_rate': 1.607905236907731e-05, 'epoch': 2.01}\n",
      "{'loss': 2.832, 'learning_rate': 1.6203491271820452e-05, 'epoch': 2.03}\n",
      "{'loss': 2.816, 'learning_rate': 1.6328179551122197e-05, 'epoch': 2.04}\n",
      "{'loss': 2.8195, 'learning_rate': 1.6452867830423942e-05, 'epoch': 2.06}\n",
      "{'loss': 2.8146, 'learning_rate': 1.6577556109725686e-05, 'epoch': 2.07}\n",
      "{'loss': 2.8354, 'learning_rate': 1.6702244389027434e-05, 'epoch': 2.09}\n",
      "{'loss': 2.8203, 'learning_rate': 1.682693266832918e-05, 'epoch': 2.1}\n",
      "{'loss': 2.8115, 'learning_rate': 1.6951620947630924e-05, 'epoch': 2.12}\n",
      "{'loss': 2.8041, 'learning_rate': 1.7076309226932672e-05, 'epoch': 2.14}\n",
      "{'loss': 2.8156, 'learning_rate': 1.7200748129675812e-05, 'epoch': 2.15}\n",
      "{'loss': 2.8013, 'learning_rate': 1.732543640897756e-05, 'epoch': 2.17}\n",
      "{'loss': 2.7983, 'learning_rate': 1.7450124688279305e-05, 'epoch': 2.18}\n",
      "{'loss': 2.7851, 'learning_rate': 1.757481296758105e-05, 'epoch': 2.2}\n",
      "{'loss': 2.7815, 'learning_rate': 1.769925187032419e-05, 'epoch': 2.21}\n",
      "{'loss': 2.7687, 'learning_rate': 1.7823690773067333e-05, 'epoch': 2.23}\n",
      "{'loss': 2.7962, 'learning_rate': 1.7948379052369077e-05, 'epoch': 2.24}\n",
      "{'loss': 2.7679, 'learning_rate': 1.8073067331670826e-05, 'epoch': 2.26}\n",
      "{'loss': 2.7784, 'learning_rate': 1.819775561097257e-05, 'epoch': 2.28}\n",
      "{'loss': 2.7774, 'learning_rate': 1.8322443890274315e-05, 'epoch': 2.29}\n",
      "{'loss': 2.767, 'learning_rate': 1.844713216957606e-05, 'epoch': 2.31}\n",
      "{'loss': 2.7816, 'learning_rate': 1.8571820448877808e-05, 'epoch': 2.32}\n",
      "{'loss': 2.7651, 'learning_rate': 1.8696508728179552e-05, 'epoch': 2.34}\n",
      "{'loss': 2.7562, 'learning_rate': 1.8820947630922696e-05, 'epoch': 2.35}\n",
      "{'loss': 2.7878, 'learning_rate': 1.894563591022444e-05, 'epoch': 2.37}\n",
      "{'loss': 2.7452, 'learning_rate': 1.9070324189526185e-05, 'epoch': 2.38}\n",
      "{'loss': 2.7651, 'learning_rate': 1.9195012468827933e-05, 'epoch': 2.4}\n",
      "{'loss': 2.7336, 'learning_rate': 1.9319451371571073e-05, 'epoch': 2.42}\n",
      "{'loss': 2.7393, 'learning_rate': 1.944413965087282e-05, 'epoch': 2.43}\n",
      "{'loss': 2.7405, 'learning_rate': 1.9568827930174566e-05, 'epoch': 2.45}\n",
      "{'loss': 2.7664, 'learning_rate': 1.969326683291771e-05, 'epoch': 2.46}\n",
      "{'loss': 2.7455, 'learning_rate': 1.9817955112219454e-05, 'epoch': 2.48}\n",
      "{'loss': 2.7454, 'learning_rate': 1.99426433915212e-05, 'epoch': 2.49}\n",
      "{'loss': 2.7425, 'learning_rate': 1.9992518703241896e-05, 'epoch': 2.51}\n",
      "{'loss': 2.7249, 'learning_rate': 1.997866444998615e-05, 'epoch': 2.52}\n",
      "{'loss': 2.7377, 'learning_rate': 1.9964810196730398e-05, 'epoch': 2.54}\n",
      "{'loss': 2.7129, 'learning_rate': 1.9950955943474648e-05, 'epoch': 2.56}\n",
      "{'loss': 2.725, 'learning_rate': 1.9937101690218897e-05, 'epoch': 2.57}\n",
      "{'loss': 2.7422, 'learning_rate': 1.992327514546966e-05, 'epoch': 2.59}\n",
      "{'loss': 2.6987, 'learning_rate': 1.9909420892213913e-05, 'epoch': 2.6}\n",
      "{'loss': 2.6971, 'learning_rate': 1.9895566638958162e-05, 'epoch': 2.62}\n",
      "{'loss': 2.683, 'learning_rate': 1.988171238570241e-05, 'epoch': 2.63}\n",
      "{'loss': 2.7164, 'learning_rate': 1.9867885840953174e-05, 'epoch': 2.65}\n",
      "{'loss': 2.7144, 'learning_rate': 1.9854031587697424e-05, 'epoch': 2.67}\n",
      "{'loss': 2.7241, 'learning_rate': 1.9840177334441676e-05, 'epoch': 2.68}\n",
      "{'loss': 2.6866, 'learning_rate': 1.9826323081185926e-05, 'epoch': 2.7}\n",
      "{'loss': 2.6824, 'learning_rate': 1.9812468827930175e-05, 'epoch': 2.71}\n",
      "{'loss': 2.7025, 'learning_rate': 1.9798642283180938e-05, 'epoch': 2.73}\n",
      "{'loss': 2.6889, 'learning_rate': 1.9784788029925187e-05, 'epoch': 2.74}\n",
      "{'loss': 2.7043, 'learning_rate': 1.977093377666944e-05, 'epoch': 2.76}\n",
      "{'loss': 2.7001, 'learning_rate': 1.975707952341369e-05, 'epoch': 2.77}\n",
      "{'loss': 2.6763, 'learning_rate': 1.9743280687170962e-05, 'epoch': 2.79}\n",
      "{'loss': 2.6822, 'learning_rate': 1.972942643391521e-05, 'epoch': 2.81}\n",
      "{'loss': 2.6849, 'learning_rate': 1.9715572180659464e-05, 'epoch': 2.82}\n",
      "{'loss': 2.663, 'learning_rate': 1.9701717927403714e-05, 'epoch': 2.84}\n",
      "{'loss': 2.6636, 'learning_rate': 1.9687863674147963e-05, 'epoch': 2.85}\n",
      "{'loss': 2.6764, 'learning_rate': 1.9674009420892216e-05, 'epoch': 2.87}\n",
      "{'loss': 2.6704, 'learning_rate': 1.9660155167636466e-05, 'epoch': 2.88}\n",
      "{'loss': 2.668, 'learning_rate': 1.9646300914380715e-05, 'epoch': 2.9}\n",
      "{'loss': 2.6516, 'learning_rate': 1.9632474369631478e-05, 'epoch': 2.91}\n",
      "{'loss': 2.6708, 'learning_rate': 1.9618620116375727e-05, 'epoch': 2.93}\n",
      "{'loss': 2.6546, 'learning_rate': 1.960476586311998e-05, 'epoch': 2.95}\n",
      "{'loss': 2.6513, 'learning_rate': 1.959093931837074e-05, 'epoch': 2.96}\n",
      "{'loss': 2.6445, 'learning_rate': 1.9577085065114992e-05, 'epoch': 2.98}\n",
      "{'loss': 2.6448, 'learning_rate': 1.956323081185924e-05, 'epoch': 2.99}\n",
      "{'loss': 2.6784, 'learning_rate': 1.954937655860349e-05, 'epoch': 3.01}\n",
      "{'loss': 2.6319, 'learning_rate': 1.9535522305347744e-05, 'epoch': 3.02}\n",
      "{'loss': 2.634, 'learning_rate': 1.9521668052091993e-05, 'epoch': 3.04}\n",
      "{'loss': 2.6403, 'learning_rate': 1.9507813798836243e-05, 'epoch': 3.05}\n",
      "{'loss': 2.6427, 'learning_rate': 1.9493959545580496e-05, 'epoch': 3.07}\n",
      "{'loss': 2.6267, 'learning_rate': 1.9480105292324745e-05, 'epoch': 3.09}\n",
      "{'loss': 2.6411, 'learning_rate': 1.9466278747575508e-05, 'epoch': 3.1}\n",
      "{'loss': 2.628, 'learning_rate': 1.9452424494319757e-05, 'epoch': 3.12}\n",
      "{'loss': 2.6432, 'learning_rate': 1.9438570241064007e-05, 'epoch': 3.13}\n",
      "{'loss': 2.6205, 'learning_rate': 1.942471598780826e-05, 'epoch': 3.15}\n",
      "{'loss': 2.6302, 'learning_rate': 1.941088944305902e-05, 'epoch': 3.16}\n",
      "{'loss': 2.6143, 'learning_rate': 1.939703518980327e-05, 'epoch': 3.18}\n",
      "{'loss': 2.653, 'learning_rate': 1.938318093654752e-05, 'epoch': 3.2}\n",
      "{'loss': 2.6148, 'learning_rate': 1.936932668329177e-05, 'epoch': 3.21}\n",
      "{'loss': 2.6148, 'learning_rate': 1.9355500138542533e-05, 'epoch': 3.23}\n",
      "{'loss': 2.6062, 'learning_rate': 1.9341645885286782e-05, 'epoch': 3.24}\n",
      "{'loss': 2.6051, 'learning_rate': 1.9327791632031035e-05, 'epoch': 3.26}\n",
      "{'loss': 2.6265, 'learning_rate': 1.9313937378775285e-05, 'epoch': 3.27}\n",
      "{'loss': 2.6067, 'learning_rate': 1.9300110834026047e-05, 'epoch': 3.29}\n",
      "{'loss': 2.5957, 'learning_rate': 1.9286256580770297e-05, 'epoch': 3.3}\n",
      "{'loss': 2.608, 'learning_rate': 1.9272402327514546e-05, 'epoch': 3.32}\n",
      "{'loss': 2.6224, 'learning_rate': 1.92585480742588e-05, 'epoch': 3.34}\n",
      "{'loss': 2.6384, 'learning_rate': 1.924472152950956e-05, 'epoch': 3.35}\n",
      "{'loss': 2.6051, 'learning_rate': 1.923086727625381e-05, 'epoch': 3.37}\n",
      "{'loss': 2.6064, 'learning_rate': 1.921701302299806e-05, 'epoch': 3.38}\n",
      "{'loss': 2.6021, 'learning_rate': 1.9203186478248823e-05, 'epoch': 3.4}\n",
      "{'loss': 2.6062, 'learning_rate': 1.9189332224993073e-05, 'epoch': 3.41}\n",
      "{'loss': 2.6004, 'learning_rate': 1.9175477971737326e-05, 'epoch': 3.43}\n",
      "{'loss': 2.5859, 'learning_rate': 1.9161623718481575e-05, 'epoch': 3.44}\n",
      "{'loss': 2.5727, 'learning_rate': 1.9147797173732338e-05, 'epoch': 3.46}\n",
      "{'loss': 2.5764, 'learning_rate': 1.9133942920476587e-05, 'epoch': 3.48}\n",
      "{'loss': 2.5898, 'learning_rate': 1.9120088667220837e-05, 'epoch': 3.49}\n",
      "{'loss': 2.591, 'learning_rate': 1.910623441396509e-05, 'epoch': 3.51}\n",
      "{'loss': 2.5873, 'learning_rate': 1.909238016070934e-05, 'epoch': 3.52}\n",
      "{'loss': 2.5889, 'learning_rate': 1.9078525907453588e-05, 'epoch': 3.54}\n",
      "{'loss': 2.6072, 'learning_rate': 1.9064671654197838e-05, 'epoch': 3.55}\n",
      "{'loss': 2.5702, 'learning_rate': 1.905081740094209e-05, 'epoch': 3.57}\n",
      "{'loss': 2.5888, 'learning_rate': 1.903696314768634e-05, 'epoch': 3.58}\n",
      "{'loss': 2.5937, 'learning_rate': 1.9023136602937103e-05, 'epoch': 3.6}\n",
      "{'loss': 2.5704, 'learning_rate': 1.9009282349681352e-05, 'epoch': 3.62}\n",
      "{'loss': 2.5493, 'learning_rate': 1.89954280964256e-05, 'epoch': 3.63}\n",
      "{'loss': 2.5873, 'learning_rate': 1.8981573843169854e-05, 'epoch': 3.65}\n",
      "{'loss': 2.5607, 'learning_rate': 1.8967747298420617e-05, 'epoch': 3.66}\n",
      "{'loss': 2.5733, 'learning_rate': 1.8953893045164866e-05, 'epoch': 3.68}\n",
      "{'loss': 2.587, 'learning_rate': 1.8940038791909116e-05, 'epoch': 3.69}\n",
      "{'loss': 2.5666, 'learning_rate': 1.892618453865337e-05, 'epoch': 3.71}\n",
      "{'loss': 2.5783, 'learning_rate': 1.8912357993904128e-05, 'epoch': 3.73}\n",
      "{'loss': 2.5555, 'learning_rate': 1.889850374064838e-05, 'epoch': 3.74}\n",
      "{'loss': 2.5395, 'learning_rate': 1.888464948739263e-05, 'epoch': 3.76}\n",
      "{'loss': 2.5716, 'learning_rate': 1.887079523413688e-05, 'epoch': 3.77}\n",
      "{'loss': 2.5611, 'learning_rate': 1.8856940980881133e-05, 'epoch': 3.79}\n",
      "{'loss': 2.5863, 'learning_rate': 1.8843142144638405e-05, 'epoch': 3.8}\n",
      "{'loss': 2.5822, 'learning_rate': 1.8829287891382658e-05, 'epoch': 3.82}\n",
      "{'loss': 2.5604, 'learning_rate': 1.8815433638126907e-05, 'epoch': 3.83}\n",
      "{'loss': 2.5557, 'learning_rate': 1.8801579384871157e-05, 'epoch': 3.85}\n",
      "{'loss': 2.5736, 'learning_rate': 1.878772513161541e-05, 'epoch': 3.87}\n",
      "{'loss': 2.5681, 'learning_rate': 1.877387087835966e-05, 'epoch': 3.88}\n",
      "{'loss': 2.5396, 'learning_rate': 1.876001662510391e-05, 'epoch': 3.9}\n",
      "{'loss': 2.5556, 'learning_rate': 1.874616237184816e-05, 'epoch': 3.91}\n",
      "{'loss': 2.5554, 'learning_rate': 1.873233582709892e-05, 'epoch': 3.93}\n",
      "{'loss': 2.5665, 'learning_rate': 1.8718481573843173e-05, 'epoch': 3.94}\n",
      "{'loss': 2.5628, 'learning_rate': 1.8704627320587423e-05, 'epoch': 3.96}\n",
      "{'loss': 2.573, 'learning_rate': 1.8690773067331672e-05, 'epoch': 3.97}\n",
      "{'loss': 2.5361, 'learning_rate': 1.8676946522582435e-05, 'epoch': 3.99}\n",
      "{'loss': 2.5559, 'learning_rate': 1.8663092269326684e-05, 'epoch': 4.01}\n",
      "{'loss': 2.5286, 'learning_rate': 1.8649238016070937e-05, 'epoch': 4.02}\n",
      "{'loss': 2.5413, 'learning_rate': 1.8635383762815187e-05, 'epoch': 4.04}\n",
      "{'loss': 2.5608, 'learning_rate': 1.8621529509559436e-05, 'epoch': 4.05}\n",
      "{'loss': 2.5243, 'learning_rate': 1.86077029648102e-05, 'epoch': 4.07}\n",
      "{'loss': 2.5341, 'learning_rate': 1.8593848711554448e-05, 'epoch': 4.08}\n",
      "{'loss': 2.529, 'learning_rate': 1.85799944582987e-05, 'epoch': 4.1}\n",
      "{'loss': 2.5526, 'learning_rate': 1.856614020504295e-05, 'epoch': 4.11}\n",
      "{'loss': 2.5418, 'learning_rate': 1.8552313660293713e-05, 'epoch': 4.13}\n",
      "{'loss': 2.55, 'learning_rate': 1.8538459407037963e-05, 'epoch': 4.15}\n",
      "{'loss': 2.5447, 'learning_rate': 1.8524605153782212e-05, 'epoch': 4.16}\n",
      "{'loss': 2.5406, 'learning_rate': 1.8510750900526465e-05, 'epoch': 4.18}\n",
      "{'loss': 2.5335, 'learning_rate': 1.8496924355777228e-05, 'epoch': 4.19}\n",
      "{'loss': 2.5086, 'learning_rate': 1.8483070102521477e-05, 'epoch': 4.21}\n",
      "{'loss': 2.5473, 'learning_rate': 1.8469215849265726e-05, 'epoch': 4.22}\n",
      "{'loss': 2.5206, 'learning_rate': 1.8455361596009976e-05, 'epoch': 4.24}\n",
      "{'loss': 2.5318, 'learning_rate': 1.844153505126074e-05, 'epoch': 4.25}\n",
      "{'loss': 2.5237, 'learning_rate': 1.842768079800499e-05, 'epoch': 4.27}\n",
      "{'loss': 2.5346, 'learning_rate': 1.841382654474924e-05, 'epoch': 4.29}\n",
      "{'loss': 2.497, 'learning_rate': 1.839997229149349e-05, 'epoch': 4.3}\n",
      "{'loss': 2.5215, 'learning_rate': 1.8386145746744253e-05, 'epoch': 4.32}\n",
      "{'loss': 2.5419, 'learning_rate': 1.8372291493488502e-05, 'epoch': 4.33}\n",
      "{'loss': 2.4986, 'learning_rate': 1.8358437240232755e-05, 'epoch': 4.35}\n",
      "{'loss': 2.5168, 'learning_rate': 1.8344582986977005e-05, 'epoch': 4.36}\n",
      "{'loss': 2.5272, 'learning_rate': 1.8330728733721254e-05, 'epoch': 4.38}\n",
      "{'loss': 2.5218, 'learning_rate': 1.8316902188972017e-05, 'epoch': 4.4}\n",
      "{'loss': 2.5254, 'learning_rate': 1.830307564422278e-05, 'epoch': 4.41}\n",
      "{'loss': 2.5106, 'learning_rate': 1.828922139096703e-05, 'epoch': 4.43}\n",
      "{'loss': 2.5176, 'learning_rate': 1.8275367137711278e-05, 'epoch': 4.44}\n",
      "{'loss': 2.5178, 'learning_rate': 1.826151288445553e-05, 'epoch': 4.46}\n",
      "{'loss': 2.5159, 'learning_rate': 1.824765863119978e-05, 'epoch': 4.47}\n",
      "{'loss': 2.5112, 'learning_rate': 1.823380437794403e-05, 'epoch': 4.49}\n",
      "{'loss': 2.508, 'learning_rate': 1.8219950124688283e-05, 'epoch': 4.5}\n",
      "{'loss': 2.5116, 'learning_rate': 1.8206095871432532e-05, 'epoch': 4.52}\n",
      "{'loss': 2.5044, 'learning_rate': 1.8192269326683295e-05, 'epoch': 4.54}\n",
      "{'loss': 2.5143, 'learning_rate': 1.8178415073427544e-05, 'epoch': 4.55}\n",
      "{'loss': 2.5147, 'learning_rate': 1.8164560820171794e-05, 'epoch': 4.57}\n",
      "{'loss': 2.5033, 'learning_rate': 1.8150706566916047e-05, 'epoch': 4.58}\n",
      "{'loss': 2.5122, 'learning_rate': 1.8136880022166806e-05, 'epoch': 4.6}\n",
      "{'loss': 2.4963, 'learning_rate': 1.812302576891106e-05, 'epoch': 4.61}\n",
      "{'loss': 2.5088, 'learning_rate': 1.8109171515655308e-05, 'epoch': 4.63}\n",
      "{'loss': 2.4984, 'learning_rate': 1.8095317262399558e-05, 'epoch': 4.64}\n",
      "{'loss': 2.493, 'learning_rate': 1.808149071765032e-05, 'epoch': 4.66}\n",
      "{'loss': 2.51, 'learning_rate': 1.806763646439457e-05, 'epoch': 4.68}\n",
      "{'loss': 2.5038, 'learning_rate': 1.8053782211138823e-05, 'epoch': 4.69}\n",
      "{'loss': 2.4807, 'learning_rate': 1.8039927957883072e-05, 'epoch': 4.71}\n",
      "{'loss': 2.5236, 'learning_rate': 1.802607370462732e-05, 'epoch': 4.72}\n",
      "{'loss': 2.4977, 'learning_rate': 1.8012247159878084e-05, 'epoch': 4.74}\n",
      "{'loss': 2.4853, 'learning_rate': 1.7998392906622334e-05, 'epoch': 4.75}\n",
      "{'loss': 2.485, 'learning_rate': 1.7984538653366586e-05, 'epoch': 4.77}\n",
      "{'loss': 2.4752, 'learning_rate': 1.7970684400110836e-05, 'epoch': 4.78}\n",
      "{'loss': 2.4965, 'learning_rate': 1.7956830146855085e-05, 'epoch': 4.8}\n",
      "{'loss': 2.5113, 'learning_rate': 1.7943003602105848e-05, 'epoch': 4.82}\n",
      "{'loss': 2.4887, 'learning_rate': 1.7929149348850097e-05, 'epoch': 4.83}\n",
      "{'loss': 2.4982, 'learning_rate': 1.791529509559435e-05, 'epoch': 4.85}\n",
      "{'loss': 2.4978, 'learning_rate': 1.79014408423386e-05, 'epoch': 4.86}\n",
      "{'loss': 2.4744, 'learning_rate': 1.7887614297589362e-05, 'epoch': 4.88}\n",
      "{'loss': 2.4726, 'learning_rate': 1.7873760044333612e-05, 'epoch': 4.89}\n",
      "{'loss': 2.4957, 'learning_rate': 1.785990579107786e-05, 'epoch': 4.91}\n",
      "{'loss': 2.4887, 'learning_rate': 1.7846051537822114e-05, 'epoch': 4.93}\n",
      "{'loss': 2.4859, 'learning_rate': 1.7832197284566364e-05, 'epoch': 4.94}\n",
      "{'loss': 2.4831, 'learning_rate': 1.7818370739817126e-05, 'epoch': 4.96}\n",
      "{'loss': 2.5012, 'learning_rate': 1.780454419506789e-05, 'epoch': 4.97}\n",
      "{'loss': 2.4705, 'learning_rate': 1.7790689941812138e-05, 'epoch': 4.99}\n",
      "{'loss': 2.4722, 'learning_rate': 1.7776835688556388e-05, 'epoch': 5.0}\n",
      "{'loss': 2.4876, 'learning_rate': 1.776298143530064e-05, 'epoch': 5.02}\n",
      "{'loss': 2.4728, 'learning_rate': 1.774912718204489e-05, 'epoch': 5.03}\n",
      "{'loss': 2.4932, 'learning_rate': 1.773527292878914e-05, 'epoch': 5.05}\n",
      "{'loss': 2.4877, 'learning_rate': 1.7721418675533392e-05, 'epoch': 5.07}\n",
      "{'loss': 2.4898, 'learning_rate': 1.7707564422277642e-05, 'epoch': 5.08}\n",
      "{'loss': 2.4682, 'learning_rate': 1.769371016902189e-05, 'epoch': 5.1}\n",
      "{'loss': 2.4544, 'learning_rate': 1.7679883624272654e-05, 'epoch': 5.11}\n",
      "{'loss': 2.4858, 'learning_rate': 1.7666029371016903e-05, 'epoch': 5.13}\n",
      "{'loss': 2.4884, 'learning_rate': 1.7652175117761156e-05, 'epoch': 5.14}\n",
      "{'loss': 2.4714, 'learning_rate': 1.7638320864505406e-05, 'epoch': 5.16}\n",
      "{'loss': 2.4396, 'learning_rate': 1.7624466611249655e-05, 'epoch': 5.17}\n",
      "{'loss': 2.476, 'learning_rate': 1.7610640066500418e-05, 'epoch': 5.19}\n",
      "{'loss': 2.483, 'learning_rate': 1.7596785813244667e-05, 'epoch': 5.21}\n",
      "{'loss': 2.462, 'learning_rate': 1.758293155998892e-05, 'epoch': 5.22}\n",
      "{'loss': 2.4605, 'learning_rate': 1.756907730673317e-05, 'epoch': 5.24}\n",
      "{'loss': 2.4555, 'learning_rate': 1.7555250761983932e-05, 'epoch': 5.25}\n",
      "{'loss': 2.4754, 'learning_rate': 1.754139650872818e-05, 'epoch': 5.27}\n",
      "{'loss': 2.4446, 'learning_rate': 1.752754225547243e-05, 'epoch': 5.28}\n",
      "{'loss': 2.4782, 'learning_rate': 1.7513688002216684e-05, 'epoch': 5.3}\n",
      "{'loss': 2.4561, 'learning_rate': 1.7499833748960933e-05, 'epoch': 5.31}\n",
      "{'loss': 2.4766, 'learning_rate': 1.7486007204211696e-05, 'epoch': 5.33}\n",
      "{'loss': 2.468, 'learning_rate': 1.7472152950955945e-05, 'epoch': 5.35}\n",
      "{'loss': 2.4621, 'learning_rate': 1.7458298697700195e-05, 'epoch': 5.36}\n",
      "{'loss': 2.4354, 'learning_rate': 1.7444444444444448e-05, 'epoch': 5.38}\n",
      "{'loss': 2.472, 'learning_rate': 1.7430617899695207e-05, 'epoch': 5.39}\n",
      "{'loss': 2.4682, 'learning_rate': 1.741676364643946e-05, 'epoch': 5.41}\n",
      "{'loss': 2.4506, 'learning_rate': 1.740290939318371e-05, 'epoch': 5.42}\n",
      "{'loss': 2.448, 'learning_rate': 1.7389082848434472e-05, 'epoch': 5.44}\n",
      "{'loss': 2.4381, 'learning_rate': 1.737522859517872e-05, 'epoch': 5.46}\n",
      "{'loss': 2.463, 'learning_rate': 1.736137434192297e-05, 'epoch': 5.47}\n",
      "{'loss': 2.4486, 'learning_rate': 1.7347520088667223e-05, 'epoch': 5.49}\n",
      "{'loss': 2.4535, 'learning_rate': 1.7333665835411473e-05, 'epoch': 5.5}\n",
      "{'loss': 2.4578, 'learning_rate': 1.7319811582155722e-05, 'epoch': 5.52}\n",
      "{'loss': 2.4537, 'learning_rate': 1.7305957328899975e-05, 'epoch': 5.53}\n",
      "{'loss': 2.4597, 'learning_rate': 1.7292103075644225e-05, 'epoch': 5.55}\n",
      "{'loss': 2.4495, 'learning_rate': 1.7278248822388474e-05, 'epoch': 5.56}\n",
      "{'loss': 2.4484, 'learning_rate': 1.7264422277639237e-05, 'epoch': 5.58}\n",
      "{'loss': 2.4596, 'learning_rate': 1.7250568024383486e-05, 'epoch': 5.6}\n",
      "{'loss': 2.4658, 'learning_rate': 1.723671377112774e-05, 'epoch': 5.61}\n",
      "{'loss': 2.4542, 'learning_rate': 1.722285951787199e-05, 'epoch': 5.63}\n",
      "{'loss': 2.4447, 'learning_rate': 1.7209005264616238e-05, 'epoch': 5.64}\n",
      "{'loss': 2.4496, 'learning_rate': 1.7195151011360487e-05, 'epoch': 5.66}\n",
      "{'loss': 2.4505, 'learning_rate': 1.718129675810474e-05, 'epoch': 5.67}\n",
      "{'loss': 2.4412, 'learning_rate': 1.716744250484899e-05, 'epoch': 5.69}\n",
      "{'loss': 2.4243, 'learning_rate': 1.7153615960099752e-05, 'epoch': 5.7}\n",
      "{'loss': 2.4237, 'learning_rate': 1.7139761706844002e-05, 'epoch': 5.72}\n",
      "{'loss': 2.4435, 'learning_rate': 1.7125907453588255e-05, 'epoch': 5.74}\n",
      "{'loss': 2.4593, 'learning_rate': 1.7112053200332504e-05, 'epoch': 5.75}\n",
      "{'loss': 2.4509, 'learning_rate': 1.7098226655583267e-05, 'epoch': 5.77}\n",
      "{'loss': 2.4425, 'learning_rate': 1.7084372402327516e-05, 'epoch': 5.78}\n",
      "{'loss': 2.4487, 'learning_rate': 1.7070518149071766e-05, 'epoch': 5.8}\n",
      "{'loss': 2.4418, 'learning_rate': 1.705666389581602e-05, 'epoch': 5.81}\n",
      "{'loss': 2.4467, 'learning_rate': 1.7042809642560268e-05, 'epoch': 5.83}\n",
      "{'loss': 2.435, 'learning_rate': 1.7028955389304517e-05, 'epoch': 5.84}\n",
      "{'loss': 2.4501, 'learning_rate': 1.701512884455528e-05, 'epoch': 5.86}\n",
      "{'loss': 2.4466, 'learning_rate': 1.700127459129953e-05, 'epoch': 5.88}\n",
      "{'loss': 2.4331, 'learning_rate': 1.6987420338043782e-05, 'epoch': 5.89}\n",
      "{'loss': 2.4442, 'learning_rate': 1.6973566084788032e-05, 'epoch': 5.91}\n",
      "{'loss': 2.4305, 'learning_rate': 1.695971183153228e-05, 'epoch': 5.92}\n",
      "{'loss': 2.4347, 'learning_rate': 1.694585757827653e-05, 'epoch': 5.94}\n",
      "{'loss': 2.4505, 'learning_rate': 1.6932031033527293e-05, 'epoch': 5.95}\n",
      "{'loss': 2.436, 'learning_rate': 1.6918176780271546e-05, 'epoch': 5.97}\n",
      "{'loss': 2.4533, 'learning_rate': 1.6904322527015796e-05, 'epoch': 5.99}\n",
      "{'loss': 2.42, 'learning_rate': 1.6890468273760045e-05, 'epoch': 6.0}\n",
      "{'loss': 2.4182, 'learning_rate': 1.6876614020504295e-05, 'epoch': 6.02}\n",
      "{'loss': 2.4242, 'learning_rate': 1.6862787475755057e-05, 'epoch': 6.03}\n",
      "{'loss': 2.4165, 'learning_rate': 1.684893322249931e-05, 'epoch': 6.05}\n",
      "{'loss': 2.4302, 'learning_rate': 1.683507896924356e-05, 'epoch': 6.06}\n",
      "{'loss': 2.4109, 'learning_rate': 1.682122471598781e-05, 'epoch': 6.08}\n",
      "{'loss': 2.4269, 'learning_rate': 1.680737046273206e-05, 'epoch': 6.09}\n",
      "{'loss': 2.4395, 'learning_rate': 1.679351620947631e-05, 'epoch': 6.11}\n",
      "{'loss': 2.4251, 'learning_rate': 1.677966195622056e-05, 'epoch': 6.13}\n",
      "{'loss': 2.4432, 'learning_rate': 1.676580770296481e-05, 'epoch': 6.14}\n",
      "{'loss': 2.4559, 'learning_rate': 1.6751981158215573e-05, 'epoch': 6.16}\n",
      "{'loss': 2.4276, 'learning_rate': 1.6738126904959822e-05, 'epoch': 6.17}\n",
      "{'loss': 2.445, 'learning_rate': 1.6724272651704075e-05, 'epoch': 6.19}\n",
      "{'loss': 2.4074, 'learning_rate': 1.6710418398448325e-05, 'epoch': 6.2}\n",
      "{'loss': 2.4288, 'learning_rate': 1.6696591853699087e-05, 'epoch': 6.22}\n",
      "{'loss': 2.4389, 'learning_rate': 1.6682737600443337e-05, 'epoch': 6.23}\n",
      "{'loss': 2.407, 'learning_rate': 1.6668883347187586e-05, 'epoch': 6.25}\n",
      "{'loss': 2.4321, 'learning_rate': 1.665502909393184e-05, 'epoch': 6.27}\n",
      "{'loss': 2.4177, 'learning_rate': 1.664117484067609e-05, 'epoch': 6.28}\n",
      "{'loss': 2.4091, 'learning_rate': 1.6627320587420338e-05, 'epoch': 6.3}\n",
      "{'loss': 2.3961, 'learning_rate': 1.66134940426711e-05, 'epoch': 6.31}\n",
      "{'loss': 2.4108, 'learning_rate': 1.6599639789415353e-05, 'epoch': 6.33}\n",
      "{'loss': 2.4141, 'learning_rate': 1.6585785536159603e-05, 'epoch': 6.34}\n",
      "{'loss': 2.431, 'learning_rate': 1.6571931282903852e-05, 'epoch': 6.36}\n",
      "{'loss': 2.41, 'learning_rate': 1.6558104738154615e-05, 'epoch': 6.37}\n",
      "{'loss': 2.4221, 'learning_rate': 1.6544250484898864e-05, 'epoch': 6.39}\n",
      "{'loss': 2.4269, 'learning_rate': 1.6530396231643117e-05, 'epoch': 6.41}\n",
      "{'loss': 2.3947, 'learning_rate': 1.6516541978387367e-05, 'epoch': 6.42}\n",
      "{'loss': 2.4327, 'learning_rate': 1.6502687725131616e-05, 'epoch': 6.44}\n",
      "{'loss': 2.4059, 'learning_rate': 1.648886118038238e-05, 'epoch': 6.45}\n",
      "{'loss': 2.4117, 'learning_rate': 1.6475006927126628e-05, 'epoch': 6.47}\n",
      "{'loss': 2.422, 'learning_rate': 1.646115267387088e-05, 'epoch': 6.48}\n",
      "{'loss': 2.399, 'learning_rate': 1.644729842061513e-05, 'epoch': 6.5}\n",
      "{'loss': 2.4074, 'learning_rate': 1.643344416735938e-05, 'epoch': 6.51}\n",
      "{'loss': 2.4253, 'learning_rate': 1.641958991410363e-05, 'epoch': 6.53}\n",
      "{'loss': 2.4061, 'learning_rate': 1.6405763369354392e-05, 'epoch': 6.55}\n",
      "{'loss': 2.384, 'learning_rate': 1.6391909116098645e-05, 'epoch': 6.56}\n",
      "{'loss': 2.402, 'learning_rate': 1.6378054862842894e-05, 'epoch': 6.58}\n",
      "{'loss': 2.4179, 'learning_rate': 1.6364200609587144e-05, 'epoch': 6.59}\n",
      "{'loss': 2.4171, 'learning_rate': 1.6350346356331393e-05, 'epoch': 6.61}\n",
      "{'loss': 2.3947, 'learning_rate': 1.6336492103075646e-05, 'epoch': 6.62}\n",
      "{'loss': 2.403, 'learning_rate': 1.632266555832641e-05, 'epoch': 6.64}\n",
      "{'loss': 2.4201, 'learning_rate': 1.6308811305070658e-05, 'epoch': 6.66}\n",
      "{'loss': 2.3958, 'learning_rate': 1.6294957051814908e-05, 'epoch': 6.67}\n",
      "{'loss': 2.4104, 'learning_rate': 1.6281102798559157e-05, 'epoch': 6.69}\n",
      "{'loss': 2.4113, 'learning_rate': 1.626724854530341e-05, 'epoch': 6.7}\n",
      "{'loss': 2.4046, 'learning_rate': 1.6253422000554172e-05, 'epoch': 6.72}\n",
      "{'loss': 2.4224, 'learning_rate': 1.6239567747298422e-05, 'epoch': 6.73}\n",
      "{'loss': 2.4296, 'learning_rate': 1.622571349404267e-05, 'epoch': 6.75}\n",
      "{'loss': 2.4239, 'learning_rate': 1.621185924078692e-05, 'epoch': 6.76}\n",
      "{'loss': 2.4136, 'learning_rate': 1.6198032696037683e-05, 'epoch': 6.78}\n",
      "{'loss': 2.4221, 'learning_rate': 1.6184178442781936e-05, 'epoch': 6.8}\n",
      "{'loss': 2.4236, 'learning_rate': 1.6170324189526186e-05, 'epoch': 6.81}\n",
      "{'loss': 2.3875, 'learning_rate': 1.6156469936270435e-05, 'epoch': 6.83}\n",
      "{'loss': 2.4009, 'learning_rate': 1.6142615683014685e-05, 'epoch': 6.84}\n",
      "{'loss': 2.404, 'learning_rate': 1.6128761429758938e-05, 'epoch': 6.86}\n",
      "{'loss': 2.4012, 'learning_rate': 1.61149348850097e-05, 'epoch': 6.87}\n",
      "{'loss': 2.3807, 'learning_rate': 1.610108063175395e-05, 'epoch': 6.89}\n",
      "{'loss': 2.4061, 'learning_rate': 1.60872263784982e-05, 'epoch': 6.9}\n",
      "{'loss': 2.3829, 'learning_rate': 1.607337212524245e-05, 'epoch': 6.92}\n",
      "{'loss': 2.4057, 'learning_rate': 1.60595178719867e-05, 'epoch': 6.94}\n",
      "{'loss': 2.3927, 'learning_rate': 1.6045691327237464e-05, 'epoch': 6.95}\n",
      "{'loss': 2.3844, 'learning_rate': 1.6031837073981713e-05, 'epoch': 6.97}\n",
      "{'loss': 2.3954, 'learning_rate': 1.6017982820725963e-05, 'epoch': 6.98}\n",
      "{'loss': 2.3988, 'learning_rate': 1.6004128567470216e-05, 'epoch': 7.0}\n",
      "{'loss': 2.4155, 'learning_rate': 1.5990274314214465e-05, 'epoch': 7.01}\n",
      "{'loss': 2.3744, 'learning_rate': 1.5976447769465228e-05, 'epoch': 7.03}\n",
      "{'loss': 2.4126, 'learning_rate': 1.5962593516209477e-05, 'epoch': 7.04}\n",
      "{'loss': 2.3951, 'learning_rate': 1.5948739262953727e-05, 'epoch': 7.06}\n",
      "{'loss': 2.3888, 'learning_rate': 1.593488500969798e-05, 'epoch': 7.08}\n",
      "{'loss': 2.3798, 'learning_rate': 1.592103075644223e-05, 'epoch': 7.09}\n",
      "{'loss': 2.3927, 'learning_rate': 1.590717650318648e-05, 'epoch': 7.11}\n",
      "{'loss': 2.3916, 'learning_rate': 1.5893322249930728e-05, 'epoch': 7.12}\n",
      "{'loss': 2.3952, 'learning_rate': 1.587949570518149e-05, 'epoch': 7.14}\n",
      "{'loss': 2.3975, 'learning_rate': 1.5865641451925743e-05, 'epoch': 7.15}\n",
      "{'loss': 2.3777, 'learning_rate': 1.5851787198669993e-05, 'epoch': 7.17}\n",
      "{'loss': 2.3885, 'learning_rate': 1.5837932945414242e-05, 'epoch': 7.19}\n",
      "{'loss': 2.3659, 'learning_rate': 1.5824078692158492e-05, 'epoch': 7.2}\n",
      "{'loss': 2.3887, 'learning_rate': 1.5810252147409254e-05, 'epoch': 7.22}\n",
      "{'loss': 2.3705, 'learning_rate': 1.5796397894153507e-05, 'epoch': 7.23}\n",
      "{'loss': 2.3897, 'learning_rate': 1.5782543640897757e-05, 'epoch': 7.25}\n",
      "{'loss': 2.3994, 'learning_rate': 1.5768689387642006e-05, 'epoch': 7.26}\n",
      "{'loss': 2.3904, 'learning_rate': 1.5754835134386256e-05, 'epoch': 7.28}\n",
      "{'loss': 2.4095, 'learning_rate': 1.5741008589637018e-05, 'epoch': 7.29}\n",
      "{'loss': 2.3894, 'learning_rate': 1.572715433638127e-05, 'epoch': 7.31}\n",
      "{'loss': 2.3876, 'learning_rate': 1.571330008312552e-05, 'epoch': 7.33}\n",
      "{'loss': 2.3982, 'learning_rate': 1.569944582986977e-05, 'epoch': 7.34}\n",
      "{'loss': 2.3576, 'learning_rate': 1.5685619285120533e-05, 'epoch': 7.36}\n",
      "{'loss': 2.395, 'learning_rate': 1.5671765031864782e-05, 'epoch': 7.37}\n",
      "{'loss': 2.3658, 'learning_rate': 1.5657910778609035e-05, 'epoch': 7.39}\n",
      "{'loss': 2.3951, 'learning_rate': 1.5644056525353284e-05, 'epoch': 7.4}\n",
      "{'loss': 2.3846, 'learning_rate': 1.5630202272097534e-05, 'epoch': 7.42}\n",
      "{'loss': 2.3652, 'learning_rate': 1.5616348018841783e-05, 'epoch': 7.43}\n",
      "{'loss': 2.4037, 'learning_rate': 1.5602493765586036e-05, 'epoch': 7.45}\n",
      "{'loss': 2.3915, 'learning_rate': 1.5588639512330286e-05, 'epoch': 7.47}\n",
      "{'loss': 2.378, 'learning_rate': 1.5574812967581048e-05, 'epoch': 7.48}\n",
      "{'loss': 2.3872, 'learning_rate': 1.5560958714325298e-05, 'epoch': 7.5}\n",
      "{'loss': 2.3736, 'learning_rate': 1.554713216957606e-05, 'epoch': 7.51}\n",
      "{'loss': 2.3724, 'learning_rate': 1.553327791632031e-05, 'epoch': 7.53}\n",
      "{'loss': 2.3659, 'learning_rate': 1.5519423663064563e-05, 'epoch': 7.54}\n",
      "{'loss': 2.3871, 'learning_rate': 1.5505569409808812e-05, 'epoch': 7.56}\n",
      "{'loss': 2.3834, 'learning_rate': 1.549171515655306e-05, 'epoch': 7.57}\n",
      "{'loss': 2.3809, 'learning_rate': 1.5477888611803824e-05, 'epoch': 7.59}\n",
      "{'loss': 2.3649, 'learning_rate': 1.5464034358548074e-05, 'epoch': 7.61}\n",
      "{'loss': 2.364, 'learning_rate': 1.5450180105292326e-05, 'epoch': 7.62}\n",
      "{'loss': 2.3698, 'learning_rate': 1.5436325852036576e-05, 'epoch': 7.64}\n",
      "{'loss': 2.36, 'learning_rate': 1.542249930728734e-05, 'epoch': 7.65}\n",
      "{'loss': 2.3749, 'learning_rate': 1.5408645054031588e-05, 'epoch': 7.67}\n",
      "{'loss': 2.3632, 'learning_rate': 1.5394790800775837e-05, 'epoch': 7.68}\n",
      "{'loss': 2.3797, 'learning_rate': 1.538093654752009e-05, 'epoch': 7.7}\n",
      "{'loss': 2.3798, 'learning_rate': 1.536708229426434e-05, 'epoch': 7.72}\n",
      "{'loss': 2.3724, 'learning_rate': 1.535322804100859e-05, 'epoch': 7.73}\n",
      "{'loss': 2.3771, 'learning_rate': 1.5339401496259352e-05, 'epoch': 7.75}\n",
      "{'loss': 2.3766, 'learning_rate': 1.53255472430036e-05, 'epoch': 7.76}\n",
      "{'loss': 2.3896, 'learning_rate': 1.5311692989747854e-05, 'epoch': 7.78}\n",
      "{'loss': 2.3639, 'learning_rate': 1.5297838736492103e-05, 'epoch': 7.79}\n",
      "{'loss': 2.3736, 'learning_rate': 1.5283984483236353e-05, 'epoch': 7.81}\n",
      "{'loss': 2.3728, 'learning_rate': 1.5270130229980606e-05, 'epoch': 7.82}\n",
      "{'loss': 2.3813, 'learning_rate': 1.5256303685231367e-05, 'epoch': 7.84}\n",
      "{'loss': 2.3673, 'learning_rate': 1.5242449431975616e-05, 'epoch': 7.86}\n",
      "{'loss': 2.3691, 'learning_rate': 1.5228595178719867e-05, 'epoch': 7.87}\n",
      "{'loss': 2.3759, 'learning_rate': 1.5214740925464118e-05, 'epoch': 7.89}\n",
      "{'loss': 2.3738, 'learning_rate': 1.5200914380714881e-05, 'epoch': 7.9}\n",
      "{'loss': 2.3507, 'learning_rate': 1.5187060127459132e-05, 'epoch': 7.92}\n",
      "{'loss': 2.3631, 'learning_rate': 1.5173205874203383e-05, 'epoch': 7.93}\n",
      "{'loss': 2.3875, 'learning_rate': 1.5159351620947633e-05, 'epoch': 7.95}\n",
      "{'loss': 2.3652, 'learning_rate': 1.5145497367691884e-05, 'epoch': 7.96}\n",
      "{'loss': 2.3568, 'learning_rate': 1.5131643114436133e-05, 'epoch': 7.98}\n",
      "{'loss': 2.3655, 'learning_rate': 1.5117788861180385e-05, 'epoch': 8.0}\n",
      "{'loss': 2.3668, 'learning_rate': 1.5103934607924636e-05, 'epoch': 8.01}\n",
      "{'loss': 2.3561, 'learning_rate': 1.5090108063175397e-05, 'epoch': 8.03}\n",
      "{'loss': 2.3488, 'learning_rate': 1.5076253809919648e-05, 'epoch': 8.04}\n",
      "{'loss': 2.3716, 'learning_rate': 1.5062399556663897e-05, 'epoch': 8.06}\n",
      "{'loss': 2.3575, 'learning_rate': 1.5048545303408148e-05, 'epoch': 8.07}\n",
      "{'loss': 2.3785, 'learning_rate': 1.5034746467165422e-05, 'epoch': 8.09}\n",
      "{'loss': 2.3613, 'learning_rate': 1.5020892213909672e-05, 'epoch': 8.1}\n",
      "{'loss': 2.3531, 'learning_rate': 1.5007037960653923e-05, 'epoch': 8.12}\n",
      "{'loss': 2.3876, 'learning_rate': 1.4993183707398174e-05, 'epoch': 8.14}\n",
      "{'loss': 2.3472, 'learning_rate': 1.4979329454142424e-05, 'epoch': 8.15}\n",
      "{'loss': 2.3702, 'learning_rate': 1.4965475200886675e-05, 'epoch': 8.17}\n",
      "{'loss': 2.3725, 'learning_rate': 1.4951648656137436e-05, 'epoch': 8.18}\n",
      "{'loss': 2.3508, 'learning_rate': 1.4937794402881687e-05, 'epoch': 8.2}\n",
      "{'loss': 2.3562, 'learning_rate': 1.4923940149625938e-05, 'epoch': 8.21}\n",
      "{'loss': 2.3549, 'learning_rate': 1.4910085896370188e-05, 'epoch': 8.23}\n",
      "{'loss': 2.3578, 'learning_rate': 1.4896231643114439e-05, 'epoch': 8.25}\n",
      "{'loss': 2.3667, 'learning_rate': 1.48824050983652e-05, 'epoch': 8.26}\n",
      "{'loss': 2.3656, 'learning_rate': 1.486855084510945e-05, 'epoch': 8.28}\n",
      "{'loss': 2.3394, 'learning_rate': 1.4854696591853702e-05, 'epoch': 8.29}\n",
      "{'loss': 2.3627, 'learning_rate': 1.4840842338597951e-05, 'epoch': 8.31}\n",
      "{'loss': 2.3356, 'learning_rate': 1.4827015793848714e-05, 'epoch': 8.32}\n",
      "{'loss': 2.374, 'learning_rate': 1.4813161540592963e-05, 'epoch': 8.34}\n",
      "{'loss': 2.3561, 'learning_rate': 1.4799307287337215e-05, 'epoch': 8.35}\n",
      "{'loss': 2.3626, 'learning_rate': 1.4785453034081466e-05, 'epoch': 8.37}\n",
      "{'loss': 2.3602, 'learning_rate': 1.4771598780825715e-05, 'epoch': 8.39}\n",
      "{'loss': 2.3422, 'learning_rate': 1.4757744527569966e-05, 'epoch': 8.4}\n",
      "{'loss': 2.3544, 'learning_rate': 1.4743890274314216e-05, 'epoch': 8.42}\n",
      "{'loss': 2.3709, 'learning_rate': 1.4730036021058467e-05, 'epoch': 8.43}\n",
      "{'loss': 2.344, 'learning_rate': 1.471620947630923e-05, 'epoch': 8.45}\n",
      "{'loss': 2.3556, 'learning_rate': 1.4702355223053479e-05, 'epoch': 8.46}\n",
      "{'loss': 2.3609, 'learning_rate': 1.4688528678304242e-05, 'epoch': 8.48}\n",
      "{'loss': 2.3408, 'learning_rate': 1.4674674425048491e-05, 'epoch': 8.49}\n",
      "{'loss': 2.3349, 'learning_rate': 1.4660820171792742e-05, 'epoch': 8.51}\n",
      "{'loss': 2.3578, 'learning_rate': 1.4646965918536993e-05, 'epoch': 8.53}\n",
      "{'loss': 2.3371, 'learning_rate': 1.4633139373787754e-05, 'epoch': 8.54}\n",
      "{'loss': 2.3613, 'learning_rate': 1.4619285120532005e-05, 'epoch': 8.56}\n",
      "{'loss': 2.3464, 'learning_rate': 1.4605430867276255e-05, 'epoch': 8.57}\n",
      "{'loss': 2.3522, 'learning_rate': 1.4591576614020506e-05, 'epoch': 8.59}\n",
      "{'loss': 2.3448, 'learning_rate': 1.4577722360764757e-05, 'epoch': 8.6}\n",
      "{'loss': 2.3505, 'learning_rate': 1.4563868107509007e-05, 'epoch': 8.62}\n",
      "{'loss': 2.3499, 'learning_rate': 1.4550013854253258e-05, 'epoch': 8.63}\n",
      "{'loss': 2.3502, 'learning_rate': 1.4536159600997507e-05, 'epoch': 8.65}\n",
      "{'loss': 2.3494, 'learning_rate': 1.452233305624827e-05, 'epoch': 8.67}\n",
      "{'loss': 2.3339, 'learning_rate': 1.4508478802992521e-05, 'epoch': 8.68}\n",
      "{'loss': 2.344, 'learning_rate': 1.449462454973677e-05, 'epoch': 8.7}\n",
      "{'loss': 2.3505, 'learning_rate': 1.4480770296481022e-05, 'epoch': 8.71}\n",
      "{'loss': 2.328, 'learning_rate': 1.4466916043225271e-05, 'epoch': 8.73}\n",
      "{'loss': 2.3421, 'learning_rate': 1.4453061789969522e-05, 'epoch': 8.74}\n",
      "{'loss': 2.3432, 'learning_rate': 1.4439207536713773e-05, 'epoch': 8.76}\n",
      "{'loss': 2.3641, 'learning_rate': 1.4425380991964534e-05, 'epoch': 8.77}\n",
      "{'loss': 2.346, 'learning_rate': 1.4411526738708786e-05, 'epoch': 8.79}\n",
      "{'loss': 2.3467, 'learning_rate': 1.4397672485453037e-05, 'epoch': 8.81}\n",
      "{'loss': 2.3461, 'learning_rate': 1.4383818232197286e-05, 'epoch': 8.82}\n",
      "{'loss': 2.325, 'learning_rate': 1.4369963978941537e-05, 'epoch': 8.84}\n",
      "{'loss': 2.3404, 'learning_rate': 1.4356109725685787e-05, 'epoch': 8.85}\n",
      "{'loss': 2.3401, 'learning_rate': 1.4342255472430038e-05, 'epoch': 8.87}\n",
      "{'loss': 2.3376, 'learning_rate': 1.4328401219174289e-05, 'epoch': 8.88}\n",
      "{'loss': 2.3519, 'learning_rate': 1.431457467442505e-05, 'epoch': 8.9}\n",
      "{'loss': 2.347, 'learning_rate': 1.4300720421169301e-05, 'epoch': 8.92}\n",
      "{'loss': 2.3279, 'learning_rate': 1.428686616791355e-05, 'epoch': 8.93}\n",
      "{'loss': 2.3319, 'learning_rate': 1.4273011914657802e-05, 'epoch': 8.95}\n",
      "{'loss': 2.3388, 'learning_rate': 1.4259185369908564e-05, 'epoch': 8.96}\n",
      "{'loss': 2.3467, 'learning_rate': 1.4245331116652814e-05, 'epoch': 8.98}\n",
      "{'loss': 2.3408, 'learning_rate': 1.4231476863397065e-05, 'epoch': 8.99}\n",
      "{'loss': 2.3375, 'learning_rate': 1.4217622610141314e-05, 'epoch': 9.01}\n",
      "{'loss': 2.3321, 'learning_rate': 1.4203796065392077e-05, 'epoch': 9.02}\n",
      "{'loss': 2.3084, 'learning_rate': 1.4189941812136328e-05, 'epoch': 9.04}\n",
      "{'loss': 2.3481, 'learning_rate': 1.4176087558880578e-05, 'epoch': 9.06}\n",
      "{'loss': 2.3372, 'learning_rate': 1.4162233305624829e-05, 'epoch': 9.07}\n",
      "{'loss': 2.3505, 'learning_rate': 1.414840676087559e-05, 'epoch': 9.09}\n",
      "{'loss': 2.345, 'learning_rate': 1.4134580216126352e-05, 'epoch': 9.1}\n",
      "{'loss': 2.332, 'learning_rate': 1.4120725962870603e-05, 'epoch': 9.12}\n",
      "{'loss': 2.3269, 'learning_rate': 1.4106871709614853e-05, 'epoch': 9.13}\n",
      "{'loss': 2.3507, 'learning_rate': 1.4093017456359104e-05, 'epoch': 9.15}\n",
      "{'loss': 2.3431, 'learning_rate': 1.4079163203103354e-05, 'epoch': 9.16}\n",
      "{'loss': 2.3261, 'learning_rate': 1.4065336658354116e-05, 'epoch': 9.18}\n",
      "{'loss': 2.3298, 'learning_rate': 1.4051482405098367e-05, 'epoch': 9.2}\n",
      "{'loss': 2.3151, 'learning_rate': 1.4037628151842617e-05, 'epoch': 9.21}\n",
      "{'loss': 2.354, 'learning_rate': 1.402380160709338e-05, 'epoch': 9.23}\n",
      "{'loss': 2.3229, 'learning_rate': 1.4009947353837629e-05, 'epoch': 9.24}\n",
      "{'loss': 2.3257, 'learning_rate': 1.399609310058188e-05, 'epoch': 9.26}\n",
      "{'loss': 2.3395, 'learning_rate': 1.3982238847326131e-05, 'epoch': 9.27}\n",
      "{'loss': 2.3275, 'learning_rate': 1.396838459407038e-05, 'epoch': 9.29}\n",
      "{'loss': 2.3284, 'learning_rate': 1.3954530340814632e-05, 'epoch': 9.3}\n",
      "{'loss': 2.3024, 'learning_rate': 1.3940676087558881e-05, 'epoch': 9.32}\n",
      "{'loss': 2.3458, 'learning_rate': 1.3926821834303132e-05, 'epoch': 9.34}\n",
      "{'loss': 2.3422, 'learning_rate': 1.3912967581047384e-05, 'epoch': 9.35}\n",
      "{'loss': 2.3528, 'learning_rate': 1.3899113327791633e-05, 'epoch': 9.37}\n",
      "{'loss': 2.3469, 'learning_rate': 1.3885286783042396e-05, 'epoch': 9.38}\n",
      "{'loss': 2.3371, 'learning_rate': 1.3871432529786647e-05, 'epoch': 9.4}\n",
      "{'loss': 2.3403, 'learning_rate': 1.3857578276530896e-05, 'epoch': 9.41}\n",
      "{'loss': 2.3514, 'learning_rate': 1.3843724023275147e-05, 'epoch': 9.43}\n",
      "{'loss': 2.3299, 'learning_rate': 1.3829869770019397e-05, 'epoch': 9.45}\n",
      "{'loss': 2.3361, 'learning_rate': 1.3816015516763648e-05, 'epoch': 9.46}\n",
      "{'loss': 2.3357, 'learning_rate': 1.3802161263507899e-05, 'epoch': 9.48}\n",
      "{'loss': 2.3197, 'learning_rate': 1.3788307010252149e-05, 'epoch': 9.49}\n",
      "{'loss': 2.3078, 'learning_rate': 1.3774480465502911e-05, 'epoch': 9.51}\n",
      "{'loss': 2.3444, 'learning_rate': 1.376062621224716e-05, 'epoch': 9.52}\n",
      "{'loss': 2.3306, 'learning_rate': 1.3746771958991412e-05, 'epoch': 9.54}\n",
      "{'loss': 2.3014, 'learning_rate': 1.3732917705735663e-05, 'epoch': 9.55}\n",
      "{'loss': 2.318, 'learning_rate': 1.3719091160986424e-05, 'epoch': 9.57}\n",
      "{'loss': 2.3155, 'learning_rate': 1.3705264616237186e-05, 'epoch': 9.59}\n",
      "{'loss': 2.336, 'learning_rate': 1.3691410362981436e-05, 'epoch': 9.6}\n",
      "{'loss': 2.3213, 'learning_rate': 1.3677556109725687e-05, 'epoch': 9.62}\n",
      "{'loss': 2.3159, 'learning_rate': 1.3663701856469938e-05, 'epoch': 9.63}\n",
      "{'loss': 2.3131, 'learning_rate': 1.3649847603214188e-05, 'epoch': 9.65}\n",
      "{'loss': 2.3037, 'learning_rate': 1.363602105846495e-05, 'epoch': 9.66}\n",
      "{'loss': 2.3116, 'learning_rate': 1.36221668052092e-05, 'epoch': 9.68}\n",
      "{'loss': 2.3428, 'learning_rate': 1.3608312551953451e-05, 'epoch': 9.69}\n",
      "{'loss': 2.3209, 'learning_rate': 1.3594458298697702e-05, 'epoch': 9.71}\n",
      "{'loss': 2.3317, 'learning_rate': 1.3580604045441952e-05, 'epoch': 9.73}\n",
      "{'loss': 2.3251, 'learning_rate': 1.3566749792186203e-05, 'epoch': 9.74}\n",
      "{'loss': 2.3083, 'learning_rate': 1.3552923247436964e-05, 'epoch': 9.76}\n",
      "{'loss': 2.3179, 'learning_rate': 1.3539068994181215e-05, 'epoch': 9.77}\n",
      "{'loss': 2.3415, 'learning_rate': 1.3525214740925466e-05, 'epoch': 9.79}\n",
      "{'loss': 2.3132, 'learning_rate': 1.3511360487669715e-05, 'epoch': 9.8}\n",
      "{'loss': 2.3351, 'learning_rate': 1.3497506234413966e-05, 'epoch': 9.82}\n",
      "{'loss': 2.307, 'learning_rate': 1.3483651981158216e-05, 'epoch': 9.83}\n",
      "{'loss': 2.3152, 'learning_rate': 1.3469825436408979e-05, 'epoch': 9.85}\n",
      "{'loss': 2.3251, 'learning_rate': 1.345597118315323e-05, 'epoch': 9.87}\n",
      "{'loss': 2.3019, 'learning_rate': 1.344211692989748e-05, 'epoch': 9.88}\n",
      "{'loss': 2.3306, 'learning_rate': 1.342826267664173e-05, 'epoch': 9.9}\n",
      "{'loss': 2.3212, 'learning_rate': 1.341440842338598e-05, 'epoch': 9.91}\n",
      "{'loss': 2.3287, 'learning_rate': 1.3400554170130231e-05, 'epoch': 9.93}\n",
      "{'loss': 2.34, 'learning_rate': 1.3386699916874482e-05, 'epoch': 9.94}\n",
      "{'loss': 2.3028, 'learning_rate': 1.3372845663618732e-05, 'epoch': 9.96}\n",
      "{'loss': 2.318, 'learning_rate': 1.3359019118869494e-05, 'epoch': 9.98}\n",
      "{'loss': 2.3075, 'learning_rate': 1.3345164865613744e-05, 'epoch': 9.99}\n",
      "{'loss': 2.3124, 'learning_rate': 1.3331310612357995e-05, 'epoch': 10.01}\n",
      "{'loss': 2.2952, 'learning_rate': 1.3317456359102246e-05, 'epoch': 10.02}\n",
      "{'loss': 2.3006, 'learning_rate': 1.3303629814353007e-05, 'epoch': 10.04}\n",
      "{'loss': 2.2931, 'learning_rate': 1.3289775561097258e-05, 'epoch': 10.05}\n",
      "{'loss': 2.306, 'learning_rate': 1.3275921307841509e-05, 'epoch': 10.07}\n",
      "{'loss': 2.3077, 'learning_rate': 1.3262067054585759e-05, 'epoch': 10.08}\n",
      "{'loss': 2.3066, 'learning_rate': 1.324821280133001e-05, 'epoch': 10.1}\n",
      "{'loss': 2.3064, 'learning_rate': 1.323438625658077e-05, 'epoch': 10.12}\n",
      "{'loss': 2.2991, 'learning_rate': 1.3220532003325022e-05, 'epoch': 10.13}\n",
      "{'loss': 2.3054, 'learning_rate': 1.3206677750069273e-05, 'epoch': 10.15}\n",
      "{'loss': 2.3252, 'learning_rate': 1.3192823496813522e-05, 'epoch': 10.16}\n",
      "{'loss': 2.3123, 'learning_rate': 1.3178969243557774e-05, 'epoch': 10.18}\n",
      "{'loss': 2.3003, 'learning_rate': 1.3165114990302023e-05, 'epoch': 10.19}\n",
      "{'loss': 2.3013, 'learning_rate': 1.3151260737046274e-05, 'epoch': 10.21}\n",
      "{'loss': 2.2983, 'learning_rate': 1.3137406483790525e-05, 'epoch': 10.22}\n",
      "{'loss': 2.3162, 'learning_rate': 1.3123579939041286e-05, 'epoch': 10.24}\n",
      "{'loss': 2.3026, 'learning_rate': 1.3109725685785537e-05, 'epoch': 10.26}\n",
      "{'loss': 2.3035, 'learning_rate': 1.3095871432529787e-05, 'epoch': 10.27}\n",
      "{'loss': 2.304, 'learning_rate': 1.3082017179274038e-05, 'epoch': 10.29}\n",
      "{'loss': 2.2977, 'learning_rate': 1.3068218343031312e-05, 'epoch': 10.3}\n",
      "{'loss': 2.3038, 'learning_rate': 1.3054364089775562e-05, 'epoch': 10.32}\n",
      "{'loss': 2.314, 'learning_rate': 1.3040509836519813e-05, 'epoch': 10.33}\n",
      "{'loss': 2.3079, 'learning_rate': 1.3026655583264062e-05, 'epoch': 10.35}\n",
      "{'loss': 2.3246, 'learning_rate': 1.3012801330008313e-05, 'epoch': 10.36}\n",
      "{'loss': 2.3201, 'learning_rate': 1.2998947076752564e-05, 'epoch': 10.38}\n",
      "{'loss': 2.3021, 'learning_rate': 1.2985120532003325e-05, 'epoch': 10.4}\n",
      "{'loss': 2.3111, 'learning_rate': 1.2971266278747577e-05, 'epoch': 10.41}\n",
      "{'loss': 2.311, 'learning_rate': 1.2957412025491826e-05, 'epoch': 10.43}\n",
      "{'loss': 2.3163, 'learning_rate': 1.2943557772236077e-05, 'epoch': 10.44}\n",
      "{'loss': 2.3239, 'learning_rate': 1.2929703518980328e-05, 'epoch': 10.46}\n",
      "{'loss': 2.3046, 'learning_rate': 1.2915849265724578e-05, 'epoch': 10.47}\n",
      "{'loss': 2.2865, 'learning_rate': 1.2901995012468829e-05, 'epoch': 10.49}\n",
      "{'loss': 2.322, 'learning_rate': 1.2888140759213078e-05, 'epoch': 10.5}\n",
      "{'loss': 2.3047, 'learning_rate': 1.2874314214463841e-05, 'epoch': 10.52}\n",
      "{'loss': 2.327, 'learning_rate': 1.2860459961208092e-05, 'epoch': 10.54}\n",
      "{'loss': 2.3155, 'learning_rate': 1.2846605707952342e-05, 'epoch': 10.55}\n",
      "{'loss': 2.3001, 'learning_rate': 1.2832751454696593e-05, 'epoch': 10.57}\n",
      "{'loss': 2.3114, 'learning_rate': 1.2818924909947354e-05, 'epoch': 10.58}\n",
      "{'loss': 2.3123, 'learning_rate': 1.2805070656691605e-05, 'epoch': 10.6}\n",
      "{'loss': 2.3222, 'learning_rate': 1.2791216403435856e-05, 'epoch': 10.61}\n",
      "{'loss': 2.3121, 'learning_rate': 1.2777362150180105e-05, 'epoch': 10.63}\n",
      "{'loss': 2.3045, 'learning_rate': 1.2763507896924357e-05, 'epoch': 10.65}\n",
      "{'loss': 2.2911, 'learning_rate': 1.2749653643668608e-05, 'epoch': 10.66}\n",
      "{'loss': 2.3142, 'learning_rate': 1.2735799390412857e-05, 'epoch': 10.68}\n",
      "{'loss': 2.3081, 'learning_rate': 1.2721945137157108e-05, 'epoch': 10.69}\n",
      "{'loss': 2.2922, 'learning_rate': 1.2708090883901358e-05, 'epoch': 10.71}\n",
      "{'loss': 2.3167, 'learning_rate': 1.269426433915212e-05, 'epoch': 10.72}\n",
      "{'loss': 2.2965, 'learning_rate': 1.2680410085896372e-05, 'epoch': 10.74}\n",
      "{'loss': 2.3149, 'learning_rate': 1.2666555832640621e-05, 'epoch': 10.75}\n",
      "{'loss': 2.3288, 'learning_rate': 1.2652701579384872e-05, 'epoch': 10.77}\n",
      "{'loss': 2.289, 'learning_rate': 1.2638847326129122e-05, 'epoch': 10.79}\n",
      "{'loss': 2.2906, 'learning_rate': 1.2624993072873373e-05, 'epoch': 10.8}\n",
      "{'loss': 2.3176, 'learning_rate': 1.2611138819617624e-05, 'epoch': 10.82}\n",
      "{'loss': 2.307, 'learning_rate': 1.2597284566361873e-05, 'epoch': 10.83}\n",
      "{'loss': 2.3096, 'learning_rate': 1.2583458021612636e-05, 'epoch': 10.85}\n",
      "{'loss': 2.2884, 'learning_rate': 1.2569603768356885e-05, 'epoch': 10.86}\n",
      "{'loss': 2.2922, 'learning_rate': 1.2555749515101137e-05, 'epoch': 10.88}\n",
      "{'loss': 2.2972, 'learning_rate': 1.2541895261845388e-05, 'epoch': 10.89}\n",
      "{'loss': 2.2925, 'learning_rate': 1.2528041008589637e-05, 'epoch': 10.91}\n",
      "{'loss': 2.2892, 'learning_rate': 1.2514186755333888e-05, 'epoch': 10.93}\n",
      "{'loss': 2.2982, 'learning_rate': 1.2500332502078138e-05, 'epoch': 10.94}\n",
      "{'loss': 2.29, 'learning_rate': 1.2486478248822389e-05, 'epoch': 10.96}\n",
      "{'loss': 2.3072, 'learning_rate': 1.2472679412579663e-05, 'epoch': 10.97}\n",
      "{'loss': 2.3058, 'learning_rate': 1.2458825159323913e-05, 'epoch': 10.99}\n",
      "{'loss': 2.3101, 'learning_rate': 1.2444970906068164e-05, 'epoch': 11.0}\n",
      "{'loss': 2.2864, 'learning_rate': 1.2431116652812413e-05, 'epoch': 11.02}\n",
      "{'loss': 2.2828, 'learning_rate': 1.2417262399556664e-05, 'epoch': 11.03}\n",
      "{'loss': 2.2916, 'learning_rate': 1.2403408146300915e-05, 'epoch': 11.05}\n",
      "{'loss': 2.2838, 'learning_rate': 1.2389553893045165e-05, 'epoch': 11.07}\n",
      "{'loss': 2.2706, 'learning_rate': 1.2375727348295928e-05, 'epoch': 11.08}\n",
      "{'loss': 2.2744, 'learning_rate': 1.2361873095040177e-05, 'epoch': 11.1}\n",
      "{'loss': 2.3126, 'learning_rate': 1.2348018841784428e-05, 'epoch': 11.11}\n",
      "{'loss': 2.288, 'learning_rate': 1.233416458852868e-05, 'epoch': 11.13}\n",
      "{'loss': 2.3038, 'learning_rate': 1.2320310335272929e-05, 'epoch': 11.14}\n",
      "{'loss': 2.2849, 'learning_rate': 1.230645608201718e-05, 'epoch': 11.16}\n",
      "{'loss': 2.2951, 'learning_rate': 1.229260182876143e-05, 'epoch': 11.18}\n",
      "{'loss': 2.2825, 'learning_rate': 1.227874757550568e-05, 'epoch': 11.19}\n",
      "{'loss': 2.2933, 'learning_rate': 1.2264921030756443e-05, 'epoch': 11.21}\n",
      "{'loss': 2.2991, 'learning_rate': 1.2251094486007204e-05, 'epoch': 11.22}\n",
      "{'loss': 2.2787, 'learning_rate': 1.2237240232751455e-05, 'epoch': 11.24}\n",
      "{'loss': 2.2945, 'learning_rate': 1.2223385979495705e-05, 'epoch': 11.25}\n",
      "{'loss': 2.2899, 'learning_rate': 1.2209531726239956e-05, 'epoch': 11.27}\n",
      "{'loss': 2.304, 'learning_rate': 1.2195677472984207e-05, 'epoch': 11.28}\n",
      "{'loss': 2.2981, 'learning_rate': 1.2181850928234968e-05, 'epoch': 11.3}\n",
      "{'loss': 2.306, 'learning_rate': 1.2167996674979219e-05, 'epoch': 11.32}\n",
      "{'loss': 2.2904, 'learning_rate': 1.215414242172347e-05, 'epoch': 11.33}\n",
      "{'loss': 2.2929, 'learning_rate': 1.214028816846772e-05, 'epoch': 11.35}\n",
      "{'loss': 2.2639, 'learning_rate': 1.212643391521197e-05, 'epoch': 11.36}\n",
      "{'loss': 2.2977, 'learning_rate': 1.2112607370462732e-05, 'epoch': 11.38}\n",
      "{'loss': 2.2841, 'learning_rate': 1.2098753117206983e-05, 'epoch': 11.39}\n",
      "{'loss': 2.2832, 'learning_rate': 1.2084898863951234e-05, 'epoch': 11.41}\n",
      "{'loss': 2.2955, 'learning_rate': 1.2071044610695483e-05, 'epoch': 11.42}\n",
      "{'loss': 2.3016, 'learning_rate': 1.2057190357439735e-05, 'epoch': 11.44}\n",
      "{'loss': 2.2943, 'learning_rate': 1.2043336104183984e-05, 'epoch': 11.46}\n",
      "{'loss': 2.3063, 'learning_rate': 1.2029481850928235e-05, 'epoch': 11.47}\n",
      "{'loss': 2.2831, 'learning_rate': 1.2015627597672486e-05, 'epoch': 11.49}\n",
      "{'loss': 2.2882, 'learning_rate': 1.2001801052923247e-05, 'epoch': 11.5}\n",
      "{'loss': 2.3014, 'learning_rate': 1.198797450817401e-05, 'epoch': 11.52}\n",
      "{'loss': 2.2907, 'learning_rate': 1.197412025491826e-05, 'epoch': 11.53}\n",
      "{'loss': 2.2837, 'learning_rate': 1.196026600166251e-05, 'epoch': 11.55}\n",
      "{'loss': 2.2821, 'learning_rate': 1.1946411748406762e-05, 'epoch': 11.56}\n",
      "{'loss': 2.2811, 'learning_rate': 1.1932557495151011e-05, 'epoch': 11.58}\n",
      "{'loss': 2.2841, 'learning_rate': 1.1918730950401774e-05, 'epoch': 11.6}\n",
      "{'loss': 2.2619, 'learning_rate': 1.1904876697146023e-05, 'epoch': 11.61}\n",
      "{'loss': 2.2617, 'learning_rate': 1.1891022443890274e-05, 'epoch': 11.63}\n",
      "{'loss': 2.2731, 'learning_rate': 1.1877168190634525e-05, 'epoch': 11.64}\n",
      "{'loss': 2.3075, 'learning_rate': 1.1863313937378775e-05, 'epoch': 11.66}\n",
      "{'loss': 2.2916, 'learning_rate': 1.1849487392629538e-05, 'epoch': 11.67}\n",
      "{'loss': 2.2973, 'learning_rate': 1.1835633139373787e-05, 'epoch': 11.69}\n",
      "{'loss': 2.2869, 'learning_rate': 1.1821778886118038e-05, 'epoch': 11.71}\n",
      "{'loss': 2.2844, 'learning_rate': 1.180792463286229e-05, 'epoch': 11.72}\n",
      "{'loss': 2.2855, 'learning_rate': 1.1794070379606539e-05, 'epoch': 11.74}\n",
      "{'loss': 2.2916, 'learning_rate': 1.178021612635079e-05, 'epoch': 11.75}\n",
      "{'loss': 2.3015, 'learning_rate': 1.176636187309504e-05, 'epoch': 11.77}\n",
      "{'loss': 2.2857, 'learning_rate': 1.175250761983929e-05, 'epoch': 11.78}\n",
      "{'loss': 2.289, 'learning_rate': 1.1738681075090053e-05, 'epoch': 11.8}\n",
      "{'loss': 2.2853, 'learning_rate': 1.1724826821834303e-05, 'epoch': 11.81}\n",
      "{'loss': 2.2713, 'learning_rate': 1.1710972568578554e-05, 'epoch': 11.83}\n",
      "{'loss': 2.2714, 'learning_rate': 1.1697118315322803e-05, 'epoch': 11.85}\n",
      "{'loss': 2.283, 'learning_rate': 1.1683291770573566e-05, 'epoch': 11.86}\n",
      "{'loss': 2.2765, 'learning_rate': 1.1669437517317817e-05, 'epoch': 11.88}\n",
      "{'loss': 2.2858, 'learning_rate': 1.1655583264062066e-05, 'epoch': 11.89}\n",
      "{'loss': 2.2879, 'learning_rate': 1.1641729010806318e-05, 'epoch': 11.91}\n",
      "{'loss': 2.292, 'learning_rate': 1.162790246605708e-05, 'epoch': 11.92}\n",
      "{'loss': 2.2666, 'learning_rate': 1.161404821280133e-05, 'epoch': 11.94}\n",
      "{'loss': 2.2864, 'learning_rate': 1.160019395954558e-05, 'epoch': 11.95}\n",
      "{'loss': 2.265, 'learning_rate': 1.158633970628983e-05, 'epoch': 11.97}\n",
      "{'loss': 2.2921, 'learning_rate': 1.1572513161540595e-05, 'epoch': 11.99}\n",
      "{'loss': 2.3026, 'learning_rate': 1.1558658908284846e-05, 'epoch': 12.0}\n",
      "{'loss': 2.2806, 'learning_rate': 1.1544804655029095e-05, 'epoch': 12.02}\n",
      "{'loss': 2.2638, 'learning_rate': 1.1530978110279858e-05, 'epoch': 12.03}\n",
      "{'loss': 2.2668, 'learning_rate': 1.1517123857024109e-05, 'epoch': 12.05}\n",
      "{'loss': 2.2723, 'learning_rate': 1.1503269603768358e-05, 'epoch': 12.06}\n",
      "{'loss': 2.2712, 'learning_rate': 1.148941535051261e-05, 'epoch': 12.08}\n",
      "{'loss': 2.2781, 'learning_rate': 1.1475561097256859e-05, 'epoch': 12.09}\n",
      "{'loss': 2.2768, 'learning_rate': 1.146170684400111e-05, 'epoch': 12.11}\n",
      "{'loss': 2.2614, 'learning_rate': 1.1447852590745361e-05, 'epoch': 12.13}\n",
      "{'loss': 2.2779, 'learning_rate': 1.1434026045996122e-05, 'epoch': 12.14}\n",
      "{'loss': 2.2793, 'learning_rate': 1.1420171792740373e-05, 'epoch': 12.16}\n",
      "{'loss': 2.2657, 'learning_rate': 1.1406317539484625e-05, 'epoch': 12.17}\n",
      "{'loss': 2.2874, 'learning_rate': 1.1392463286228874e-05, 'epoch': 12.19}\n",
      "{'loss': 2.2665, 'learning_rate': 1.1378609032973125e-05, 'epoch': 12.2}\n",
      "{'loss': 2.2834, 'learning_rate': 1.1364754779717375e-05, 'epoch': 12.22}\n",
      "{'loss': 2.2742, 'learning_rate': 1.1350900526461626e-05, 'epoch': 12.24}\n",
      "{'loss': 2.2679, 'learning_rate': 1.1337046273205877e-05, 'epoch': 12.25}\n",
      "{'loss': 2.2751, 'learning_rate': 1.1323219728456638e-05, 'epoch': 12.27}\n",
      "{'loss': 2.2634, 'learning_rate': 1.1309365475200889e-05, 'epoch': 12.28}\n",
      "{'loss': 2.2805, 'learning_rate': 1.1295511221945138e-05, 'epoch': 12.3}\n",
      "{'loss': 2.2691, 'learning_rate': 1.128165696868939e-05, 'epoch': 12.31}\n",
      "{'loss': 2.282, 'learning_rate': 1.1267830423940152e-05, 'epoch': 12.33}\n",
      "{'loss': 2.2787, 'learning_rate': 1.1254003879190913e-05, 'epoch': 12.34}\n",
      "{'loss': 2.3031, 'learning_rate': 1.1240149625935164e-05, 'epoch': 12.36}\n",
      "{'loss': 2.2711, 'learning_rate': 1.1226295372679414e-05, 'epoch': 12.38}\n",
      "{'loss': 2.2501, 'learning_rate': 1.1212441119423665e-05, 'epoch': 12.39}\n",
      "{'loss': 2.2698, 'learning_rate': 1.1198586866167916e-05, 'epoch': 12.41}\n",
      "{'loss': 2.2742, 'learning_rate': 1.1184760321418677e-05, 'epoch': 12.42}\n",
      "{'loss': 2.2832, 'learning_rate': 1.1170906068162928e-05, 'epoch': 12.44}\n",
      "{'loss': 2.2833, 'learning_rate': 1.1157051814907178e-05, 'epoch': 12.45}\n",
      "{'loss': 2.3048, 'learning_rate': 1.1143197561651429e-05, 'epoch': 12.47}\n",
      "{'loss': 2.2588, 'learning_rate': 1.112934330839568e-05, 'epoch': 12.48}\n",
      "{'loss': 2.2774, 'learning_rate': 1.111548905513993e-05, 'epoch': 12.5}\n",
      "{'loss': 2.252, 'learning_rate': 1.1101662510390692e-05, 'epoch': 12.52}\n",
      "{'loss': 2.2816, 'learning_rate': 1.1087808257134941e-05, 'epoch': 12.53}\n",
      "{'loss': 2.271, 'learning_rate': 1.1073954003879193e-05, 'epoch': 12.55}\n",
      "{'loss': 2.2528, 'learning_rate': 1.1060099750623444e-05, 'epoch': 12.56}\n",
      "{'loss': 2.2676, 'learning_rate': 1.1046245497367693e-05, 'epoch': 12.58}\n",
      "{'loss': 2.2674, 'learning_rate': 1.1032391244111944e-05, 'epoch': 12.59}\n",
      "{'loss': 2.2568, 'learning_rate': 1.1018564699362705e-05, 'epoch': 12.61}\n",
      "{'loss': 2.2669, 'learning_rate': 1.1004710446106956e-05, 'epoch': 12.62}\n",
      "{'loss': 2.2567, 'learning_rate': 1.0990856192851208e-05, 'epoch': 12.64}\n",
      "{'loss': 2.2671, 'learning_rate': 1.0977001939595457e-05, 'epoch': 12.66}\n",
      "{'loss': 2.2713, 'learning_rate': 1.0963147686339708e-05, 'epoch': 12.67}\n",
      "{'loss': 2.2631, 'learning_rate': 1.0949321141590469e-05, 'epoch': 12.69}\n",
      "{'loss': 2.2702, 'learning_rate': 1.093546688833472e-05, 'epoch': 12.7}\n",
      "{'loss': 2.2871, 'learning_rate': 1.0921612635078971e-05, 'epoch': 12.72}\n",
      "{'loss': 2.2612, 'learning_rate': 1.090775838182322e-05, 'epoch': 12.73}\n",
      "{'loss': 2.2701, 'learning_rate': 1.0893904128567472e-05, 'epoch': 12.75}\n",
      "{'loss': 2.2733, 'learning_rate': 1.0880049875311721e-05, 'epoch': 12.76}\n",
      "{'loss': 2.2668, 'learning_rate': 1.0866195622055973e-05, 'epoch': 12.78}\n",
      "{'loss': 2.2777, 'learning_rate': 1.0852341368800224e-05, 'epoch': 12.8}\n",
      "{'loss': 2.2508, 'learning_rate': 1.0838514824050985e-05, 'epoch': 12.81}\n",
      "{'loss': 2.2731, 'learning_rate': 1.0824660570795236e-05, 'epoch': 12.83}\n",
      "{'loss': 2.2469, 'learning_rate': 1.0810806317539487e-05, 'epoch': 12.84}\n",
      "{'loss': 2.2606, 'learning_rate': 1.0796952064283736e-05, 'epoch': 12.86}\n",
      "{'loss': 2.2914, 'learning_rate': 1.078315322804101e-05, 'epoch': 12.87}\n",
      "{'loss': 2.265, 'learning_rate': 1.076929897478526e-05, 'epoch': 12.89}\n",
      "{'loss': 2.2492, 'learning_rate': 1.0755444721529511e-05, 'epoch': 12.91}\n",
      "{'loss': 2.2623, 'learning_rate': 1.0741590468273762e-05, 'epoch': 12.92}\n",
      "{'loss': 2.2522, 'learning_rate': 1.0727736215018012e-05, 'epoch': 12.94}\n",
      "{'loss': 2.2633, 'learning_rate': 1.0713909670268774e-05, 'epoch': 12.95}\n",
      "{'loss': 2.2756, 'learning_rate': 1.0700055417013024e-05, 'epoch': 12.97}\n",
      "{'loss': 2.2598, 'learning_rate': 1.0686201163757275e-05, 'epoch': 12.98}\n",
      "{'loss': 2.2631, 'learning_rate': 1.0672346910501526e-05, 'epoch': 13.0}\n",
      "{'loss': 2.2701, 'learning_rate': 1.0658492657245776e-05, 'epoch': 13.01}\n",
      "{'loss': 2.2504, 'learning_rate': 1.0644638403990027e-05, 'epoch': 13.03}\n",
      "{'loss': 2.273, 'learning_rate': 1.0630784150734276e-05, 'epoch': 13.05}\n",
      "{'loss': 2.255, 'learning_rate': 1.0616929897478527e-05, 'epoch': 13.06}\n",
      "{'loss': 2.2634, 'learning_rate': 1.060310335272929e-05, 'epoch': 13.08}\n",
      "{'loss': 2.2602, 'learning_rate': 1.058927680798005e-05, 'epoch': 13.09}\n",
      "{'loss': 2.2623, 'learning_rate': 1.0575422554724302e-05, 'epoch': 13.11}\n",
      "{'loss': 2.264, 'learning_rate': 1.0561568301468551e-05, 'epoch': 13.12}\n",
      "{'loss': 2.2537, 'learning_rate': 1.0547714048212803e-05, 'epoch': 13.14}\n",
      "{'loss': 2.2493, 'learning_rate': 1.0533887503463565e-05, 'epoch': 13.15}\n",
      "{'loss': 2.2528, 'learning_rate': 1.0520033250207815e-05, 'epoch': 13.17}\n",
      "{'loss': 2.2503, 'learning_rate': 1.0506178996952066e-05, 'epoch': 13.19}\n",
      "{'loss': 2.2659, 'learning_rate': 1.0492324743696315e-05, 'epoch': 13.2}\n",
      "{'loss': 2.2696, 'learning_rate': 1.0478470490440566e-05, 'epoch': 13.22}\n",
      "{'loss': 2.2501, 'learning_rate': 1.0464616237184818e-05, 'epoch': 13.23}\n",
      "{'loss': 2.246, 'learning_rate': 1.0450761983929067e-05, 'epoch': 13.25}\n",
      "{'loss': 2.2921, 'learning_rate': 1.0436907730673318e-05, 'epoch': 13.26}\n",
      "{'loss': 2.2537, 'learning_rate': 1.0423081185924079e-05, 'epoch': 13.28}\n",
      "{'loss': 2.2423, 'learning_rate': 1.040922693266833e-05, 'epoch': 13.29}\n",
      "{'loss': 2.2569, 'learning_rate': 1.0395372679412581e-05, 'epoch': 13.31}\n",
      "{'loss': 2.2759, 'learning_rate': 1.0381518426156831e-05, 'epoch': 13.33}\n",
      "{'loss': 2.2613, 'learning_rate': 1.0367664172901082e-05, 'epoch': 13.34}\n",
      "{'loss': 2.2592, 'learning_rate': 1.0353837628151845e-05, 'epoch': 13.36}\n",
      "{'loss': 2.2499, 'learning_rate': 1.0339983374896094e-05, 'epoch': 13.37}\n",
      "{'loss': 2.2654, 'learning_rate': 1.0326129121640345e-05, 'epoch': 13.39}\n",
      "{'loss': 2.2524, 'learning_rate': 1.0312274868384595e-05, 'epoch': 13.4}\n",
      "{'loss': 2.2506, 'learning_rate': 1.0298420615128846e-05, 'epoch': 13.42}\n",
      "{'loss': 2.2606, 'learning_rate': 1.0284566361873097e-05, 'epoch': 13.44}\n",
      "{'loss': 2.2462, 'learning_rate': 1.0270712108617346e-05, 'epoch': 13.45}\n",
      "{'loss': 2.2601, 'learning_rate': 1.0256857855361598e-05, 'epoch': 13.47}\n",
      "{'loss': 2.2685, 'learning_rate': 1.0243031310612359e-05, 'epoch': 13.48}\n",
      "{'loss': 2.2561, 'learning_rate': 1.0229204765863121e-05, 'epoch': 13.5}\n",
      "{'loss': 2.2615, 'learning_rate': 1.0215350512607372e-05, 'epoch': 13.51}\n",
      "{'loss': 2.2502, 'learning_rate': 1.0201496259351622e-05, 'epoch': 13.53}\n",
      "{'loss': 2.2371, 'learning_rate': 1.0187642006095873e-05, 'epoch': 13.54}\n",
      "{'loss': 2.2395, 'learning_rate': 1.0173787752840122e-05, 'epoch': 13.56}\n",
      "{'loss': 2.2464, 'learning_rate': 1.0159933499584374e-05, 'epoch': 13.58}\n",
      "{'loss': 2.257, 'learning_rate': 1.0146106954835136e-05, 'epoch': 13.59}\n",
      "{'loss': 2.2613, 'learning_rate': 1.0132252701579386e-05, 'epoch': 13.61}\n",
      "{'loss': 2.2779, 'learning_rate': 1.0118398448323637e-05, 'epoch': 13.62}\n",
      "{'loss': 2.2615, 'learning_rate': 1.0104544195067886e-05, 'epoch': 13.64}\n",
      "{'loss': 2.2479, 'learning_rate': 1.0090689941812137e-05, 'epoch': 13.65}\n",
      "{'loss': 2.2509, 'learning_rate': 1.0076835688556389e-05, 'epoch': 13.67}\n",
      "{'loss': 2.2569, 'learning_rate': 1.0062981435300638e-05, 'epoch': 13.68}\n",
      "{'loss': 2.2478, 'learning_rate': 1.0049127182044889e-05, 'epoch': 13.7}\n",
      "{'loss': 2.2525, 'learning_rate': 1.003530063729565e-05, 'epoch': 13.72}\n",
      "{'loss': 2.2445, 'learning_rate': 1.0021446384039901e-05, 'epoch': 13.73}\n",
      "{'loss': 2.2506, 'learning_rate': 1.0007592130784152e-05, 'epoch': 13.75}\n",
      "{'loss': 2.2612, 'learning_rate': 9.993737877528402e-06, 'epoch': 13.76}\n",
      "{'loss': 2.2552, 'learning_rate': 9.979911332779164e-06, 'epoch': 13.78}\n",
      "{'loss': 2.2525, 'learning_rate': 9.966057079523414e-06, 'epoch': 13.79}\n",
      "{'loss': 2.2452, 'learning_rate': 9.952202826267665e-06, 'epoch': 13.81}\n",
      "{'loss': 2.2515, 'learning_rate': 9.938348573011916e-06, 'epoch': 13.82}\n",
      "{'loss': 2.2359, 'learning_rate': 9.924522028262677e-06, 'epoch': 13.84}\n",
      "{'loss': 2.2648, 'learning_rate': 9.910667775006928e-06, 'epoch': 13.86}\n",
      "{'loss': 2.2443, 'learning_rate': 9.896813521751178e-06, 'epoch': 13.87}\n",
      "{'loss': 2.2508, 'learning_rate': 9.882959268495429e-06, 'epoch': 13.89}\n",
      "{'loss': 2.2606, 'learning_rate': 9.869132723746191e-06, 'epoch': 13.9}\n",
      "{'loss': 2.2633, 'learning_rate': 9.855278470490441e-06, 'epoch': 13.92}\n",
      "{'loss': 2.2544, 'learning_rate': 9.841424217234692e-06, 'epoch': 13.93}\n",
      "{'loss': 2.2518, 'learning_rate': 9.827569963978942e-06, 'epoch': 13.95}\n",
      "{'loss': 2.2614, 'learning_rate': 9.813743419229704e-06, 'epoch': 13.97}\n",
      "{'loss': 2.2598, 'learning_rate': 9.799889165973955e-06, 'epoch': 13.98}\n",
      "{'loss': 2.2494, 'learning_rate': 9.786034912718205e-06, 'epoch': 14.0}\n",
      "{'loss': 2.2428, 'learning_rate': 9.772180659462456e-06, 'epoch': 14.01}\n",
      "{'loss': 2.2533, 'learning_rate': 9.758354114713218e-06, 'epoch': 14.03}\n",
      "{'loss': 2.2262, 'learning_rate': 9.744499861457468e-06, 'epoch': 14.04}\n",
      "{'loss': 2.2614, 'learning_rate': 9.730645608201719e-06, 'epoch': 14.06}\n",
      "{'loss': 2.2385, 'learning_rate': 9.716791354945969e-06, 'epoch': 14.07}\n",
      "{'loss': 2.2297, 'learning_rate': 9.70293710169022e-06, 'epoch': 14.09}\n",
      "{'loss': 2.2653, 'learning_rate': 9.689082848434471e-06, 'epoch': 14.11}\n",
      "{'loss': 2.2427, 'learning_rate': 9.67522859517872e-06, 'epoch': 14.12}\n",
      "{'loss': 2.2248, 'learning_rate': 9.661374341922972e-06, 'epoch': 14.14}\n",
      "{'loss': 2.2402, 'learning_rate': 9.647547797173732e-06, 'epoch': 14.15}\n",
      "{'loss': 2.2469, 'learning_rate': 9.633693543917984e-06, 'epoch': 14.17}\n",
      "{'loss': 2.2584, 'learning_rate': 9.619839290662235e-06, 'epoch': 14.18}\n",
      "{'loss': 2.2551, 'learning_rate': 9.606012745912996e-06, 'epoch': 14.2}\n",
      "{'loss': 2.2457, 'learning_rate': 9.592158492657247e-06, 'epoch': 14.21}\n",
      "{'loss': 2.2433, 'learning_rate': 9.578304239401496e-06, 'epoch': 14.23}\n",
      "{'loss': 2.2627, 'learning_rate': 9.564449986145747e-06, 'epoch': 14.25}\n",
      "{'loss': 2.2131, 'learning_rate': 9.550595732889999e-06, 'epoch': 14.26}\n",
      "{'loss': 2.2469, 'learning_rate': 9.536741479634248e-06, 'epoch': 14.28}\n",
      "{'loss': 2.2571, 'learning_rate': 9.5228872263785e-06, 'epoch': 14.29}\n",
      "{'loss': 2.2503, 'learning_rate': 9.509032973122749e-06, 'epoch': 14.31}\n",
      "{'loss': 2.238, 'learning_rate': 9.495206428373511e-06, 'epoch': 14.32}\n",
      "{'loss': 2.2317, 'learning_rate': 9.481379883624274e-06, 'epoch': 14.34}\n",
      "{'loss': 2.2372, 'learning_rate': 9.467525630368523e-06, 'epoch': 14.35}\n",
      "{'loss': 2.2364, 'learning_rate': 9.453671377112774e-06, 'epoch': 14.37}\n",
      "{'loss': 2.2346, 'learning_rate': 9.439817123857024e-06, 'epoch': 14.39}\n",
      "{'loss': 2.2462, 'learning_rate': 9.425962870601275e-06, 'epoch': 14.4}\n",
      "{'loss': 2.235, 'learning_rate': 9.412108617345526e-06, 'epoch': 14.42}\n",
      "{'loss': 2.2185, 'learning_rate': 9.398254364089776e-06, 'epoch': 14.43}\n",
      "{'loss': 2.2274, 'learning_rate': 9.384400110834027e-06, 'epoch': 14.45}\n",
      "{'loss': 2.249, 'learning_rate': 9.370573566084788e-06, 'epoch': 14.46}\n",
      "{'loss': 2.2487, 'learning_rate': 9.356719312829039e-06, 'epoch': 14.48}\n",
      "{'loss': 2.2356, 'learning_rate': 9.34286505957329e-06, 'epoch': 14.5}\n",
      "{'loss': 2.2393, 'learning_rate': 9.32901080631754e-06, 'epoch': 14.51}\n",
      "{'loss': 2.2649, 'learning_rate': 9.31515655306179e-06, 'epoch': 14.53}\n",
      "{'loss': 2.2372, 'learning_rate': 9.301330008312552e-06, 'epoch': 14.54}\n",
      "{'loss': 2.2584, 'learning_rate': 9.287475755056803e-06, 'epoch': 14.56}\n",
      "{'loss': 2.2363, 'learning_rate': 9.273621501801054e-06, 'epoch': 14.57}\n",
      "{'loss': 2.2669, 'learning_rate': 9.259794957051815e-06, 'epoch': 14.59}\n",
      "{'loss': 2.2457, 'learning_rate': 9.245940703796066e-06, 'epoch': 14.6}\n",
      "{'loss': 2.2206, 'learning_rate': 9.232086450540317e-06, 'epoch': 14.62}\n",
      "{'loss': 2.226, 'learning_rate': 9.218232197284567e-06, 'epoch': 14.64}\n",
      "{'loss': 2.2265, 'learning_rate': 9.204377944028818e-06, 'epoch': 14.65}\n",
      "{'loss': 2.229, 'learning_rate': 9.190523690773067e-06, 'epoch': 14.67}\n",
      "{'loss': 2.2426, 'learning_rate': 9.176669437517318e-06, 'epoch': 14.68}\n",
      "{'loss': 2.2459, 'learning_rate': 9.16281518426157e-06, 'epoch': 14.7}\n",
      "{'loss': 2.2528, 'learning_rate': 9.14898863951233e-06, 'epoch': 14.71}\n",
      "{'loss': 2.2287, 'learning_rate': 9.135134386256582e-06, 'epoch': 14.73}\n",
      "{'loss': 2.2352, 'learning_rate': 9.121280133000831e-06, 'epoch': 14.74}\n",
      "{'loss': 2.244, 'learning_rate': 9.107425879745082e-06, 'epoch': 14.76}\n",
      "{'loss': 2.2635, 'learning_rate': 9.093571626489333e-06, 'epoch': 14.78}\n",
      "{'loss': 2.2366, 'learning_rate': 9.079772790246606e-06, 'epoch': 14.79}\n",
      "{'loss': 2.2373, 'learning_rate': 9.065918536990857e-06, 'epoch': 14.81}\n",
      "{'loss': 2.2448, 'learning_rate': 9.052064283735106e-06, 'epoch': 14.82}\n",
      "{'loss': 2.2403, 'learning_rate': 9.038210030479357e-06, 'epoch': 14.84}\n",
      "{'loss': 2.2417, 'learning_rate': 9.024355777223609e-06, 'epoch': 14.85}\n",
      "{'loss': 2.2314, 'learning_rate': 9.010501523967858e-06, 'epoch': 14.87}\n",
      "{'loss': 2.2451, 'learning_rate': 8.99664727071211e-06, 'epoch': 14.88}\n",
      "{'loss': 2.2368, 'learning_rate': 8.982793017456359e-06, 'epoch': 14.9}\n",
      "{'loss': 2.2057, 'learning_rate': 8.968966472707121e-06, 'epoch': 14.92}\n",
      "{'loss': 2.2416, 'learning_rate': 8.955112219451372e-06, 'epoch': 14.93}\n",
      "{'loss': 2.2602, 'learning_rate': 8.941257966195622e-06, 'epoch': 14.95}\n",
      "{'loss': 2.237, 'learning_rate': 8.927403712939873e-06, 'epoch': 14.96}\n",
      "{'loss': 2.2578, 'learning_rate': 8.913549459684122e-06, 'epoch': 14.98}\n",
      "{'loss': 2.2648, 'learning_rate': 8.899722914934887e-06, 'epoch': 14.99}\n",
      "{'loss': 2.2437, 'learning_rate': 8.885868661679136e-06, 'epoch': 15.01}\n",
      "{'loss': 2.2296, 'learning_rate': 8.872042116929899e-06, 'epoch': 15.02}\n",
      "{'loss': 2.2426, 'learning_rate': 8.85818786367415e-06, 'epoch': 15.04}\n",
      "{'loss': 2.2537, 'learning_rate': 8.8443336104184e-06, 'epoch': 15.06}\n",
      "{'loss': 2.2031, 'learning_rate': 8.83047935716265e-06, 'epoch': 15.07}\n",
      "{'loss': 2.2442, 'learning_rate': 8.8166251039069e-06, 'epoch': 15.09}\n",
      "{'loss': 2.2152, 'learning_rate': 8.802770850651151e-06, 'epoch': 15.1}\n",
      "{'loss': 2.231, 'learning_rate': 8.788916597395402e-06, 'epoch': 15.12}\n",
      "{'loss': 2.2248, 'learning_rate': 8.775062344139652e-06, 'epoch': 15.13}\n",
      "{'loss': 2.2311, 'learning_rate': 8.761235799390414e-06, 'epoch': 15.15}\n",
      "{'loss': 2.2386, 'learning_rate': 8.747381546134664e-06, 'epoch': 15.17}\n",
      "{'loss': 2.2215, 'learning_rate': 8.733527292878915e-06, 'epoch': 15.18}\n",
      "{'loss': 2.2381, 'learning_rate': 8.719673039623166e-06, 'epoch': 15.2}\n",
      "{'loss': 2.2208, 'learning_rate': 8.705846494873927e-06, 'epoch': 15.21}\n",
      "{'loss': 2.2337, 'learning_rate': 8.691992241618178e-06, 'epoch': 15.23}\n",
      "{'loss': 2.2329, 'learning_rate': 8.678137988362428e-06, 'epoch': 15.24}\n",
      "{'loss': 2.2412, 'learning_rate': 8.664283735106679e-06, 'epoch': 15.26}\n",
      "{'loss': 2.2443, 'learning_rate': 8.65042948185093e-06, 'epoch': 15.27}\n",
      "{'loss': 2.2328, 'learning_rate': 8.636630645608202e-06, 'epoch': 15.29}\n",
      "{'loss': 2.2197, 'learning_rate': 8.622776392352454e-06, 'epoch': 15.31}\n",
      "{'loss': 2.2241, 'learning_rate': 8.608922139096703e-06, 'epoch': 15.32}\n",
      "{'loss': 2.2275, 'learning_rate': 8.595067885840954e-06, 'epoch': 15.34}\n",
      "{'loss': 2.2311, 'learning_rate': 8.581213632585205e-06, 'epoch': 15.35}\n",
      "{'loss': 2.2351, 'learning_rate': 8.567359379329455e-06, 'epoch': 15.37}\n",
      "{'loss': 2.2199, 'learning_rate': 8.553505126073706e-06, 'epoch': 15.38}\n",
      "{'loss': 2.2455, 'learning_rate': 8.539650872817955e-06, 'epoch': 15.4}\n",
      "{'loss': 2.2264, 'learning_rate': 8.525824328068718e-06, 'epoch': 15.41}\n",
      "{'loss': 2.2128, 'learning_rate': 8.51197007481297e-06, 'epoch': 15.43}\n",
      "{'loss': 2.2331, 'learning_rate': 8.498115821557219e-06, 'epoch': 15.45}\n",
      "{'loss': 2.2281, 'learning_rate': 8.48426156830147e-06, 'epoch': 15.46}\n",
      "{'loss': 2.2268, 'learning_rate': 8.47040731504572e-06, 'epoch': 15.48}\n",
      "{'loss': 2.2505, 'learning_rate': 8.45655306178997e-06, 'epoch': 15.49}\n",
      "{'loss': 2.2275, 'learning_rate': 8.442698808534222e-06, 'epoch': 15.51}\n",
      "{'loss': 2.233, 'learning_rate': 8.428844555278471e-06, 'epoch': 15.52}\n",
      "{'loss': 2.2211, 'learning_rate': 8.415018010529234e-06, 'epoch': 15.54}\n",
      "{'loss': 2.2119, 'learning_rate': 8.401163757273483e-06, 'epoch': 15.55}\n",
      "{'loss': 2.2267, 'learning_rate': 8.387309504017734e-06, 'epoch': 15.57}\n",
      "{'loss': 2.219, 'learning_rate': 8.373455250761985e-06, 'epoch': 15.59}\n",
      "{'loss': 2.2161, 'learning_rate': 8.359600997506235e-06, 'epoch': 15.6}\n",
      "{'loss': 2.2431, 'learning_rate': 8.345774452756997e-06, 'epoch': 15.62}\n",
      "{'loss': 2.2404, 'learning_rate': 8.331920199501249e-06, 'epoch': 15.63}\n",
      "{'loss': 2.221, 'learning_rate': 8.31809365475201e-06, 'epoch': 15.65}\n",
      "{'loss': 2.2195, 'learning_rate': 8.30423940149626e-06, 'epoch': 15.66}\n",
      "{'loss': 2.2442, 'learning_rate': 8.29038514824051e-06, 'epoch': 15.68}\n",
      "{'loss': 2.2438, 'learning_rate': 8.276530894984761e-06, 'epoch': 15.7}\n",
      "{'loss': 2.2212, 'learning_rate': 8.262676641729012e-06, 'epoch': 15.71}\n",
      "{'loss': 2.2099, 'learning_rate': 8.248822388473262e-06, 'epoch': 15.73}\n",
      "{'loss': 2.2157, 'learning_rate': 8.234995843724024e-06, 'epoch': 15.74}\n",
      "{'loss': 2.2308, 'learning_rate': 8.221141590468274e-06, 'epoch': 15.76}\n",
      "{'loss': 2.2278, 'learning_rate': 8.207287337212525e-06, 'epoch': 15.77}\n",
      "{'loss': 2.2206, 'learning_rate': 8.193433083956776e-06, 'epoch': 15.79}\n",
      "{'loss': 2.2051, 'learning_rate': 8.179578830701026e-06, 'epoch': 15.8}\n",
      "{'loss': 2.2208, 'learning_rate': 8.165724577445277e-06, 'epoch': 15.82}\n",
      "{'loss': 2.2398, 'learning_rate': 8.151870324189526e-06, 'epoch': 15.84}\n",
      "{'loss': 2.2287, 'learning_rate': 8.138016070933777e-06, 'epoch': 15.85}\n",
      "{'loss': 2.222, 'learning_rate': 8.12418952618454e-06, 'epoch': 15.87}\n",
      "{'loss': 2.223, 'learning_rate': 8.11033527292879e-06, 'epoch': 15.88}\n",
      "{'loss': 2.2343, 'learning_rate': 8.09648101967304e-06, 'epoch': 15.9}\n",
      "{'loss': 2.2491, 'learning_rate': 8.08262676641729e-06, 'epoch': 15.91}\n",
      "{'loss': 2.2264, 'learning_rate': 8.068772513161541e-06, 'epoch': 15.93}\n",
      "{'loss': 2.2337, 'learning_rate': 8.054918259905792e-06, 'epoch': 15.94}\n",
      "{'loss': 2.2387, 'learning_rate': 8.041064006650042e-06, 'epoch': 15.96}\n",
      "{'loss': 2.2378, 'learning_rate': 8.027209753394293e-06, 'epoch': 15.98}\n",
      "{'loss': 2.2376, 'learning_rate': 8.013383208645054e-06, 'epoch': 15.99}\n",
      "{'loss': 2.2397, 'learning_rate': 7.999528955389305e-06, 'epoch': 16.01}\n",
      "{'loss': 2.246, 'learning_rate': 7.985702410640068e-06, 'epoch': 16.02}\n",
      "{'loss': 2.2397, 'learning_rate': 7.971848157384317e-06, 'epoch': 16.04}\n",
      "{'loss': 2.2045, 'learning_rate': 7.957993904128568e-06, 'epoch': 16.05}\n",
      "{'loss': 2.2367, 'learning_rate': 7.944139650872818e-06, 'epoch': 16.07}\n",
      "{'loss': 2.22, 'learning_rate': 7.930285397617069e-06, 'epoch': 16.08}\n",
      "{'loss': 2.2275, 'learning_rate': 7.91643114436132e-06, 'epoch': 16.1}\n",
      "{'loss': 2.2102, 'learning_rate': 7.902604599612081e-06, 'epoch': 16.12}\n",
      "{'loss': 2.2576, 'learning_rate': 7.888750346356332e-06, 'epoch': 16.13}\n",
      "{'loss': 2.2329, 'learning_rate': 7.874896093100582e-06, 'epoch': 16.15}\n",
      "{'loss': 2.2236, 'learning_rate': 7.861041839844833e-06, 'epoch': 16.16}\n",
      "{'loss': 2.2227, 'learning_rate': 7.847187586589084e-06, 'epoch': 16.18}\n",
      "{'loss': 2.2125, 'learning_rate': 7.833333333333333e-06, 'epoch': 16.19}\n",
      "{'loss': 2.2185, 'learning_rate': 7.819479080077585e-06, 'epoch': 16.21}\n",
      "{'loss': 2.2129, 'learning_rate': 7.805624826821834e-06, 'epoch': 16.23}\n",
      "{'loss': 2.2311, 'learning_rate': 7.791798282072597e-06, 'epoch': 16.24}\n",
      "{'loss': 2.2445, 'learning_rate': 7.777944028816848e-06, 'epoch': 16.26}\n",
      "{'loss': 2.2121, 'learning_rate': 7.764089775561097e-06, 'epoch': 16.27}\n",
      "{'loss': 2.2288, 'learning_rate': 7.750235522305348e-06, 'epoch': 16.29}\n",
      "{'loss': 2.2091, 'learning_rate': 7.736408977556111e-06, 'epoch': 16.3}\n",
      "{'loss': 2.2211, 'learning_rate': 7.72255472430036e-06, 'epoch': 16.32}\n",
      "{'loss': 2.2141, 'learning_rate': 7.708700471044612e-06, 'epoch': 16.33}\n",
      "{'loss': 2.2216, 'learning_rate': 7.694846217788861e-06, 'epoch': 16.35}\n",
      "{'loss': 2.2039, 'learning_rate': 7.681019673039624e-06, 'epoch': 16.37}\n",
      "{'loss': 2.22, 'learning_rate': 7.667165419783875e-06, 'epoch': 16.38}\n",
      "{'loss': 2.2181, 'learning_rate': 7.653311166528124e-06, 'epoch': 16.4}\n",
      "{'loss': 2.2329, 'learning_rate': 7.639456913272375e-06, 'epoch': 16.41}\n",
      "{'loss': 2.2023, 'learning_rate': 7.625602660016626e-06, 'epoch': 16.43}\n",
      "{'loss': 2.2164, 'learning_rate': 7.611748406760876e-06, 'epoch': 16.44}\n",
      "{'loss': 2.2103, 'learning_rate': 7.597894153505126e-06, 'epoch': 16.46}\n",
      "{'loss': 2.2184, 'learning_rate': 7.584067608755888e-06, 'epoch': 16.47}\n",
      "{'loss': 2.219, 'learning_rate': 7.570213355500139e-06, 'epoch': 16.49}\n",
      "{'loss': 2.2199, 'learning_rate': 7.55635910224439e-06, 'epoch': 16.51}\n",
      "{'loss': 2.2291, 'learning_rate': 7.54250484898864e-06, 'epoch': 16.52}\n",
      "{'loss': 2.2202, 'learning_rate': 7.52865059573289e-06, 'epoch': 16.54}\n",
      "{'loss': 2.2285, 'learning_rate': 7.5147963424771405e-06, 'epoch': 16.55}\n",
      "{'loss': 2.2029, 'learning_rate': 7.500969797727903e-06, 'epoch': 16.57}\n",
      "{'loss': 2.2339, 'learning_rate': 7.4871155444721534e-06, 'epoch': 16.58}\n",
      "{'loss': 2.2209, 'learning_rate': 7.473261291216404e-06, 'epoch': 16.6}\n",
      "{'loss': 2.2096, 'learning_rate': 7.459407037960654e-06, 'epoch': 16.61}\n",
      "{'loss': 2.2237, 'learning_rate': 7.445552784704904e-06, 'epoch': 16.63}\n",
      "{'loss': 2.2317, 'learning_rate': 7.4316985314491555e-06, 'epoch': 16.65}\n",
      "{'loss': 2.1954, 'learning_rate': 7.417844278193406e-06, 'epoch': 16.66}\n",
      "{'loss': 2.211, 'learning_rate': 7.403990024937656e-06, 'epoch': 16.68}\n",
      "{'loss': 2.2229, 'learning_rate': 7.390163480188418e-06, 'epoch': 16.69}\n",
      "{'loss': 2.2059, 'learning_rate': 7.376309226932668e-06, 'epoch': 16.71}\n",
      "{'loss': 2.2313, 'learning_rate': 7.362454973676919e-06, 'epoch': 16.72}\n",
      "{'loss': 2.2139, 'learning_rate': 7.34860072042117e-06, 'epoch': 16.74}\n",
      "{'loss': 2.2191, 'learning_rate': 7.33474646716542e-06, 'epoch': 16.75}\n",
      "{'loss': 2.2069, 'learning_rate': 7.32089221390967e-06, 'epoch': 16.77}\n",
      "{'loss': 2.1997, 'learning_rate': 7.307037960653921e-06, 'epoch': 16.79}\n",
      "{'loss': 2.2004, 'learning_rate': 7.293183707398172e-06, 'epoch': 16.8}\n",
      "{'loss': 2.2155, 'learning_rate': 7.2793571626489335e-06, 'epoch': 16.82}\n",
      "{'loss': 2.2234, 'learning_rate': 7.265502909393184e-06, 'epoch': 16.83}\n",
      "{'loss': 2.2164, 'learning_rate': 7.251648656137434e-06, 'epoch': 16.85}\n",
      "{'loss': 2.2028, 'learning_rate': 7.237794402881685e-06, 'epoch': 16.86}\n",
      "{'loss': 2.2168, 'learning_rate': 7.223967858132447e-06, 'epoch': 16.88}\n",
      "{'loss': 2.2189, 'learning_rate': 7.210113604876697e-06, 'epoch': 16.9}\n",
      "{'loss': 2.2075, 'learning_rate': 7.196259351620948e-06, 'epoch': 16.91}\n",
      "{'loss': 2.2109, 'learning_rate': 7.182405098365198e-06, 'epoch': 16.93}\n",
      "{'loss': 2.2008, 'learning_rate': 7.1685785536159605e-06, 'epoch': 16.94}\n",
      "{'loss': 2.2366, 'learning_rate': 7.154724300360211e-06, 'epoch': 16.96}\n",
      "{'loss': 2.2057, 'learning_rate': 7.140870047104461e-06, 'epoch': 16.97}\n",
      "{'loss': 2.2317, 'learning_rate': 7.127043502355223e-06, 'epoch': 16.99}\n",
      "{'loss': 2.2271, 'learning_rate': 7.113189249099473e-06, 'epoch': 17.0}\n",
      "{'loss': 2.2135, 'learning_rate': 7.099334995843724e-06, 'epoch': 17.02}\n",
      "{'loss': 2.2059, 'learning_rate': 7.085480742587975e-06, 'epoch': 17.04}\n",
      "{'loss': 2.2124, 'learning_rate': 7.071626489332225e-06, 'epoch': 17.05}\n",
      "{'loss': 2.2035, 'learning_rate': 7.057772236076475e-06, 'epoch': 17.07}\n",
      "{'loss': 2.2173, 'learning_rate': 7.043917982820726e-06, 'epoch': 17.08}\n",
      "{'loss': 2.2216, 'learning_rate': 7.030063729564977e-06, 'epoch': 17.1}\n",
      "{'loss': 2.2095, 'learning_rate': 7.0162371848157385e-06, 'epoch': 17.11}\n",
      "{'loss': 2.2027, 'learning_rate': 7.002382931559989e-06, 'epoch': 17.13}\n",
      "{'loss': 2.2075, 'learning_rate': 6.988528678304239e-06, 'epoch': 17.14}\n",
      "{'loss': 2.2119, 'learning_rate': 6.97467442504849e-06, 'epoch': 17.16}\n",
      "{'loss': 2.2115, 'learning_rate': 6.960847880299253e-06, 'epoch': 17.18}\n",
      "{'loss': 2.2067, 'learning_rate': 6.946993627043503e-06, 'epoch': 17.19}\n",
      "{'loss': 2.2215, 'learning_rate': 6.9331393737877535e-06, 'epoch': 17.21}\n",
      "{'loss': 2.2027, 'learning_rate': 6.919285120532005e-06, 'epoch': 17.22}\n",
      "{'loss': 2.2009, 'learning_rate': 6.905430867276255e-06, 'epoch': 17.24}\n",
      "{'loss': 2.2045, 'learning_rate': 6.891632031033528e-06, 'epoch': 17.25}\n",
      "{'loss': 2.2061, 'learning_rate': 6.8777777777777785e-06, 'epoch': 17.27}\n",
      "{'loss': 2.2357, 'learning_rate': 6.86392352452203e-06, 'epoch': 17.28}\n",
      "{'loss': 2.1945, 'learning_rate': 6.85006927126628e-06, 'epoch': 17.3}\n",
      "{'loss': 2.1951, 'learning_rate': 6.83621501801053e-06, 'epoch': 17.32}\n",
      "{'loss': 2.2099, 'learning_rate': 6.8223607647547805e-06, 'epoch': 17.33}\n",
      "{'loss': 2.2144, 'learning_rate': 6.808506511499031e-06, 'epoch': 17.35}\n",
      "{'loss': 2.2266, 'learning_rate': 6.7946799667497935e-06, 'epoch': 17.36}\n",
      "{'loss': 2.2083, 'learning_rate': 6.780825713494044e-06, 'epoch': 17.38}\n",
      "{'loss': 2.197, 'learning_rate': 6.766971460238294e-06, 'epoch': 17.39}\n",
      "{'loss': 2.2257, 'learning_rate': 6.753117206982544e-06, 'epoch': 17.41}\n",
      "{'loss': 2.2216, 'learning_rate': 6.739262953726795e-06, 'epoch': 17.43}\n",
      "{'loss': 2.2154, 'learning_rate': 6.725436408977557e-06, 'epoch': 17.44}\n",
      "{'loss': 2.2212, 'learning_rate': 6.711582155721808e-06, 'epoch': 17.46}\n",
      "{'loss': 2.2265, 'learning_rate': 6.697727902466058e-06, 'epoch': 17.47}\n",
      "{'loss': 2.2271, 'learning_rate': 6.683873649210308e-06, 'epoch': 17.49}\n",
      "{'loss': 2.1959, 'learning_rate': 6.6700193959545585e-06, 'epoch': 17.5}\n",
      "{'loss': 2.2125, 'learning_rate': 6.65616514269881e-06, 'epoch': 17.52}\n",
      "{'loss': 2.2025, 'learning_rate': 6.64231088944306e-06, 'epoch': 17.53}\n",
      "{'loss': 2.228, 'learning_rate': 6.62845663618731e-06, 'epoch': 17.55}\n",
      "{'loss': 2.2177, 'learning_rate': 6.6146577999445835e-06, 'epoch': 17.57}\n",
      "{'loss': 2.2173, 'learning_rate': 6.600803546688835e-06, 'epoch': 17.58}\n",
      "{'loss': 2.2077, 'learning_rate': 6.586949293433085e-06, 'epoch': 17.6}\n",
      "{'loss': 2.1933, 'learning_rate': 6.573095040177335e-06, 'epoch': 17.61}\n",
      "{'loss': 2.1814, 'learning_rate': 6.5592407869215856e-06, 'epoch': 17.63}\n",
      "{'loss': 2.2063, 'learning_rate': 6.545386533665836e-06, 'epoch': 17.64}\n",
      "{'loss': 2.1921, 'learning_rate': 6.531532280410087e-06, 'epoch': 17.66}\n",
      "{'loss': 2.1983, 'learning_rate': 6.517678027154337e-06, 'epoch': 17.67}\n",
      "{'loss': 2.198, 'learning_rate': 6.503851482405099e-06, 'epoch': 17.69}\n",
      "{'loss': 2.2107, 'learning_rate': 6.489997229149349e-06, 'epoch': 17.71}\n",
      "{'loss': 2.1949, 'learning_rate': 6.476170684400111e-06, 'epoch': 17.72}\n",
      "{'loss': 2.2033, 'learning_rate': 6.462316431144362e-06, 'epoch': 17.74}\n",
      "{'loss': 2.2074, 'learning_rate': 6.448462177888613e-06, 'epoch': 17.75}\n",
      "{'loss': 2.2049, 'learning_rate': 6.434607924632863e-06, 'epoch': 17.77}\n",
      "{'loss': 2.1934, 'learning_rate': 6.420753671377113e-06, 'epoch': 17.78}\n",
      "{'loss': 2.209, 'learning_rate': 6.4068994181213635e-06, 'epoch': 17.8}\n",
      "{'loss': 2.2042, 'learning_rate': 6.393045164865615e-06, 'epoch': 17.81}\n",
      "{'loss': 2.2054, 'learning_rate': 6.379190911609865e-06, 'epoch': 17.83}\n",
      "{'loss': 2.1932, 'learning_rate': 6.365364366860627e-06, 'epoch': 17.85}\n",
      "{'loss': 2.21, 'learning_rate': 6.351510113604877e-06, 'epoch': 17.86}\n",
      "{'loss': 2.2002, 'learning_rate': 6.337655860349128e-06, 'epoch': 17.88}\n",
      "{'loss': 2.2205, 'learning_rate': 6.3238016070933785e-06, 'epoch': 17.89}\n",
      "{'loss': 2.2005, 'learning_rate': 6.309947353837629e-06, 'epoch': 17.91}\n",
      "{'loss': 2.2062, 'learning_rate': 6.296093100581879e-06, 'epoch': 17.92}\n",
      "{'loss': 2.2122, 'learning_rate': 6.2822388473261295e-06, 'epoch': 17.94}\n",
      "{'loss': 2.2024, 'learning_rate': 6.268384594070381e-06, 'epoch': 17.96}\n",
      "{'loss': 2.215, 'learning_rate': 6.254558049321142e-06, 'epoch': 17.97}\n",
      "{'loss': 2.1887, 'learning_rate': 6.240703796065393e-06, 'epoch': 17.99}\n",
      "{'loss': 2.1919, 'learning_rate': 6.226849542809643e-06, 'epoch': 18.0}\n",
      "{'loss': 2.213, 'learning_rate': 6.213022998060405e-06, 'epoch': 18.02}\n",
      "{'loss': 2.2189, 'learning_rate': 6.199168744804656e-06, 'epoch': 18.03}\n",
      "{'loss': 2.1936, 'learning_rate': 6.185314491548906e-06, 'epoch': 18.05}\n",
      "{'loss': 2.2076, 'learning_rate': 6.1714602382931565e-06, 'epoch': 18.06}\n",
      "{'loss': 2.2006, 'learning_rate': 6.157605985037407e-06, 'epoch': 18.08}\n",
      "{'loss': 2.2009, 'learning_rate': 6.143751731781657e-06, 'epoch': 18.1}\n",
      "{'loss': 2.2109, 'learning_rate': 6.129897478525908e-06, 'epoch': 18.11}\n",
      "{'loss': 2.1744, 'learning_rate': 6.116043225270159e-06, 'epoch': 18.13}\n",
      "{'loss': 2.2004, 'learning_rate': 6.102188972014409e-06, 'epoch': 18.14}\n",
      "{'loss': 2.2281, 'learning_rate': 6.088362427265171e-06, 'epoch': 18.16}\n",
      "{'loss': 2.1981, 'learning_rate': 6.074508174009422e-06, 'epoch': 18.17}\n",
      "{'loss': 2.2017, 'learning_rate': 6.060653920753672e-06, 'epoch': 18.19}\n",
      "{'loss': 2.2051, 'learning_rate': 6.046799667497922e-06, 'epoch': 18.2}\n",
      "{'loss': 2.1965, 'learning_rate': 6.032973122748684e-06, 'epoch': 18.22}\n",
      "{'loss': 2.1991, 'learning_rate': 6.0191188694929345e-06, 'epoch': 18.24}\n",
      "{'loss': 2.1954, 'learning_rate': 6.005264616237186e-06, 'epoch': 18.25}\n",
      "{'loss': 2.2081, 'learning_rate': 5.991410362981436e-06, 'epoch': 18.27}\n",
      "{'loss': 2.2127, 'learning_rate': 5.977583818232198e-06, 'epoch': 18.28}\n",
      "{'loss': 2.2006, 'learning_rate': 5.963729564976448e-06, 'epoch': 18.3}\n",
      "{'loss': 2.2085, 'learning_rate': 5.949875311720698e-06, 'epoch': 18.31}\n",
      "{'loss': 2.1995, 'learning_rate': 5.9360210584649495e-06, 'epoch': 18.33}\n",
      "{'loss': 2.1844, 'learning_rate': 5.922194513715711e-06, 'epoch': 18.34}\n",
      "{'loss': 2.1975, 'learning_rate': 5.908367968966473e-06, 'epoch': 18.36}\n",
      "{'loss': 2.2024, 'learning_rate': 5.894513715710723e-06, 'epoch': 18.38}\n",
      "{'loss': 2.2006, 'learning_rate': 5.8806594624549736e-06, 'epoch': 18.39}\n",
      "{'loss': 2.2004, 'learning_rate': 5.866805209199225e-06, 'epoch': 18.41}\n",
      "{'loss': 2.1951, 'learning_rate': 5.852950955943475e-06, 'epoch': 18.42}\n",
      "{'loss': 2.1966, 'learning_rate': 5.839096702687725e-06, 'epoch': 18.44}\n",
      "{'loss': 2.1751, 'learning_rate': 5.825242449431976e-06, 'epoch': 18.45}\n",
      "{'loss': 2.2076, 'learning_rate': 5.811388196176227e-06, 'epoch': 18.47}\n",
      "{'loss': 2.1776, 'learning_rate': 5.7975616514269886e-06, 'epoch': 18.49}\n",
      "{'loss': 2.2053, 'learning_rate': 5.783707398171239e-06, 'epoch': 18.5}\n",
      "{'loss': 2.2136, 'learning_rate': 5.769853144915489e-06, 'epoch': 18.52}\n",
      "{'loss': 2.2065, 'learning_rate': 5.7559988916597395e-06, 'epoch': 18.53}\n",
      "{'loss': 2.2, 'learning_rate': 5.742172346910502e-06, 'epoch': 18.55}\n",
      "{'loss': 2.2078, 'learning_rate': 5.728318093654752e-06, 'epoch': 18.56}\n",
      "{'loss': 2.199, 'learning_rate': 5.714491548905514e-06, 'epoch': 18.58}\n",
      "{'loss': 2.193, 'learning_rate': 5.7006372956497645e-06, 'epoch': 18.59}\n",
      "{'loss': 2.2004, 'learning_rate': 5.686783042394015e-06, 'epoch': 18.61}\n",
      "{'loss': 2.1978, 'learning_rate': 5.672928789138266e-06, 'epoch': 18.63}\n",
      "{'loss': 2.2207, 'learning_rate': 5.659074535882516e-06, 'epoch': 18.64}\n",
      "{'loss': 2.1922, 'learning_rate': 5.6452202826267665e-06, 'epoch': 18.66}\n",
      "{'loss': 2.2117, 'learning_rate': 5.631366029371017e-06, 'epoch': 18.67}\n",
      "{'loss': 2.2023, 'learning_rate': 5.617511776115267e-06, 'epoch': 18.69}\n",
      "{'loss': 2.1968, 'learning_rate': 5.603712939872541e-06, 'epoch': 18.7}\n",
      "{'loss': 2.1947, 'learning_rate': 5.5898586866167915e-06, 'epoch': 18.72}\n",
      "{'loss': 2.1915, 'learning_rate': 5.576004433361042e-06, 'epoch': 18.73}\n",
      "{'loss': 2.2084, 'learning_rate': 5.562150180105292e-06, 'epoch': 18.75}\n",
      "{'loss': 2.1973, 'learning_rate': 5.548295926849543e-06, 'epoch': 18.77}\n",
      "{'loss': 2.1937, 'learning_rate': 5.534441673593794e-06, 'epoch': 18.78}\n",
      "{'loss': 2.1867, 'learning_rate': 5.520587420338044e-06, 'epoch': 18.8}\n",
      "{'loss': 2.2092, 'learning_rate': 5.506733167082294e-06, 'epoch': 18.81}\n",
      "{'loss': 2.1979, 'learning_rate': 5.492906622333056e-06, 'epoch': 18.83}\n",
      "{'loss': 2.1836, 'learning_rate': 5.479052369077307e-06, 'epoch': 18.84}\n",
      "{'loss': 2.2063, 'learning_rate': 5.465198115821557e-06, 'epoch': 18.86}\n",
      "{'loss': 2.1847, 'learning_rate': 5.451343862565808e-06, 'epoch': 18.87}\n",
      "{'loss': 2.1986, 'learning_rate': 5.4375173178165695e-06, 'epoch': 18.89}\n",
      "{'loss': 2.1816, 'learning_rate': 5.423690773067331e-06, 'epoch': 18.91}\n",
      "{'loss': 2.2028, 'learning_rate': 5.409836519811582e-06, 'epoch': 18.92}\n",
      "{'loss': 2.1984, 'learning_rate': 5.395982266555833e-06, 'epoch': 18.94}\n",
      "{'loss': 2.1826, 'learning_rate': 5.382128013300083e-06, 'epoch': 18.95}\n",
      "{'loss': 2.1848, 'learning_rate': 5.368273760044333e-06, 'epoch': 18.97}\n",
      "{'loss': 2.2022, 'learning_rate': 5.354419506788584e-06, 'epoch': 18.98}\n",
      "{'loss': 2.1974, 'learning_rate': 5.340565253532835e-06, 'epoch': 19.0}\n",
      "{'loss': 2.178, 'learning_rate': 5.326711000277085e-06, 'epoch': 19.01}\n",
      "{'loss': 2.1978, 'learning_rate': 5.312884455527847e-06, 'epoch': 19.03}\n",
      "{'loss': 2.1902, 'learning_rate': 5.299030202272099e-06, 'epoch': 19.05}\n",
      "{'loss': 2.1778, 'learning_rate': 5.285175949016349e-06, 'epoch': 19.06}\n",
      "{'loss': 2.1797, 'learning_rate': 5.2713216957605994e-06, 'epoch': 19.08}\n",
      "{'loss': 2.1832, 'learning_rate': 5.25746744250485e-06, 'epoch': 19.09}\n",
      "{'loss': 2.1783, 'learning_rate': 5.2436408977556115e-06, 'epoch': 19.11}\n",
      "{'loss': 2.1854, 'learning_rate': 5.229786644499863e-06, 'epoch': 19.12}\n",
      "{'loss': 2.2093, 'learning_rate': 5.215932391244113e-06, 'epoch': 19.14}\n",
      "{'loss': 2.198, 'learning_rate': 5.202105846494875e-06, 'epoch': 19.16}\n",
      "{'loss': 2.2127, 'learning_rate': 5.188251593239125e-06, 'epoch': 19.17}\n",
      "{'loss': 2.1633, 'learning_rate': 5.174397339983376e-06, 'epoch': 19.19}\n",
      "{'loss': 2.1788, 'learning_rate': 5.1605430867276265e-06, 'epoch': 19.2}\n",
      "{'loss': 2.1962, 'learning_rate': 5.146688833471877e-06, 'epoch': 19.22}\n",
      "{'loss': 2.1879, 'learning_rate': 5.1328622887226385e-06, 'epoch': 19.23}\n",
      "{'loss': 2.1856, 'learning_rate': 5.119008035466889e-06, 'epoch': 19.25}\n",
      "{'loss': 2.2185, 'learning_rate': 5.10515378221114e-06, 'epoch': 19.26}\n",
      "{'loss': 2.1922, 'learning_rate': 5.09129952895539e-06, 'epoch': 19.28}\n",
      "{'loss': 2.2081, 'learning_rate': 5.077445275699641e-06, 'epoch': 19.3}\n",
      "{'loss': 2.2087, 'learning_rate': 5.063591022443891e-06, 'epoch': 19.31}\n",
      "{'loss': 2.1932, 'learning_rate': 5.049736769188141e-06, 'epoch': 19.33}\n",
      "{'loss': 2.1714, 'learning_rate': 5.035882515932392e-06, 'epoch': 19.34}\n",
      "{'loss': 2.1978, 'learning_rate': 5.022055971183154e-06, 'epoch': 19.36}\n",
      "{'loss': 2.1784, 'learning_rate': 5.0082017179274045e-06, 'epoch': 19.37}\n",
      "{'loss': 2.169, 'learning_rate': 4.994347464671655e-06, 'epoch': 19.39}\n",
      "{'loss': 2.1968, 'learning_rate': 4.980493211415905e-06, 'epoch': 19.4}\n",
      "{'loss': 2.192, 'learning_rate': 4.966666666666667e-06, 'epoch': 19.42}\n",
      "{'loss': 2.1945, 'learning_rate': 4.952812413410917e-06, 'epoch': 19.44}\n",
      "{'loss': 2.1985, 'learning_rate': 4.9389581601551674e-06, 'epoch': 19.45}\n",
      "{'loss': 2.1971, 'learning_rate': 4.925103906899419e-06, 'epoch': 19.47}\n",
      "{'loss': 2.1613, 'learning_rate': 4.91127736215018e-06, 'epoch': 19.48}\n",
      "{'loss': 2.1806, 'learning_rate': 4.897423108894431e-06, 'epoch': 19.5}\n",
      "{'loss': 2.1853, 'learning_rate': 4.883568855638681e-06, 'epoch': 19.51}\n",
      "{'loss': 2.2039, 'learning_rate': 4.869714602382931e-06, 'epoch': 19.53}\n",
      "{'loss': 2.1837, 'learning_rate': 4.8558603491271824e-06, 'epoch': 19.54}\n",
      "{'loss': 2.1894, 'learning_rate': 4.842033804377945e-06, 'epoch': 19.56}\n",
      "{'loss': 2.1916, 'learning_rate': 4.828179551122195e-06, 'epoch': 19.58}\n",
      "{'loss': 2.2147, 'learning_rate': 4.814325297866446e-06, 'epoch': 19.59}\n",
      "{'loss': 2.1941, 'learning_rate': 4.800471044610696e-06, 'epoch': 19.61}\n",
      "{'loss': 2.1915, 'learning_rate': 4.786616791354946e-06, 'epoch': 19.62}\n",
      "{'loss': 2.1927, 'learning_rate': 4.772762538099197e-06, 'epoch': 19.64}\n",
      "{'loss': 2.1742, 'learning_rate': 4.758908284843448e-06, 'epoch': 19.65}\n",
      "{'loss': 2.1846, 'learning_rate': 4.745054031587698e-06, 'epoch': 19.67}\n",
      "{'loss': 2.1933, 'learning_rate': 4.73122748683846e-06, 'epoch': 19.69}\n",
      "{'loss': 2.2061, 'learning_rate': 4.71737323358271e-06, 'epoch': 19.7}\n",
      "{'loss': 2.2068, 'learning_rate': 4.703518980326961e-06, 'epoch': 19.72}\n",
      "{'loss': 2.1891, 'learning_rate': 4.6896647270712116e-06, 'epoch': 19.73}\n",
      "{'loss': 2.1994, 'learning_rate': 4.675838182321973e-06, 'epoch': 19.75}\n",
      "{'loss': 2.1942, 'learning_rate': 4.661983929066224e-06, 'epoch': 19.76}\n",
      "{'loss': 2.1937, 'learning_rate': 4.648129675810475e-06, 'epoch': 19.78}\n",
      "{'loss': 2.1833, 'learning_rate': 4.634275422554725e-06, 'epoch': 19.79}\n",
      "{'loss': 2.173, 'learning_rate': 4.620448877805487e-06, 'epoch': 19.81}\n",
      "{'loss': 2.1942, 'learning_rate': 4.606594624549737e-06, 'epoch': 19.83}\n",
      "{'loss': 2.2081, 'learning_rate': 4.5927403712939875e-06, 'epoch': 19.84}\n",
      "{'loss': 2.1896, 'learning_rate': 4.578886118038239e-06, 'epoch': 19.86}\n",
      "{'loss': 2.2004, 'learning_rate': 4.565059573289e-06, 'epoch': 19.87}\n",
      "{'loss': 2.1716, 'learning_rate': 4.551205320033251e-06, 'epoch': 19.89}\n",
      "{'loss': 2.1774, 'learning_rate': 4.537351066777501e-06, 'epoch': 19.9}\n",
      "{'loss': 2.1868, 'learning_rate': 4.523496813521751e-06, 'epoch': 19.92}\n",
      "{'loss': 2.1714, 'learning_rate': 4.509670268772514e-06, 'epoch': 19.93}\n",
      "{'loss': 2.1754, 'learning_rate': 4.495816015516764e-06, 'epoch': 19.95}\n",
      "{'loss': 2.1963, 'learning_rate': 4.4819617622610145e-06, 'epoch': 19.97}\n",
      "{'loss': 2.206, 'learning_rate': 4.468107509005265e-06, 'epoch': 19.98}\n",
      "{'loss': 2.1959, 'learning_rate': 4.4542809642560266e-06, 'epoch': 20.0}\n",
      "{'loss': 2.1849, 'learning_rate': 4.440426711000278e-06, 'epoch': 20.01}\n",
      "{'loss': 2.188, 'learning_rate': 4.426572457744528e-06, 'epoch': 20.03}\n",
      "{'loss': 2.163, 'learning_rate': 4.41274591299529e-06, 'epoch': 20.04}\n",
      "{'loss': 2.1821, 'learning_rate': 4.39889165973954e-06, 'epoch': 20.06}\n",
      "{'loss': 2.1795, 'learning_rate': 4.385037406483791e-06, 'epoch': 20.07}\n",
      "{'loss': 2.1791, 'learning_rate': 4.3711831532280415e-06, 'epoch': 20.09}\n",
      "{'loss': 2.1811, 'learning_rate': 4.357328899972292e-06, 'epoch': 20.11}\n",
      "{'loss': 2.1791, 'learning_rate': 4.343474646716542e-06, 'epoch': 20.12}\n",
      "{'loss': 2.1861, 'learning_rate': 4.3296203934607925e-06, 'epoch': 20.14}\n",
      "{'loss': 2.1892, 'learning_rate': 4.315793848711555e-06, 'epoch': 20.15}\n",
      "{'loss': 2.1796, 'learning_rate': 4.301939595455805e-06, 'epoch': 20.17}\n",
      "{'loss': 2.2, 'learning_rate': 4.288085342200056e-06, 'epoch': 20.18}\n",
      "{'loss': 2.1894, 'learning_rate': 4.274231088944306e-06, 'epoch': 20.2}\n",
      "{'loss': 2.1815, 'learning_rate': 4.260376835688556e-06, 'epoch': 20.22}\n",
      "{'loss': 2.1834, 'learning_rate': 4.2465225824328075e-06, 'epoch': 20.23}\n",
      "{'loss': 2.1971, 'learning_rate': 4.232668329177058e-06, 'epoch': 20.25}\n",
      "{'loss': 2.1753, 'learning_rate': 4.2188417844278195e-06, 'epoch': 20.26}\n",
      "{'loss': 2.1733, 'learning_rate': 4.20498753117207e-06, 'epoch': 20.28}\n",
      "{'loss': 2.1791, 'learning_rate': 4.19113327791632e-06, 'epoch': 20.29}\n",
      "{'loss': 2.19, 'learning_rate': 4.177279024660571e-06, 'epoch': 20.31}\n",
      "{'loss': 2.1708, 'learning_rate': 4.163424771404822e-06, 'epoch': 20.32}\n",
      "{'loss': 2.1939, 'learning_rate': 4.149570518149072e-06, 'epoch': 20.34}\n",
      "{'loss': 2.1902, 'learning_rate': 4.135716264893322e-06, 'epoch': 20.36}\n",
      "{'loss': 2.2046, 'learning_rate': 4.1218620116375725e-06, 'epoch': 20.37}\n",
      "{'loss': 2.171, 'learning_rate': 4.108035466888335e-06, 'epoch': 20.39}\n",
      "{'loss': 2.1816, 'learning_rate': 4.0941812136325854e-06, 'epoch': 20.4}\n",
      "{'loss': 2.1863, 'learning_rate': 4.080326960376836e-06, 'epoch': 20.42}\n",
      "{'loss': 2.1914, 'learning_rate': 4.066472707121086e-06, 'epoch': 20.43}\n",
      "{'loss': 2.1673, 'learning_rate': 4.052646162371849e-06, 'epoch': 20.45}\n",
      "{'loss': 2.1798, 'learning_rate': 4.038791909116099e-06, 'epoch': 20.46}\n",
      "{'loss': 2.1662, 'learning_rate': 4.024937655860349e-06, 'epoch': 20.48}\n",
      "{'loss': 2.1846, 'learning_rate': 4.0110834026045996e-06, 'epoch': 20.5}\n",
      "{'loss': 2.1833, 'learning_rate': 3.997256857855361e-06, 'epoch': 20.51}\n",
      "{'loss': 2.175, 'learning_rate': 3.9834026045996125e-06, 'epoch': 20.53}\n",
      "{'loss': 2.1856, 'learning_rate': 3.969548351343863e-06, 'epoch': 20.54}\n",
      "{'loss': 2.1834, 'learning_rate': 3.955694098088113e-06, 'epoch': 20.56}\n",
      "{'loss': 2.1987, 'learning_rate': 3.941867553338876e-06, 'epoch': 20.57}\n",
      "{'loss': 2.1784, 'learning_rate': 3.928013300083126e-06, 'epoch': 20.59}\n",
      "{'loss': 2.1487, 'learning_rate': 3.914159046827376e-06, 'epoch': 20.6}\n",
      "{'loss': 2.1923, 'learning_rate': 3.900332502078139e-06, 'epoch': 20.62}\n",
      "{'loss': 2.1876, 'learning_rate': 3.886478248822389e-06, 'epoch': 20.64}\n",
      "{'loss': 2.1813, 'learning_rate': 3.8726239955666395e-06, 'epoch': 20.65}\n",
      "{'loss': 2.1942, 'learning_rate': 3.85876974231089e-06, 'epoch': 20.67}\n",
      "{'loss': 2.1786, 'learning_rate': 3.84491548905514e-06, 'epoch': 20.68}\n",
      "{'loss': 2.1797, 'learning_rate': 3.831088944305903e-06, 'epoch': 20.7}\n",
      "{'loss': 2.1919, 'learning_rate': 3.817234691050153e-06, 'epoch': 20.71}\n",
      "{'loss': 2.1661, 'learning_rate': 3.8033804377944034e-06, 'epoch': 20.73}\n",
      "{'loss': 2.1762, 'learning_rate': 3.7895261845386537e-06, 'epoch': 20.75}\n",
      "{'loss': 2.1772, 'learning_rate': 3.7756719312829044e-06, 'epoch': 20.76}\n",
      "{'loss': 2.1698, 'learning_rate': 3.7618176780271547e-06, 'epoch': 20.78}\n",
      "{'loss': 2.172, 'learning_rate': 3.7479634247714054e-06, 'epoch': 20.79}\n",
      "{'loss': 2.1769, 'learning_rate': 3.7341091715156557e-06, 'epoch': 20.81}\n",
      "{'loss': 2.1972, 'learning_rate': 3.720282626766418e-06, 'epoch': 20.82}\n",
      "{'loss': 2.1815, 'learning_rate': 3.7064560820171797e-06, 'epoch': 20.84}\n",
      "{'loss': 2.1983, 'learning_rate': 3.69260182876143e-06, 'epoch': 20.85}\n",
      "{'loss': 2.1798, 'learning_rate': 3.6787475755056807e-06, 'epoch': 20.87}\n",
      "{'loss': 2.1991, 'learning_rate': 3.664893322249931e-06, 'epoch': 20.89}\n",
      "{'loss': 2.2079, 'learning_rate': 3.6510390689941817e-06, 'epoch': 20.9}\n",
      "{'loss': 2.1715, 'learning_rate': 3.637184815738432e-06, 'epoch': 20.92}\n",
      "{'loss': 2.1725, 'learning_rate': 3.6233305624826824e-06, 'epoch': 20.93}\n",
      "{'loss': 2.1729, 'learning_rate': 3.609476309226933e-06, 'epoch': 20.95}\n",
      "{'loss': 2.1758, 'learning_rate': 3.595649764477695e-06, 'epoch': 20.96}\n",
      "{'loss': 2.1782, 'learning_rate': 3.5817955112219456e-06, 'epoch': 20.98}\n",
      "{'loss': 2.1847, 'learning_rate': 3.567941257966196e-06, 'epoch': 20.99}\n",
      "{'loss': 2.1779, 'learning_rate': 3.554114713216958e-06, 'epoch': 21.01}\n",
      "{'loss': 2.1873, 'learning_rate': 3.5402604599612084e-06, 'epoch': 21.03}\n",
      "{'loss': 2.1652, 'learning_rate': 3.5264062067054587e-06, 'epoch': 21.04}\n",
      "{'loss': 2.1563, 'learning_rate': 3.5125519534497094e-06, 'epoch': 21.06}\n",
      "{'loss': 2.1655, 'learning_rate': 3.4986977001939597e-06, 'epoch': 21.07}\n",
      "{'loss': 2.1698, 'learning_rate': 3.4848434469382105e-06, 'epoch': 21.09}\n",
      "{'loss': 2.181, 'learning_rate': 3.4709891936824608e-06, 'epoch': 21.1}\n",
      "{'loss': 2.174, 'learning_rate': 3.457134940426711e-06, 'epoch': 21.12}\n",
      "{'loss': 2.1578, 'learning_rate': 3.4433083956774732e-06, 'epoch': 21.13}\n",
      "{'loss': 2.1786, 'learning_rate': 3.4294541424217236e-06, 'epoch': 21.15}\n",
      "{'loss': 2.1807, 'learning_rate': 3.4155998891659743e-06, 'epoch': 21.17}\n",
      "{'loss': 2.1897, 'learning_rate': 3.4017456359102246e-06, 'epoch': 21.18}\n",
      "{'loss': 2.1784, 'learning_rate': 3.3879190911609868e-06, 'epoch': 21.2}\n",
      "{'loss': 2.2022, 'learning_rate': 3.374064837905237e-06, 'epoch': 21.21}\n",
      "{'loss': 2.1942, 'learning_rate': 3.3602105846494874e-06, 'epoch': 21.23}\n",
      "{'loss': 2.1717, 'learning_rate': 3.346356331393738e-06, 'epoch': 21.24}\n",
      "{'loss': 2.1926, 'learning_rate': 3.3325020781379884e-06, 'epoch': 21.26}\n",
      "{'loss': 2.1854, 'learning_rate': 3.318647824882239e-06, 'epoch': 21.27}\n",
      "{'loss': 2.1634, 'learning_rate': 3.3047935716264895e-06, 'epoch': 21.29}\n",
      "{'loss': 2.1726, 'learning_rate': 3.2909393183707398e-06, 'epoch': 21.31}\n",
      "{'loss': 2.178, 'learning_rate': 3.277112773621502e-06, 'epoch': 21.32}\n",
      "{'loss': 2.1639, 'learning_rate': 3.2632585203657523e-06, 'epoch': 21.34}\n",
      "{'loss': 2.1802, 'learning_rate': 3.249404267110003e-06, 'epoch': 21.35}\n",
      "{'loss': 2.1989, 'learning_rate': 3.2355500138542533e-06, 'epoch': 21.37}\n",
      "{'loss': 2.1663, 'learning_rate': 3.2217234691050155e-06, 'epoch': 21.38}\n",
      "{'loss': 2.1608, 'learning_rate': 3.2078692158492658e-06, 'epoch': 21.4}\n",
      "{'loss': 2.1755, 'learning_rate': 3.194014962593516e-06, 'epoch': 21.42}\n",
      "{'loss': 2.1823, 'learning_rate': 3.180160709337767e-06, 'epoch': 21.43}\n",
      "{'loss': 2.164, 'learning_rate': 3.1663341645885286e-06, 'epoch': 21.45}\n",
      "{'loss': 2.1569, 'learning_rate': 3.1525076198392907e-06, 'epoch': 21.46}\n",
      "{'loss': 2.1687, 'learning_rate': 3.138653366583541e-06, 'epoch': 21.48}\n",
      "{'loss': 2.1849, 'learning_rate': 3.1247991133277918e-06, 'epoch': 21.49}\n",
      "{'loss': 2.1733, 'learning_rate': 3.110944860072042e-06, 'epoch': 21.51}\n",
      "{'loss': 2.1903, 'learning_rate': 3.0970906068162924e-06, 'epoch': 21.52}\n",
      "{'loss': 2.1808, 'learning_rate': 3.083236353560543e-06, 'epoch': 21.54}\n",
      "{'loss': 2.185, 'learning_rate': 3.0694098088113057e-06, 'epoch': 21.56}\n",
      "{'loss': 2.1553, 'learning_rate': 3.055555555555556e-06, 'epoch': 21.57}\n",
      "{'loss': 2.1936, 'learning_rate': 3.0417013022998063e-06, 'epoch': 21.59}\n",
      "{'loss': 2.1652, 'learning_rate': 3.027847049044057e-06, 'epoch': 21.6}\n",
      "{'loss': 2.1844, 'learning_rate': 3.0139927957883074e-06, 'epoch': 21.62}\n",
      "{'loss': 2.1605, 'learning_rate': 3.000138542532558e-06, 'epoch': 21.63}\n",
      "{'loss': 2.17, 'learning_rate': 2.9862842892768084e-06, 'epoch': 21.65}\n",
      "{'loss': 2.1514, 'learning_rate': 2.9724300360210587e-06, 'epoch': 21.66}\n",
      "{'loss': 2.1775, 'learning_rate': 2.958603491271821e-06, 'epoch': 21.68}\n",
      "{'loss': 2.1695, 'learning_rate': 2.9447492380160712e-06, 'epoch': 21.7}\n",
      "{'loss': 2.1773, 'learning_rate': 2.930894984760322e-06, 'epoch': 21.71}\n",
      "{'loss': 2.1567, 'learning_rate': 2.9170407315045723e-06, 'epoch': 21.73}\n",
      "{'loss': 2.1822, 'learning_rate': 2.9032141867553344e-06, 'epoch': 21.74}\n",
      "{'loss': 2.1754, 'learning_rate': 2.8893599334995847e-06, 'epoch': 21.76}\n",
      "{'loss': 2.1726, 'learning_rate': 2.875505680243835e-06, 'epoch': 21.77}\n",
      "{'loss': 2.1553, 'learning_rate': 2.8616514269880858e-06, 'epoch': 21.79}\n",
      "{'loss': 2.1783, 'learning_rate': 2.8478248822388475e-06, 'epoch': 21.8}\n",
      "{'loss': 2.1782, 'learning_rate': 2.8339706289830983e-06, 'epoch': 21.82}\n",
      "{'loss': 2.1767, 'learning_rate': 2.8201163757273486e-06, 'epoch': 21.84}\n",
      "{'loss': 2.1766, 'learning_rate': 2.8062621224715993e-06, 'epoch': 21.85}\n",
      "{'loss': 2.1916, 'learning_rate': 2.792435577722361e-06, 'epoch': 21.87}\n",
      "{'loss': 2.1826, 'learning_rate': 2.7785813244666114e-06, 'epoch': 21.88}\n",
      "{'loss': 2.1862, 'learning_rate': 2.764727071210862e-06, 'epoch': 21.9}\n",
      "{'loss': 2.1679, 'learning_rate': 2.7508728179551124e-06, 'epoch': 21.91}\n",
      "{'loss': 2.1553, 'learning_rate': 2.7370462732058746e-06, 'epoch': 21.93}\n",
      "{'loss': 2.1842, 'learning_rate': 2.723192019950125e-06, 'epoch': 21.95}\n",
      "{'loss': 2.1786, 'learning_rate': 2.709365475200887e-06, 'epoch': 21.96}\n",
      "{'loss': 2.1641, 'learning_rate': 2.6955112219451374e-06, 'epoch': 21.98}\n",
      "{'loss': 2.1843, 'learning_rate': 2.6816569686893877e-06, 'epoch': 21.99}\n",
      "{'loss': 2.1509, 'learning_rate': 2.6678027154336384e-06, 'epoch': 22.01}\n",
      "{'loss': 2.2062, 'learning_rate': 2.6539484621778887e-06, 'epoch': 22.02}\n",
      "{'loss': 2.1725, 'learning_rate': 2.6400942089221395e-06, 'epoch': 22.04}\n",
      "{'loss': 2.1887, 'learning_rate': 2.6262399556663898e-06, 'epoch': 22.05}\n",
      "{'loss': 2.1768, 'learning_rate': 2.61238570241064e-06, 'epoch': 22.07}\n",
      "{'loss': 2.1548, 'learning_rate': 2.598531449154891e-06, 'epoch': 22.09}\n",
      "{'loss': 2.1638, 'learning_rate': 2.584677195899141e-06, 'epoch': 22.1}\n",
      "{'loss': 2.1622, 'learning_rate': 2.570822942643392e-06, 'epoch': 22.12}\n",
      "{'loss': 2.1603, 'learning_rate': 2.5569963978941536e-06, 'epoch': 22.13}\n",
      "{'loss': 2.1704, 'learning_rate': 2.5431421446384043e-06, 'epoch': 22.15}\n",
      "{'loss': 2.1558, 'learning_rate': 2.5292878913826546e-06, 'epoch': 22.16}\n",
      "{'loss': 2.1891, 'learning_rate': 2.515433638126905e-06, 'epoch': 22.18}\n",
      "{'loss': 2.1749, 'learning_rate': 2.5015793848711557e-06, 'epoch': 22.19}\n",
      "{'loss': 2.1768, 'learning_rate': 2.487725131615406e-06, 'epoch': 22.21}\n",
      "{'loss': 2.1753, 'learning_rate': 2.4738708783596567e-06, 'epoch': 22.23}\n",
      "{'loss': 2.1661, 'learning_rate': 2.460016625103907e-06, 'epoch': 22.24}\n",
      "{'loss': 2.1879, 'learning_rate': 2.4461900803546688e-06, 'epoch': 22.26}\n",
      "{'loss': 2.1783, 'learning_rate': 2.4323358270989195e-06, 'epoch': 22.27}\n",
      "{'loss': 2.1775, 'learning_rate': 2.41848157384317e-06, 'epoch': 22.29}\n",
      "{'loss': 2.1951, 'learning_rate': 2.4046273205874206e-06, 'epoch': 22.3}\n",
      "{'loss': 2.1594, 'learning_rate': 2.3908007758381827e-06, 'epoch': 22.32}\n",
      "{'loss': 2.1789, 'learning_rate': 2.3769742310889445e-06, 'epoch': 22.33}\n",
      "{'loss': 2.1664, 'learning_rate': 2.363119977833195e-06, 'epoch': 22.35}\n",
      "{'loss': 2.148, 'learning_rate': 2.3492657245774455e-06, 'epoch': 22.37}\n",
      "{'loss': 2.1743, 'learning_rate': 2.3354114713216962e-06, 'epoch': 22.38}\n",
      "{'loss': 2.1624, 'learning_rate': 2.3215572180659466e-06, 'epoch': 22.4}\n",
      "{'loss': 2.1649, 'learning_rate': 2.307702964810197e-06, 'epoch': 22.41}\n",
      "{'loss': 2.1572, 'learning_rate': 2.2938487115544476e-06, 'epoch': 22.43}\n",
      "{'loss': 2.1852, 'learning_rate': 2.279994458298698e-06, 'epoch': 22.44}\n",
      "{'loss': 2.1643, 'learning_rate': 2.26616791354946e-06, 'epoch': 22.46}\n",
      "{'loss': 2.1642, 'learning_rate': 2.2523136602937104e-06, 'epoch': 22.48}\n",
      "{'loss': 2.1733, 'learning_rate': 2.238487115544472e-06, 'epoch': 22.49}\n",
      "{'loss': 2.1414, 'learning_rate': 2.224632862288723e-06, 'epoch': 22.51}\n",
      "{'loss': 2.1802, 'learning_rate': 2.210778609032973e-06, 'epoch': 22.52}\n",
      "{'loss': 2.1534, 'learning_rate': 2.196924355777224e-06, 'epoch': 22.54}\n",
      "{'loss': 2.199, 'learning_rate': 2.1830701025214742e-06, 'epoch': 22.55}\n",
      "{'loss': 2.1573, 'learning_rate': 2.169215849265725e-06, 'epoch': 22.57}\n",
      "{'loss': 2.1662, 'learning_rate': 2.1553893045164867e-06, 'epoch': 22.58}\n",
      "{'loss': 2.1675, 'learning_rate': 2.141535051260737e-06, 'epoch': 22.6}\n",
      "{'loss': 2.1704, 'learning_rate': 2.1276807980049877e-06, 'epoch': 22.62}\n",
      "{'loss': 2.1582, 'learning_rate': 2.113826544749238e-06, 'epoch': 22.63}\n",
      "{'loss': 2.1605, 'learning_rate': 2.0999722914934888e-06, 'epoch': 22.65}\n",
      "{'loss': 2.1648, 'learning_rate': 2.086118038237739e-06, 'epoch': 22.66}\n",
      "{'loss': 2.16, 'learning_rate': 2.0722637849819894e-06, 'epoch': 22.68}\n",
      "{'loss': 2.1674, 'learning_rate': 2.05840953172624e-06, 'epoch': 22.69}\n",
      "{'loss': 2.1815, 'learning_rate': 2.0445552784704904e-06, 'epoch': 22.71}\n",
      "{'loss': 2.176, 'learning_rate': 2.0307287337212526e-06, 'epoch': 22.72}\n",
      "{'loss': 2.1621, 'learning_rate': 2.016874480465503e-06, 'epoch': 22.74}\n",
      "{'loss': 2.1356, 'learning_rate': 2.0030202272097537e-06, 'epoch': 22.76}\n",
      "{'loss': 2.1674, 'learning_rate': 1.989165973954004e-06, 'epoch': 22.77}\n",
      "{'loss': 2.1787, 'learning_rate': 1.9753394292047657e-06, 'epoch': 22.79}\n",
      "{'loss': 2.1642, 'learning_rate': 1.9614851759490164e-06, 'epoch': 22.8}\n",
      "{'loss': 2.1599, 'learning_rate': 1.9476586311997786e-06, 'epoch': 22.82}\n",
      "{'loss': 2.1714, 'learning_rate': 1.933804377944029e-06, 'epoch': 22.83}\n",
      "{'loss': 2.1717, 'learning_rate': 1.9199501246882797e-06, 'epoch': 22.85}\n",
      "{'loss': 2.1624, 'learning_rate': 1.90609587143253e-06, 'epoch': 22.86}\n",
      "{'loss': 2.1595, 'learning_rate': 1.8922416181767805e-06, 'epoch': 22.88}\n",
      "{'loss': 2.18, 'learning_rate': 1.878387364921031e-06, 'epoch': 22.9}\n",
      "{'loss': 2.1486, 'learning_rate': 1.8645331116652815e-06, 'epoch': 22.91}\n",
      "{'loss': 2.1905, 'learning_rate': 1.850678858409532e-06, 'epoch': 22.93}\n",
      "{'loss': 2.148, 'learning_rate': 1.836852313660294e-06, 'epoch': 22.94}\n",
      "{'loss': 2.1609, 'learning_rate': 1.823025768911056e-06, 'epoch': 22.96}\n",
      "{'loss': 2.1474, 'learning_rate': 1.8091715156553063e-06, 'epoch': 22.97}\n",
      "{'loss': 2.1431, 'learning_rate': 1.7953172623995568e-06, 'epoch': 22.99}\n",
      "{'loss': 2.1528, 'learning_rate': 1.7814630091438073e-06, 'epoch': 23.0}\n",
      "{'loss': 2.1526, 'learning_rate': 1.7676087558880578e-06, 'epoch': 23.02}\n",
      "{'loss': 2.1752, 'learning_rate': 1.7537545026323084e-06, 'epoch': 23.04}\n",
      "{'loss': 2.163, 'learning_rate': 1.7399002493765587e-06, 'epoch': 23.05}\n",
      "{'loss': 2.145, 'learning_rate': 1.7260459961208092e-06, 'epoch': 23.07}\n",
      "{'loss': 2.1709, 'learning_rate': 1.7122194513715712e-06, 'epoch': 23.08}\n",
      "{'loss': 2.1546, 'learning_rate': 1.6983651981158217e-06, 'epoch': 23.1}\n",
      "{'loss': 2.1759, 'learning_rate': 1.6845109448600722e-06, 'epoch': 23.11}\n",
      "{'loss': 2.1556, 'learning_rate': 1.6706844001108342e-06, 'epoch': 23.13}\n",
      "{'loss': 2.1502, 'learning_rate': 1.6568301468550847e-06, 'epoch': 23.15}\n",
      "{'loss': 2.1841, 'learning_rate': 1.642975893599335e-06, 'epoch': 23.16}\n",
      "{'loss': 2.1719, 'learning_rate': 1.6291216403435855e-06, 'epoch': 23.18}\n",
      "{'loss': 2.1673, 'learning_rate': 1.615267387087836e-06, 'epoch': 23.19}\n",
      "{'loss': 2.1819, 'learning_rate': 1.6014131338320865e-06, 'epoch': 23.21}\n",
      "{'loss': 2.1626, 'learning_rate': 1.587558880576337e-06, 'epoch': 23.22}\n",
      "{'loss': 2.1542, 'learning_rate': 1.5737046273205876e-06, 'epoch': 23.24}\n",
      "{'loss': 2.1769, 'learning_rate': 1.5598780825713493e-06, 'epoch': 23.25}\n",
      "{'loss': 2.1621, 'learning_rate': 1.5460238293155999e-06, 'epoch': 23.27}\n",
      "{'loss': 2.168, 'learning_rate': 1.5321695760598504e-06, 'epoch': 23.29}\n",
      "{'loss': 2.1514, 'learning_rate': 1.518315322804101e-06, 'epoch': 23.3}\n",
      "{'loss': 2.1413, 'learning_rate': 1.5044610695483514e-06, 'epoch': 23.32}\n",
      "{'loss': 2.1898, 'learning_rate': 1.4906345247991136e-06, 'epoch': 23.33}\n",
      "{'loss': 2.157, 'learning_rate': 1.4767802715433641e-06, 'epoch': 23.35}\n",
      "{'loss': 2.1819, 'learning_rate': 1.4629260182876146e-06, 'epoch': 23.36}\n",
      "{'loss': 2.143, 'learning_rate': 1.449071765031865e-06, 'epoch': 23.38}\n",
      "{'loss': 2.1669, 'learning_rate': 1.435245220282627e-06, 'epoch': 23.39}\n",
      "{'loss': 2.1735, 'learning_rate': 1.4213909670268774e-06, 'epoch': 23.41}\n",
      "{'loss': 2.1465, 'learning_rate': 1.4075644222776394e-06, 'epoch': 23.43}\n",
      "{'loss': 2.1534, 'learning_rate': 1.39371016902189e-06, 'epoch': 23.44}\n",
      "{'loss': 2.1503, 'learning_rate': 1.3798559157661404e-06, 'epoch': 23.46}\n",
      "{'loss': 2.1628, 'learning_rate': 1.366001662510391e-06, 'epoch': 23.47}\n",
      "{'loss': 2.1747, 'learning_rate': 1.3521474092546413e-06, 'epoch': 23.49}\n",
      "{'loss': 2.1699, 'learning_rate': 1.3382931559988918e-06, 'epoch': 23.5}\n",
      "{'loss': 2.1579, 'learning_rate': 1.3244389027431423e-06, 'epoch': 23.52}\n",
      "{'loss': 2.154, 'learning_rate': 1.3105846494873928e-06, 'epoch': 23.53}\n",
      "{'loss': 2.1555, 'learning_rate': 1.2967303962316433e-06, 'epoch': 23.55}\n",
      "{'loss': 2.1893, 'learning_rate': 1.2828761429758936e-06, 'epoch': 23.57}\n",
      "{'loss': 2.1453, 'learning_rate': 1.2690218897201442e-06, 'epoch': 23.58}\n",
      "{'loss': 2.1744, 'learning_rate': 1.2551676364643947e-06, 'epoch': 23.6}\n",
      "{'loss': 2.1558, 'learning_rate': 1.2413133832086452e-06, 'epoch': 23.61}\n",
      "{'loss': 2.1557, 'learning_rate': 1.2275145469659186e-06, 'epoch': 23.63}\n",
      "{'loss': 2.1628, 'learning_rate': 1.2136602937101691e-06, 'epoch': 23.64}\n",
      "{'loss': 2.168, 'learning_rate': 1.1998060404544197e-06, 'epoch': 23.66}\n",
      "{'loss': 2.1813, 'learning_rate': 1.18595178719867e-06, 'epoch': 23.68}\n",
      "{'loss': 2.1495, 'learning_rate': 1.1720975339429205e-06, 'epoch': 23.69}\n",
      "{'loss': 2.1483, 'learning_rate': 1.158243280687171e-06, 'epoch': 23.71}\n",
      "{'loss': 2.1593, 'learning_rate': 1.1443890274314215e-06, 'epoch': 23.72}\n",
      "{'loss': 2.1511, 'learning_rate': 1.130534774175672e-06, 'epoch': 23.74}\n",
      "{'loss': 2.1507, 'learning_rate': 1.1166805209199226e-06, 'epoch': 23.75}\n",
      "{'loss': 2.1689, 'learning_rate': 1.1028539761706845e-06, 'epoch': 23.77}\n",
      "{'loss': 2.1418, 'learning_rate': 1.088999722914935e-06, 'epoch': 23.78}\n",
      "{'loss': 2.1639, 'learning_rate': 1.0751454696591856e-06, 'epoch': 23.8}\n",
      "{'loss': 2.1672, 'learning_rate': 1.061291216403436e-06, 'epoch': 23.82}\n",
      "{'loss': 2.1718, 'learning_rate': 1.0474646716541978e-06, 'epoch': 23.83}\n",
      "{'loss': 2.1518, 'learning_rate': 1.0336104183984484e-06, 'epoch': 23.85}\n",
      "{'loss': 2.1546, 'learning_rate': 1.0197561651426989e-06, 'epoch': 23.86}\n",
      "{'loss': 2.1759, 'learning_rate': 1.0059019118869494e-06, 'epoch': 23.88}\n",
      "{'loss': 2.1716, 'learning_rate': 9.920753671377114e-07, 'epoch': 23.89}\n",
      "{'loss': 2.1761, 'learning_rate': 9.782211138819619e-07, 'epoch': 23.91}\n",
      "{'loss': 2.1752, 'learning_rate': 9.643668606262122e-07, 'epoch': 23.92}\n",
      "{'loss': 2.1582, 'learning_rate': 9.505126073704628e-07, 'epoch': 23.94}\n",
      "{'loss': 2.1637, 'learning_rate': 9.366583541147132e-07, 'epoch': 23.96}\n",
      "{'loss': 2.1527, 'learning_rate': 9.228041008589638e-07, 'epoch': 23.97}\n",
      "{'loss': 2.1665, 'learning_rate': 9.089498476032143e-07, 'epoch': 23.99}\n",
      "{'loss': 2.1678, 'learning_rate': 8.950955943474647e-07, 'epoch': 24.0}\n",
      "{'loss': 2.1487, 'learning_rate': 8.812967581047383e-07, 'epoch': 24.02}\n",
      "{'loss': 2.1577, 'learning_rate': 8.674425048489887e-07, 'epoch': 24.03}\n",
      "{'loss': 2.1562, 'learning_rate': 8.535882515932392e-07, 'epoch': 24.05}\n",
      "{'loss': 2.1413, 'learning_rate': 8.397339983374897e-07, 'epoch': 24.06}\n",
      "{'loss': 2.1679, 'learning_rate': 8.258797450817402e-07, 'epoch': 24.08}\n",
      "{'loss': 2.1357, 'learning_rate': 8.120254918259907e-07, 'epoch': 24.1}\n",
      "{'loss': 2.1591, 'learning_rate': 7.981712385702411e-07, 'epoch': 24.11}\n",
      "{'loss': 2.1461, 'learning_rate': 7.843169853144916e-07, 'epoch': 24.13}\n",
      "{'loss': 2.1622, 'learning_rate': 7.704904405652536e-07, 'epoch': 24.14}\n",
      "{'loss': 2.1883, 'learning_rate': 7.566361873095041e-07, 'epoch': 24.16}\n",
      "{'loss': 2.1428, 'learning_rate': 7.427819340537545e-07, 'epoch': 24.17}\n",
      "{'loss': 2.1586, 'learning_rate': 7.28927680798005e-07, 'epoch': 24.19}\n",
      "{'loss': 2.1639, 'learning_rate': 7.15101136048767e-07, 'epoch': 24.21}\n",
      "{'loss': 2.1575, 'learning_rate': 7.012468827930174e-07, 'epoch': 24.22}\n",
      "{'loss': 2.1431, 'learning_rate': 6.873926295372679e-07, 'epoch': 24.24}\n",
      "{'loss': 2.1647, 'learning_rate': 6.735383762815185e-07, 'epoch': 24.25}\n",
      "{'loss': 2.1441, 'learning_rate': 6.596841230257689e-07, 'epoch': 24.27}\n",
      "{'loss': 2.1479, 'learning_rate': 6.458575782765309e-07, 'epoch': 24.28}\n",
      "{'loss': 2.1695, 'learning_rate': 6.320033250207815e-07, 'epoch': 24.3}\n",
      "{'loss': 2.1596, 'learning_rate': 6.18149071765032e-07, 'epoch': 24.31}\n",
      "{'loss': 2.1471, 'learning_rate': 6.042948185092824e-07, 'epoch': 24.33}\n",
      "{'loss': 2.186, 'learning_rate': 5.904682737600444e-07, 'epoch': 24.35}\n",
      "{'loss': 2.1622, 'learning_rate': 5.766140205042949e-07, 'epoch': 24.36}\n",
      "{'loss': 2.1514, 'learning_rate': 5.627597672485453e-07, 'epoch': 24.38}\n",
      "{'loss': 2.1668, 'learning_rate': 5.489332224993074e-07, 'epoch': 24.39}\n",
      "{'loss': 2.1629, 'learning_rate': 5.350789692435579e-07, 'epoch': 24.41}\n",
      "{'loss': 2.1647, 'learning_rate': 5.212247159878083e-07, 'epoch': 24.42}\n",
      "{'loss': 2.1504, 'learning_rate': 5.073704627320588e-07, 'epoch': 24.44}\n",
      "{'loss': 2.1593, 'learning_rate': 4.935162094763092e-07, 'epoch': 24.45}\n",
      "{'loss': 2.1562, 'learning_rate': 4.796619562205598e-07, 'epoch': 24.47}\n",
      "{'loss': 2.1631, 'learning_rate': 4.658077029648102e-07, 'epoch': 24.49}\n",
      "{'loss': 2.1575, 'learning_rate': 4.5195344970906074e-07, 'epoch': 24.5}\n",
      "{'loss': 2.1727, 'learning_rate': 4.3812690495982265e-07, 'epoch': 24.52}\n",
      "{'loss': 2.1699, 'learning_rate': 4.2427265170407317e-07, 'epoch': 24.53}\n",
      "{'loss': 2.1529, 'learning_rate': 4.1041839844832364e-07, 'epoch': 24.55}\n",
      "{'loss': 2.178, 'learning_rate': 3.965641451925741e-07, 'epoch': 24.56}\n",
      "{'loss': 2.1679, 'learning_rate': 3.827376004433361e-07, 'epoch': 24.58}\n",
      "{'loss': 2.1741, 'learning_rate': 3.6888334718758664e-07, 'epoch': 24.59}\n",
      "{'loss': 2.1636, 'learning_rate': 3.550290939318371e-07, 'epoch': 24.61}\n",
      "{'loss': 2.1625, 'learning_rate': 3.411748406760876e-07, 'epoch': 24.63}\n",
      "{'loss': 2.1666, 'learning_rate': 3.273482959268496e-07, 'epoch': 24.64}\n",
      "{'loss': 2.1529, 'learning_rate': 3.1349404267110006e-07, 'epoch': 24.66}\n",
      "{'loss': 2.1524, 'learning_rate': 2.996397894153505e-07, 'epoch': 24.67}\n",
      "{'loss': 2.1627, 'learning_rate': 2.85785536159601e-07, 'epoch': 24.69}\n",
      "{'loss': 2.1474, 'learning_rate': 2.71958991410363e-07, 'epoch': 24.7}\n",
      "{'loss': 2.1558, 'learning_rate': 2.581047381546135e-07, 'epoch': 24.72}\n",
      "{'loss': 2.1596, 'learning_rate': 2.44250484898864e-07, 'epoch': 24.74}\n",
      "{'loss': 2.1606, 'learning_rate': 2.3039623164311446e-07, 'epoch': 24.75}\n",
      "{'loss': 2.1524, 'learning_rate': 2.1654197838736496e-07, 'epoch': 24.77}\n",
      "{'loss': 2.1589, 'learning_rate': 2.0268772513161542e-07, 'epoch': 24.78}\n",
      "{'loss': 2.1429, 'learning_rate': 1.8883347187586592e-07, 'epoch': 24.8}\n",
      "{'loss': 2.1471, 'learning_rate': 1.750069271266279e-07, 'epoch': 24.81}\n",
      "{'loss': 2.1513, 'learning_rate': 1.6115267387087837e-07, 'epoch': 24.83}\n",
      "{'loss': 2.1396, 'learning_rate': 1.4729842061512887e-07, 'epoch': 24.84}\n",
      "{'loss': 2.1276, 'learning_rate': 1.3344416735937933e-07, 'epoch': 24.86}\n",
      "{'loss': 2.1823, 'learning_rate': 1.1958991410362983e-07, 'epoch': 24.88}\n",
      "{'loss': 2.1662, 'learning_rate': 1.0573566084788031e-07, 'epoch': 24.89}\n",
      "{'loss': 2.1448, 'learning_rate': 9.188140759213079e-08, 'epoch': 24.91}\n",
      "{'loss': 2.1607, 'learning_rate': 7.805486284289278e-08, 'epoch': 24.92}\n",
      "{'loss': 2.1731, 'learning_rate': 6.420060958714326e-08, 'epoch': 24.94}\n",
      "{'loss': 2.1431, 'learning_rate': 5.034635633139374e-08, 'epoch': 24.95}\n",
      "{'loss': 2.1581, 'learning_rate': 3.649210307564423e-08, 'epoch': 24.97}\n",
      "{'loss': 2.1521, 'learning_rate': 2.263784981989471e-08, 'epoch': 24.98}\n",
      "{'loss': 2.1305, 'learning_rate': 8.811305070656692e-09, 'epoch': 25.0}\n",
      "{'train_runtime': 166391.6402, 'train_samples_per_second': 86.758, 'train_steps_per_second': 4.82, 'train_loss': 2.4409706580716177, 'epoch': 25.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c474c3e2d3064cf281f3a6ee06e66a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8327 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 8.35\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "data = [\"persuratan-dataset-final-fourth.txt\",\"peraturan-dataset-final-fifth.txt\"]\n",
    "tokenizer_file = \"cahya/bert-base-indonesian-522M\"\n",
    "batch_size = 18\n",
    "model_checkpoint = \"cahya/bert-base-indonesian-522M\"\n",
    "model_name = \"wirawan-finetuned-all-25\"\n",
    "\n",
    "run_finetune(data,tokenizer_file, batch_size, model_checkpoint, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/agus/.cache/huggingface/datasets/text/suffix_array-0bb18389d41e00ae/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401520ce8f3849c99eab41f6cc84c81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 17750\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 4438\n",
      "    })\n",
      "})\n",
      "The max length for the tokenizer is: 1000000000000000019884624838656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a450272c17ab4182b30aa11d60ec4493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/17750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a6f724c5c0450ba304ab0046a6f39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/4438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2a29df23a04581afb5a9d651f59256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/17750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0810f7f966ce4cb585aa64e354e36c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/4438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_dataset DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 149929\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 38737\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjust-108\u001b[0m (\u001b[33mcofog\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/agus/DATA/DDALM/script/IndoGovBERT-final/wandb/run-20230823_022724-0hm66rlu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cofog/huggingface/runs/0hm66rlu' target=\"_blank\">radiant-terrain-157</a></strong> to <a href='https://wandb.ai/cofog/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cofog/huggingface' target=\"_blank\">https://wandb.ai/cofog/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cofog/huggingface/runs/0hm66rlu' target=\"_blank\">https://wandb.ai/cofog/huggingface/runs/0hm66rlu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbc426e49844925811b44b50f8da989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/208250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.9353, 'learning_rate': 4.801920768307324e-07, 'epoch': 0.06}\n",
      "{'loss': 6.54, 'learning_rate': 9.603841536614647e-07, 'epoch': 0.12}\n",
      "{'loss': 6.3994, 'learning_rate': 1.4405762304921969e-06, 'epoch': 0.18}\n",
      "{'loss': 6.3324, 'learning_rate': 1.9207683073229294e-06, 'epoch': 0.24}\n",
      "{'loss': 6.2373, 'learning_rate': 2.4009603841536618e-06, 'epoch': 0.3}\n",
      "{'loss': 6.1926, 'learning_rate': 2.8811524609843937e-06, 'epoch': 0.36}\n",
      "{'loss': 6.1436, 'learning_rate': 3.3613445378151265e-06, 'epoch': 0.42}\n",
      "{'loss': 6.1248, 'learning_rate': 3.841536614645859e-06, 'epoch': 0.48}\n",
      "{'loss': 6.0684, 'learning_rate': 4.320768307322929e-06, 'epoch': 0.54}\n",
      "{'loss': 6.051, 'learning_rate': 4.800960384153662e-06, 'epoch': 0.6}\n",
      "{'loss': 6.0158, 'learning_rate': 5.281152460984395e-06, 'epoch': 0.66}\n",
      "{'loss': 6.0091, 'learning_rate': 5.761344537815126e-06, 'epoch': 0.72}\n",
      "{'loss': 5.9856, 'learning_rate': 6.240576230492197e-06, 'epoch': 0.78}\n",
      "{'loss': 5.9647, 'learning_rate': 6.72076830732293e-06, 'epoch': 0.84}\n",
      "{'loss': 5.9198, 'learning_rate': 7.200960384153662e-06, 'epoch': 0.9}\n",
      "{'loss': 5.8696, 'learning_rate': 7.681152460984394e-06, 'epoch': 0.96}\n",
      "{'loss': 5.8114, 'learning_rate': 8.161344537815126e-06, 'epoch': 1.02}\n",
      "{'loss': 5.7484, 'learning_rate': 8.641536614645859e-06, 'epoch': 1.08}\n",
      "{'loss': 5.6024, 'learning_rate': 9.12076830732293e-06, 'epoch': 1.14}\n",
      "{'loss': 5.4703, 'learning_rate': 9.600960384153662e-06, 'epoch': 1.2}\n",
      "{'loss': 5.3095, 'learning_rate': 1.0081152460984393e-05, 'epoch': 1.26}\n",
      "{'loss': 5.1563, 'learning_rate': 1.0561344537815125e-05, 'epoch': 1.32}\n",
      "{'loss': 5.0103, 'learning_rate': 1.1040576230492197e-05, 'epoch': 1.38}\n",
      "{'loss': 4.8563, 'learning_rate': 1.1520768307322929e-05, 'epoch': 1.44}\n",
      "{'loss': 4.735, 'learning_rate': 1.2000960384153661e-05, 'epoch': 1.5}\n",
      "{'loss': 4.6162, 'learning_rate': 1.2481152460984394e-05, 'epoch': 1.56}\n",
      "{'loss': 4.4997, 'learning_rate': 1.2961344537815128e-05, 'epoch': 1.62}\n",
      "{'loss': 4.3928, 'learning_rate': 1.344153661464586e-05, 'epoch': 1.68}\n",
      "{'loss': 4.272, 'learning_rate': 1.392076830732293e-05, 'epoch': 1.74}\n",
      "{'loss': 4.2011, 'learning_rate': 1.4400960384153662e-05, 'epoch': 1.8}\n",
      "{'loss': 4.1368, 'learning_rate': 1.4881152460984396e-05, 'epoch': 1.86}\n",
      "{'loss': 4.0871, 'learning_rate': 1.536134453781513e-05, 'epoch': 1.92}\n",
      "{'loss': 4.0581, 'learning_rate': 1.584153661464586e-05, 'epoch': 1.98}\n",
      "{'loss': 4.0118, 'learning_rate': 1.632076830732293e-05, 'epoch': 2.04}\n",
      "{'loss': 3.9747, 'learning_rate': 1.6800960384153665e-05, 'epoch': 2.1}\n",
      "{'loss': 3.9761, 'learning_rate': 1.7281152460984395e-05, 'epoch': 2.16}\n",
      "{'loss': 3.9406, 'learning_rate': 1.776134453781513e-05, 'epoch': 2.22}\n",
      "{'loss': 3.8869, 'learning_rate': 1.8240576230492197e-05, 'epoch': 2.28}\n",
      "{'loss': 3.8967, 'learning_rate': 1.872076830732293e-05, 'epoch': 2.34}\n",
      "{'loss': 3.885, 'learning_rate': 1.9200960384153665e-05, 'epoch': 2.4}\n",
      "{'loss': 3.8606, 'learning_rate': 1.9681152460984396e-05, 'epoch': 2.46}\n",
      "{'loss': 3.8275, 'learning_rate': 1.9982072829131654e-05, 'epoch': 2.52}\n",
      "{'loss': 3.8292, 'learning_rate': 1.992871815392824e-05, 'epoch': 2.58}\n",
      "{'loss': 3.7823, 'learning_rate': 1.987547018807523e-05, 'epoch': 2.64}\n",
      "{'loss': 3.7903, 'learning_rate': 1.9822115512871818e-05, 'epoch': 2.7}\n",
      "{'loss': 3.7598, 'learning_rate': 1.9768760837668402e-05, 'epoch': 2.76}\n",
      "{'loss': 3.7327, 'learning_rate': 1.9715406162464986e-05, 'epoch': 2.82}\n",
      "{'loss': 3.7184, 'learning_rate': 1.9662051487261573e-05, 'epoch': 2.88}\n",
      "{'loss': 3.6937, 'learning_rate': 1.960869681205816e-05, 'epoch': 2.94}\n",
      "{'loss': 3.6562, 'learning_rate': 1.955534213685474e-05, 'epoch': 3.0}\n",
      "{'loss': 3.6676, 'learning_rate': 1.9502094171001737e-05, 'epoch': 3.06}\n",
      "{'loss': 3.6536, 'learning_rate': 1.944873949579832e-05, 'epoch': 3.12}\n",
      "{'loss': 3.6239, 'learning_rate': 1.9395384820594908e-05, 'epoch': 3.18}\n",
      "{'loss': 3.6326, 'learning_rate': 1.9342030145391492e-05, 'epoch': 3.24}\n",
      "{'loss': 3.6268, 'learning_rate': 1.9288675470188076e-05, 'epoch': 3.3}\n",
      "{'loss': 3.6062, 'learning_rate': 1.9235427504335068e-05, 'epoch': 3.36}\n",
      "{'loss': 3.6077, 'learning_rate': 1.9182072829131655e-05, 'epoch': 3.42}\n",
      "{'loss': 3.5787, 'learning_rate': 1.912871815392824e-05, 'epoch': 3.48}\n",
      "{'loss': 3.5664, 'learning_rate': 1.9075363478724823e-05, 'epoch': 3.54}\n",
      "{'loss': 3.5589, 'learning_rate': 1.902200880352141e-05, 'epoch': 3.6}\n",
      "{'loss': 3.5424, 'learning_rate': 1.8968760837668403e-05, 'epoch': 3.66}\n",
      "{'loss': 3.5269, 'learning_rate': 1.8915406162464987e-05, 'epoch': 3.72}\n",
      "{'loss': 3.557, 'learning_rate': 1.886205148726157e-05, 'epoch': 3.78}\n",
      "{'loss': 3.5515, 'learning_rate': 1.8808696812058158e-05, 'epoch': 3.84}\n",
      "{'loss': 3.5112, 'learning_rate': 1.8755342136854745e-05, 'epoch': 3.9}\n",
      "{'loss': 3.5263, 'learning_rate': 1.870198746165133e-05, 'epoch': 3.96}\n",
      "{'loss': 3.5287, 'learning_rate': 1.8648632786447913e-05, 'epoch': 4.02}\n",
      "{'loss': 3.4985, 'learning_rate': 1.85952781112445e-05, 'epoch': 4.08}\n",
      "{'loss': 3.4905, 'learning_rate': 1.8542030145391493e-05, 'epoch': 4.14}\n",
      "{'loss': 3.462, 'learning_rate': 1.8488675470188077e-05, 'epoch': 4.2}\n",
      "{'loss': 3.4754, 'learning_rate': 1.843542750433507e-05, 'epoch': 4.26}\n",
      "{'loss': 3.4748, 'learning_rate': 1.8382072829131653e-05, 'epoch': 4.32}\n",
      "{'loss': 3.4727, 'learning_rate': 1.832871815392824e-05, 'epoch': 4.38}\n",
      "{'loss': 3.4586, 'learning_rate': 1.8275363478724824e-05, 'epoch': 4.44}\n",
      "{'loss': 3.4741, 'learning_rate': 1.8222008803521408e-05, 'epoch': 4.5}\n",
      "{'loss': 3.4256, 'learning_rate': 1.8168654128317995e-05, 'epoch': 4.56}\n",
      "{'loss': 3.4487, 'learning_rate': 1.8115406162464988e-05, 'epoch': 4.62}\n",
      "{'loss': 3.4464, 'learning_rate': 1.8062051487261575e-05, 'epoch': 4.68}\n",
      "{'loss': 3.4199, 'learning_rate': 1.800869681205816e-05, 'epoch': 4.74}\n",
      "{'loss': 3.4209, 'learning_rate': 1.7955342136854743e-05, 'epoch': 4.8}\n",
      "{'loss': 3.4313, 'learning_rate': 1.790198746165133e-05, 'epoch': 4.86}\n",
      "{'loss': 3.4127, 'learning_rate': 1.7848632786447914e-05, 'epoch': 4.92}\n",
      "{'loss': 3.4292, 'learning_rate': 1.7795278111244498e-05, 'epoch': 4.98}\n",
      "{'loss': 3.4139, 'learning_rate': 1.7741923436041086e-05, 'epoch': 5.04}\n",
      "{'loss': 3.4043, 'learning_rate': 1.7688782179538482e-05, 'epoch': 5.1}\n",
      "{'loss': 3.3776, 'learning_rate': 1.763542750433507e-05, 'epoch': 5.16}\n",
      "{'loss': 3.3822, 'learning_rate': 1.7582072829131654e-05, 'epoch': 5.22}\n",
      "{'loss': 3.3772, 'learning_rate': 1.7528718153928238e-05, 'epoch': 5.28}\n",
      "{'loss': 3.3641, 'learning_rate': 1.7475363478724825e-05, 'epoch': 5.34}\n",
      "{'loss': 3.3846, 'learning_rate': 1.7422008803521412e-05, 'epoch': 5.4}\n",
      "{'loss': 3.358, 'learning_rate': 1.7368654128317993e-05, 'epoch': 5.46}\n",
      "{'loss': 3.3817, 'learning_rate': 1.731529945311458e-05, 'epoch': 5.52}\n",
      "{'loss': 3.3658, 'learning_rate': 1.726215819661198e-05, 'epoch': 5.58}\n",
      "{'loss': 3.3709, 'learning_rate': 1.7208803521408564e-05, 'epoch': 5.64}\n",
      "{'loss': 3.3561, 'learning_rate': 1.715544884620515e-05, 'epoch': 5.7}\n",
      "{'loss': 3.3509, 'learning_rate': 1.7102094171001736e-05, 'epoch': 5.76}\n",
      "{'loss': 3.3569, 'learning_rate': 1.704873949579832e-05, 'epoch': 5.82}\n",
      "{'loss': 3.338, 'learning_rate': 1.6995384820594907e-05, 'epoch': 5.88}\n",
      "{'loss': 3.3458, 'learning_rate': 1.694203014539149e-05, 'epoch': 5.94}\n",
      "{'loss': 3.3344, 'learning_rate': 1.6888675470188075e-05, 'epoch': 6.0}\n",
      "{'loss': 3.338, 'learning_rate': 1.683542750433507e-05, 'epoch': 6.06}\n",
      "{'loss': 3.3218, 'learning_rate': 1.6782072829131655e-05, 'epoch': 6.12}\n",
      "{'loss': 3.321, 'learning_rate': 1.672871815392824e-05, 'epoch': 6.18}\n",
      "{'loss': 3.2995, 'learning_rate': 1.6675363478724823e-05, 'epoch': 6.24}\n",
      "{'loss': 3.3272, 'learning_rate': 1.6622115512871818e-05, 'epoch': 6.3}\n",
      "{'loss': 3.3181, 'learning_rate': 1.6568760837668402e-05, 'epoch': 6.36}\n",
      "{'loss': 3.305, 'learning_rate': 1.6515512871815394e-05, 'epoch': 6.42}\n",
      "{'loss': 3.2938, 'learning_rate': 1.6462158196611978e-05, 'epoch': 6.48}\n",
      "{'loss': 3.3347, 'learning_rate': 1.6408803521408565e-05, 'epoch': 6.54}\n",
      "{'loss': 3.293, 'learning_rate': 1.635544884620515e-05, 'epoch': 6.6}\n",
      "{'loss': 3.2863, 'learning_rate': 1.6302094171001733e-05, 'epoch': 6.66}\n",
      "{'loss': 3.3034, 'learning_rate': 1.624873949579832e-05, 'epoch': 6.72}\n",
      "{'loss': 3.2963, 'learning_rate': 1.6195384820594905e-05, 'epoch': 6.78}\n",
      "{'loss': 3.3037, 'learning_rate': 1.6142030145391492e-05, 'epoch': 6.84}\n",
      "{'loss': 3.2925, 'learning_rate': 1.6088782179538484e-05, 'epoch': 6.9}\n",
      "{'loss': 3.2699, 'learning_rate': 1.6035427504335068e-05, 'epoch': 6.96}\n",
      "{'loss': 3.2784, 'learning_rate': 1.5982072829131655e-05, 'epoch': 7.02}\n",
      "{'loss': 3.278, 'learning_rate': 1.592871815392824e-05, 'epoch': 7.08}\n",
      "{'loss': 3.2739, 'learning_rate': 1.587547018807523e-05, 'epoch': 7.14}\n",
      "{'loss': 3.2589, 'learning_rate': 1.5822222222222224e-05, 'epoch': 7.2}\n",
      "{'loss': 3.2729, 'learning_rate': 1.5768867547018808e-05, 'epoch': 7.26}\n",
      "{'loss': 3.2672, 'learning_rate': 1.5715512871815395e-05, 'epoch': 7.32}\n",
      "{'loss': 3.287, 'learning_rate': 1.566215819661198e-05, 'epoch': 7.38}\n",
      "{'loss': 3.2537, 'learning_rate': 1.5608803521408563e-05, 'epoch': 7.44}\n",
      "{'loss': 3.2459, 'learning_rate': 1.555544884620515e-05, 'epoch': 7.5}\n",
      "{'loss': 3.2588, 'learning_rate': 1.5502094171001734e-05, 'epoch': 7.56}\n",
      "{'loss': 3.2601, 'learning_rate': 1.544873949579832e-05, 'epoch': 7.62}\n",
      "{'loss': 3.2473, 'learning_rate': 1.5395491529945314e-05, 'epoch': 7.68}\n",
      "{'loss': 3.2496, 'learning_rate': 1.5342136854741898e-05, 'epoch': 7.74}\n",
      "{'loss': 3.2577, 'learning_rate': 1.528888888888889e-05, 'epoch': 7.8}\n",
      "{'loss': 3.2304, 'learning_rate': 1.5235534213685474e-05, 'epoch': 7.86}\n",
      "{'loss': 3.2357, 'learning_rate': 1.5182179538482061e-05, 'epoch': 7.92}\n",
      "{'loss': 3.2333, 'learning_rate': 1.5128824863278647e-05, 'epoch': 7.98}\n",
      "{'loss': 3.2264, 'learning_rate': 1.5075470188075232e-05, 'epoch': 8.04}\n",
      "{'loss': 3.2296, 'learning_rate': 1.5022115512871818e-05, 'epoch': 8.1}\n",
      "{'loss': 3.2357, 'learning_rate': 1.4968760837668402e-05, 'epoch': 8.16}\n",
      "{'loss': 3.2332, 'learning_rate': 1.4915406162464988e-05, 'epoch': 8.22}\n",
      "{'loss': 3.2266, 'learning_rate': 1.486215819661198e-05, 'epoch': 8.28}\n",
      "{'loss': 3.2194, 'learning_rate': 1.4808803521408565e-05, 'epoch': 8.34}\n",
      "{'loss': 3.2215, 'learning_rate': 1.475544884620515e-05, 'epoch': 8.4}\n",
      "{'loss': 3.207, 'learning_rate': 1.4702094171001735e-05, 'epoch': 8.46}\n",
      "{'loss': 3.2183, 'learning_rate': 1.4648846205148727e-05, 'epoch': 8.52}\n",
      "{'loss': 3.202, 'learning_rate': 1.4595491529945315e-05, 'epoch': 8.58}\n",
      "{'loss': 3.2176, 'learning_rate': 1.4542136854741897e-05, 'epoch': 8.64}\n",
      "{'loss': 3.2256, 'learning_rate': 1.4488782179538482e-05, 'epoch': 8.7}\n",
      "{'loss': 3.2257, 'learning_rate': 1.4435534213685476e-05, 'epoch': 8.76}\n",
      "{'loss': 3.1978, 'learning_rate': 1.4382179538482062e-05, 'epoch': 8.82}\n",
      "{'loss': 3.2055, 'learning_rate': 1.4328824863278646e-05, 'epoch': 8.88}\n",
      "{'loss': 3.1956, 'learning_rate': 1.4275470188075232e-05, 'epoch': 8.94}\n",
      "{'loss': 3.1879, 'learning_rate': 1.4222222222222224e-05, 'epoch': 9.0}\n",
      "{'loss': 3.2035, 'learning_rate': 1.416886754701881e-05, 'epoch': 9.06}\n",
      "{'loss': 3.1999, 'learning_rate': 1.4115512871815393e-05, 'epoch': 9.12}\n",
      "{'loss': 3.2044, 'learning_rate': 1.4062158196611979e-05, 'epoch': 9.18}\n",
      "{'loss': 3.208, 'learning_rate': 1.4008910230758973e-05, 'epoch': 9.24}\n",
      "{'loss': 3.1954, 'learning_rate': 1.3955555555555558e-05, 'epoch': 9.3}\n",
      "{'loss': 3.1839, 'learning_rate': 1.390220088035214e-05, 'epoch': 9.36}\n",
      "{'loss': 3.1847, 'learning_rate': 1.3848846205148726e-05, 'epoch': 9.42}\n",
      "{'loss': 3.1862, 'learning_rate': 1.379559823929572e-05, 'epoch': 9.48}\n",
      "{'loss': 3.1812, 'learning_rate': 1.3742243564092306e-05, 'epoch': 9.54}\n",
      "{'loss': 3.1789, 'learning_rate': 1.368888888888889e-05, 'epoch': 9.6}\n",
      "{'loss': 3.1596, 'learning_rate': 1.3635534213685475e-05, 'epoch': 9.66}\n",
      "{'loss': 3.1855, 'learning_rate': 1.3582286247832468e-05, 'epoch': 9.72}\n",
      "{'loss': 3.1761, 'learning_rate': 1.3528931572629053e-05, 'epoch': 9.78}\n",
      "{'loss': 3.1954, 'learning_rate': 1.3475576897425637e-05, 'epoch': 9.84}\n",
      "{'loss': 3.1625, 'learning_rate': 1.3422222222222223e-05, 'epoch': 9.9}\n",
      "{'loss': 3.1703, 'learning_rate': 1.3368974256369217e-05, 'epoch': 9.96}\n",
      "{'loss': 3.1816, 'learning_rate': 1.3315619581165802e-05, 'epoch': 10.02}\n",
      "{'loss': 3.1708, 'learning_rate': 1.3262264905962385e-05, 'epoch': 10.08}\n",
      "{'loss': 3.1564, 'learning_rate': 1.3208910230758972e-05, 'epoch': 10.14}\n",
      "{'loss': 3.1422, 'learning_rate': 1.3155555555555558e-05, 'epoch': 10.2}\n",
      "{'loss': 3.1462, 'learning_rate': 1.310230758970255e-05, 'epoch': 10.26}\n",
      "{'loss': 3.1458, 'learning_rate': 1.3048952914499134e-05, 'epoch': 10.32}\n",
      "{'loss': 3.1569, 'learning_rate': 1.299559823929572e-05, 'epoch': 10.38}\n",
      "{'loss': 3.1926, 'learning_rate': 1.2942243564092305e-05, 'epoch': 10.44}\n",
      "{'loss': 3.182, 'learning_rate': 1.2888995598239297e-05, 'epoch': 10.5}\n",
      "{'loss': 3.1511, 'learning_rate': 1.2835640923035881e-05, 'epoch': 10.56}\n",
      "{'loss': 3.155, 'learning_rate': 1.2782286247832467e-05, 'epoch': 10.62}\n",
      "{'loss': 3.1599, 'learning_rate': 1.2728931572629052e-05, 'epoch': 10.68}\n",
      "{'loss': 3.1404, 'learning_rate': 1.2675683606776046e-05, 'epoch': 10.74}\n",
      "{'loss': 3.1137, 'learning_rate': 1.262232893157263e-05, 'epoch': 10.8}\n",
      "{'loss': 3.1702, 'learning_rate': 1.2568974256369216e-05, 'epoch': 10.86}\n",
      "{'loss': 3.1511, 'learning_rate': 1.2515619581165801e-05, 'epoch': 10.92}\n",
      "{'loss': 3.1619, 'learning_rate': 1.2462371615312794e-05, 'epoch': 10.98}\n",
      "{'loss': 3.1345, 'learning_rate': 1.2409016940109378e-05, 'epoch': 11.04}\n",
      "{'loss': 3.146, 'learning_rate': 1.2355662264905963e-05, 'epoch': 11.1}\n",
      "{'loss': 3.1491, 'learning_rate': 1.2302307589702549e-05, 'epoch': 11.16}\n",
      "{'loss': 3.1372, 'learning_rate': 1.2249059623849543e-05, 'epoch': 11.22}\n",
      "{'loss': 3.148, 'learning_rate': 1.2195704948646125e-05, 'epoch': 11.28}\n",
      "{'loss': 3.1319, 'learning_rate': 1.214235027344271e-05, 'epoch': 11.34}\n",
      "{'loss': 3.1176, 'learning_rate': 1.2088995598239296e-05, 'epoch': 11.4}\n",
      "{'loss': 3.144, 'learning_rate': 1.203574763238629e-05, 'epoch': 11.46}\n",
      "{'loss': 3.145, 'learning_rate': 1.1982392957182874e-05, 'epoch': 11.52}\n",
      "{'loss': 3.1331, 'learning_rate': 1.192903828197946e-05, 'epoch': 11.58}\n",
      "{'loss': 3.1333, 'learning_rate': 1.1875683606776045e-05, 'epoch': 11.64}\n",
      "{'loss': 3.1396, 'learning_rate': 1.1822435640923037e-05, 'epoch': 11.7}\n",
      "{'loss': 3.131, 'learning_rate': 1.1769080965719621e-05, 'epoch': 11.76}\n",
      "{'loss': 3.1269, 'learning_rate': 1.1715726290516207e-05, 'epoch': 11.82}\n",
      "{'loss': 3.1388, 'learning_rate': 1.1662371615312793e-05, 'epoch': 11.88}\n",
      "{'loss': 3.1064, 'learning_rate': 1.1609123649459787e-05, 'epoch': 11.94}\n",
      "{'loss': 3.1029, 'learning_rate': 1.1555768974256369e-05, 'epoch': 12.0}\n",
      "{'loss': 3.1077, 'learning_rate': 1.1502414299052954e-05, 'epoch': 12.06}\n",
      "{'loss': 3.1255, 'learning_rate': 1.1449059623849542e-05, 'epoch': 12.12}\n",
      "{'loss': 3.1023, 'learning_rate': 1.1395811657996534e-05, 'epoch': 12.18}\n",
      "{'loss': 3.1297, 'learning_rate': 1.1342456982793118e-05, 'epoch': 12.24}\n",
      "{'loss': 3.1259, 'learning_rate': 1.1289102307589704e-05, 'epoch': 12.3}\n",
      "{'loss': 3.087, 'learning_rate': 1.123574763238629e-05, 'epoch': 12.36}\n",
      "{'loss': 3.1121, 'learning_rate': 1.1182392957182875e-05, 'epoch': 12.42}\n",
      "{'loss': 3.1068, 'learning_rate': 1.1129144991329865e-05, 'epoch': 12.48}\n",
      "{'loss': 3.109, 'learning_rate': 1.1075790316126451e-05, 'epoch': 12.55}\n",
      "{'loss': 3.0925, 'learning_rate': 1.1022435640923037e-05, 'epoch': 12.61}\n",
      "{'loss': 3.0872, 'learning_rate': 1.0969080965719622e-05, 'epoch': 12.67}\n",
      "{'loss': 3.1145, 'learning_rate': 1.0915832999866613e-05, 'epoch': 12.73}\n",
      "{'loss': 3.1248, 'learning_rate': 1.08624783246632e-05, 'epoch': 12.79}\n",
      "{'loss': 3.0971, 'learning_rate': 1.0809123649459786e-05, 'epoch': 12.85}\n",
      "{'loss': 3.1174, 'learning_rate': 1.0755768974256371e-05, 'epoch': 12.91}\n",
      "{'loss': 3.119, 'learning_rate': 1.0702521008403362e-05, 'epoch': 12.97}\n",
      "{'loss': 3.1207, 'learning_rate': 1.0649166333199947e-05, 'epoch': 13.03}\n",
      "{'loss': 3.109, 'learning_rate': 1.0595811657996533e-05, 'epoch': 13.09}\n",
      "{'loss': 3.1094, 'learning_rate': 1.0542563692143525e-05, 'epoch': 13.15}\n",
      "{'loss': 3.1044, 'learning_rate': 1.0489209016940109e-05, 'epoch': 13.21}\n",
      "{'loss': 3.0807, 'learning_rate': 1.0435854341736695e-05, 'epoch': 13.27}\n",
      "{'loss': 3.0942, 'learning_rate': 1.038249966653328e-05, 'epoch': 13.33}\n",
      "{'loss': 3.097, 'learning_rate': 1.0329144991329866e-05, 'epoch': 13.39}\n",
      "{'loss': 3.0889, 'learning_rate': 1.027579031612645e-05, 'epoch': 13.45}\n",
      "{'loss': 3.1121, 'learning_rate': 1.0222435640923036e-05, 'epoch': 13.51}\n",
      "{'loss': 3.0921, 'learning_rate': 1.0169080965719621e-05, 'epoch': 13.57}\n",
      "{'loss': 3.1018, 'learning_rate': 1.0115832999866615e-05, 'epoch': 13.63}\n",
      "{'loss': 3.0854, 'learning_rate': 1.00624783246632e-05, 'epoch': 13.69}\n",
      "{'loss': 3.0827, 'learning_rate': 1.0009123649459785e-05, 'epoch': 13.75}\n",
      "{'loss': 3.0785, 'learning_rate': 9.95576897425637e-06, 'epoch': 13.81}\n",
      "{'loss': 3.0893, 'learning_rate': 9.902521008403363e-06, 'epoch': 13.87}\n",
      "{'loss': 3.0776, 'learning_rate': 9.849166333199948e-06, 'epoch': 13.93}\n",
      "{'loss': 3.0825, 'learning_rate': 9.795811657996532e-06, 'epoch': 13.99}\n",
      "{'loss': 3.0786, 'learning_rate': 9.742456982793118e-06, 'epoch': 14.05}\n",
      "{'loss': 3.0914, 'learning_rate': 9.68920901694011e-06, 'epoch': 14.11}\n",
      "{'loss': 3.0602, 'learning_rate': 9.635854341736696e-06, 'epoch': 14.17}\n",
      "{'loss': 3.0763, 'learning_rate': 9.58249966653328e-06, 'epoch': 14.23}\n",
      "{'loss': 3.0923, 'learning_rate': 9.529144991329865e-06, 'epoch': 14.29}\n",
      "{'loss': 3.0894, 'learning_rate': 9.475790316126451e-06, 'epoch': 14.35}\n",
      "{'loss': 3.0726, 'learning_rate': 9.422435640923037e-06, 'epoch': 14.41}\n",
      "{'loss': 3.0637, 'learning_rate': 9.369080965719622e-06, 'epoch': 14.47}\n",
      "{'loss': 3.0786, 'learning_rate': 9.315726290516206e-06, 'epoch': 14.53}\n",
      "{'loss': 3.0707, 'learning_rate': 9.262478324663198e-06, 'epoch': 14.59}\n",
      "{'loss': 3.0715, 'learning_rate': 9.209123649459784e-06, 'epoch': 14.65}\n",
      "{'loss': 3.073, 'learning_rate': 9.15576897425637e-06, 'epoch': 14.71}\n",
      "{'loss': 3.075, 'learning_rate': 9.102414299052955e-06, 'epoch': 14.77}\n",
      "{'loss': 3.0486, 'learning_rate': 9.049166333199947e-06, 'epoch': 14.83}\n",
      "{'loss': 3.0799, 'learning_rate': 8.99591836734694e-06, 'epoch': 14.89}\n",
      "{'loss': 3.0993, 'learning_rate': 8.942563692143524e-06, 'epoch': 14.95}\n",
      "{'loss': 3.0914, 'learning_rate': 8.889209016940111e-06, 'epoch': 15.01}\n",
      "{'loss': 3.061, 'learning_rate': 8.835854341736695e-06, 'epoch': 15.07}\n",
      "{'loss': 3.0553, 'learning_rate': 8.78249966653328e-06, 'epoch': 15.13}\n",
      "{'loss': 3.0504, 'learning_rate': 8.729144991329866e-06, 'epoch': 15.19}\n",
      "{'loss': 3.0741, 'learning_rate': 8.675790316126452e-06, 'epoch': 15.25}\n",
      "{'loss': 3.0665, 'learning_rate': 8.622435640923038e-06, 'epoch': 15.31}\n",
      "{'loss': 3.075, 'learning_rate': 8.569187675070028e-06, 'epoch': 15.37}\n",
      "{'loss': 3.063, 'learning_rate': 8.515832999866615e-06, 'epoch': 15.43}\n",
      "{'loss': 3.0771, 'learning_rate': 8.4624783246632e-06, 'epoch': 15.49}\n",
      "{'loss': 3.0664, 'learning_rate': 8.409123649459785e-06, 'epoch': 15.55}\n",
      "{'loss': 3.0614, 'learning_rate': 8.355875683606777e-06, 'epoch': 15.61}\n",
      "{'loss': 3.0674, 'learning_rate': 8.302521008403363e-06, 'epoch': 15.67}\n",
      "{'loss': 3.0587, 'learning_rate': 8.249166333199947e-06, 'epoch': 15.73}\n",
      "{'loss': 3.0473, 'learning_rate': 8.195811657996532e-06, 'epoch': 15.79}\n",
      "{'loss': 3.061, 'learning_rate': 8.142563692143524e-06, 'epoch': 15.85}\n",
      "{'loss': 3.0693, 'learning_rate': 8.08920901694011e-06, 'epoch': 15.91}\n",
      "{'loss': 3.0395, 'learning_rate': 8.035854341736696e-06, 'epoch': 15.97}\n",
      "{'loss': 3.046, 'learning_rate': 7.982499666533281e-06, 'epoch': 16.03}\n",
      "{'loss': 3.0313, 'learning_rate': 7.929144991329865e-06, 'epoch': 16.09}\n",
      "{'loss': 3.0528, 'learning_rate': 7.87589702547686e-06, 'epoch': 16.15}\n",
      "{'loss': 3.061, 'learning_rate': 7.822542350273443e-06, 'epoch': 16.21}\n",
      "{'loss': 3.0676, 'learning_rate': 7.769187675070029e-06, 'epoch': 16.27}\n",
      "{'loss': 3.0667, 'learning_rate': 7.715832999866614e-06, 'epoch': 16.33}\n",
      "{'loss': 3.058, 'learning_rate': 7.662585034013607e-06, 'epoch': 16.39}\n",
      "{'loss': 3.0458, 'learning_rate': 7.609230358810191e-06, 'epoch': 16.45}\n",
      "{'loss': 3.043, 'learning_rate': 7.555875683606777e-06, 'epoch': 16.51}\n",
      "{'loss': 3.036, 'learning_rate': 7.502521008403362e-06, 'epoch': 16.57}\n",
      "{'loss': 3.0466, 'learning_rate': 7.449273042550355e-06, 'epoch': 16.63}\n",
      "{'loss': 3.0593, 'learning_rate': 7.39591836734694e-06, 'epoch': 16.69}\n",
      "{'loss': 3.0471, 'learning_rate': 7.342563692143525e-06, 'epoch': 16.75}\n",
      "{'loss': 3.0379, 'learning_rate': 7.28920901694011e-06, 'epoch': 16.81}\n",
      "{'loss': 3.0075, 'learning_rate': 7.235854341736696e-06, 'epoch': 16.87}\n",
      "{'loss': 3.0402, 'learning_rate': 7.182606375883687e-06, 'epoch': 16.93}\n",
      "{'loss': 3.0474, 'learning_rate': 7.129251700680273e-06, 'epoch': 16.99}\n",
      "{'loss': 3.0582, 'learning_rate': 7.0758970254768575e-06, 'epoch': 17.05}\n",
      "{'loss': 3.0299, 'learning_rate': 7.022542350273443e-06, 'epoch': 17.11}\n",
      "{'loss': 3.0413, 'learning_rate': 6.969294384420435e-06, 'epoch': 17.17}\n",
      "{'loss': 3.0529, 'learning_rate': 6.915939709217021e-06, 'epoch': 17.23}\n",
      "{'loss': 3.0439, 'learning_rate': 6.862585034013606e-06, 'epoch': 17.29}\n",
      "{'loss': 3.0406, 'learning_rate': 6.8092303588101914e-06, 'epoch': 17.35}\n",
      "{'loss': 3.0245, 'learning_rate': 6.7559823929571835e-06, 'epoch': 17.41}\n",
      "{'loss': 3.039, 'learning_rate': 6.702627717753769e-06, 'epoch': 17.47}\n",
      "{'loss': 3.0281, 'learning_rate': 6.649273042550354e-06, 'epoch': 17.53}\n",
      "{'loss': 3.0345, 'learning_rate': 6.59591836734694e-06, 'epoch': 17.59}\n",
      "{'loss': 3.0352, 'learning_rate': 6.542670401493931e-06, 'epoch': 17.65}\n",
      "{'loss': 3.0485, 'learning_rate': 6.489315726290517e-06, 'epoch': 17.71}\n",
      "{'loss': 3.0305, 'learning_rate': 6.435961051087101e-06, 'epoch': 17.77}\n",
      "{'loss': 3.0359, 'learning_rate': 6.382606375883688e-06, 'epoch': 17.83}\n",
      "{'loss': 3.0286, 'learning_rate': 6.329358410030679e-06, 'epoch': 17.89}\n",
      "{'loss': 3.0141, 'learning_rate': 6.276003734827265e-06, 'epoch': 17.95}\n",
      "{'loss': 3.0251, 'learning_rate': 6.22264905962385e-06, 'epoch': 18.01}\n",
      "{'loss': 3.049, 'learning_rate': 6.169294384420435e-06, 'epoch': 18.07}\n",
      "{'loss': 3.0247, 'learning_rate': 6.11593970921702e-06, 'epoch': 18.13}\n",
      "{'loss': 3.0208, 'learning_rate': 6.062691743364013e-06, 'epoch': 18.19}\n",
      "{'loss': 3.0329, 'learning_rate': 6.009337068160598e-06, 'epoch': 18.25}\n",
      "{'loss': 3.0098, 'learning_rate': 5.9559823929571835e-06, 'epoch': 18.31}\n",
      "{'loss': 3.0377, 'learning_rate': 5.902627717753768e-06, 'epoch': 18.37}\n",
      "{'loss': 3.0404, 'learning_rate': 5.849379751900761e-06, 'epoch': 18.43}\n",
      "{'loss': 3.0271, 'learning_rate': 5.796025076697346e-06, 'epoch': 18.49}\n",
      "{'loss': 3.0258, 'learning_rate': 5.742670401493932e-06, 'epoch': 18.55}\n",
      "{'loss': 3.0287, 'learning_rate': 5.689315726290517e-06, 'epoch': 18.61}\n",
      "{'loss': 3.0271, 'learning_rate': 5.6360677604375095e-06, 'epoch': 18.67}\n",
      "{'loss': 3.009, 'learning_rate': 5.5827130852340935e-06, 'epoch': 18.73}\n",
      "{'loss': 3.0284, 'learning_rate': 5.52935841003068e-06, 'epoch': 18.79}\n",
      "{'loss': 3.0367, 'learning_rate': 5.476003734827264e-06, 'epoch': 18.85}\n",
      "{'loss': 3.0151, 'learning_rate': 5.4226490596238505e-06, 'epoch': 18.91}\n",
      "{'loss': 3.0089, 'learning_rate': 5.369401093770842e-06, 'epoch': 18.97}\n",
      "{'loss': 3.0168, 'learning_rate': 5.316046418567427e-06, 'epoch': 19.03}\n",
      "{'loss': 3.0033, 'learning_rate': 5.262691743364012e-06, 'epoch': 19.09}\n",
      "{'loss': 3.0103, 'learning_rate': 5.209337068160598e-06, 'epoch': 19.15}\n",
      "{'loss': 3.0126, 'learning_rate': 5.15608910230759e-06, 'epoch': 19.21}\n",
      "{'loss': 3.0281, 'learning_rate': 5.102734427104176e-06, 'epoch': 19.27}\n",
      "{'loss': 3.0175, 'learning_rate': 5.0493797519007605e-06, 'epoch': 19.33}\n",
      "{'loss': 3.0229, 'learning_rate': 4.996025076697346e-06, 'epoch': 19.39}\n",
      "{'loss': 3.038, 'learning_rate': 4.942777110844338e-06, 'epoch': 19.45}\n",
      "{'loss': 3.0269, 'learning_rate': 4.889422435640924e-06, 'epoch': 19.51}\n",
      "{'loss': 3.003, 'learning_rate': 4.836067760437509e-06, 'epoch': 19.57}\n",
      "{'loss': 3.0182, 'learning_rate': 4.782713085234094e-06, 'epoch': 19.63}\n",
      "{'loss': 3.0094, 'learning_rate': 4.729358410030679e-06, 'epoch': 19.69}\n",
      "{'loss': 3.0036, 'learning_rate': 4.676110444177671e-06, 'epoch': 19.75}\n",
      "{'loss': 3.0136, 'learning_rate': 4.622755768974257e-06, 'epoch': 19.81}\n",
      "{'loss': 3.013, 'learning_rate': 4.569401093770842e-06, 'epoch': 19.87}\n",
      "{'loss': 3.0237, 'learning_rate': 4.5160464185674275e-06, 'epoch': 19.93}\n",
      "{'loss': 2.9926, 'learning_rate': 4.4627984527144195e-06, 'epoch': 19.99}\n",
      "{'loss': 3.0179, 'learning_rate': 4.409443777511005e-06, 'epoch': 20.05}\n",
      "{'loss': 3.0019, 'learning_rate': 4.35608910230759e-06, 'epoch': 20.11}\n",
      "{'loss': 3.03, 'learning_rate': 4.302734427104176e-06, 'epoch': 20.17}\n",
      "{'loss': 2.9925, 'learning_rate': 4.249486461251168e-06, 'epoch': 20.23}\n",
      "{'loss': 3.0179, 'learning_rate': 4.196131786047753e-06, 'epoch': 20.29}\n",
      "{'loss': 3.0161, 'learning_rate': 4.142777110844338e-06, 'epoch': 20.35}\n",
      "{'loss': 3.0082, 'learning_rate': 4.089422435640923e-06, 'epoch': 20.41}\n",
      "{'loss': 3.0129, 'learning_rate': 4.036174469787916e-06, 'epoch': 20.47}\n",
      "{'loss': 3.0128, 'learning_rate': 3.982819794584501e-06, 'epoch': 20.53}\n",
      "{'loss': 3.0098, 'learning_rate': 3.9294651193810865e-06, 'epoch': 20.59}\n",
      "{'loss': 2.9824, 'learning_rate': 3.876110444177671e-06, 'epoch': 20.65}\n",
      "{'loss': 3.0181, 'learning_rate': 3.822862478324663e-06, 'epoch': 20.71}\n",
      "{'loss': 2.996, 'learning_rate': 3.769507803121249e-06, 'epoch': 20.77}\n",
      "{'loss': 3.0261, 'learning_rate': 3.7161531279178343e-06, 'epoch': 20.83}\n",
      "{'loss': 2.9939, 'learning_rate': 3.6627984527144196e-06, 'epoch': 20.89}\n",
      "{'loss': 3.0034, 'learning_rate': 3.609443777511005e-06, 'epoch': 20.95}\n",
      "{'loss': 2.9973, 'learning_rate': 3.556195811657997e-06, 'epoch': 21.01}\n",
      "{'loss': 3.0005, 'learning_rate': 3.502841136454582e-06, 'epoch': 21.07}\n",
      "{'loss': 3.0027, 'learning_rate': 3.4494864612511674e-06, 'epoch': 21.13}\n",
      "{'loss': 3.0141, 'learning_rate': 3.3961317860477526e-06, 'epoch': 21.19}\n",
      "{'loss': 2.9972, 'learning_rate': 3.342777110844338e-06, 'epoch': 21.25}\n",
      "{'loss': 2.9946, 'learning_rate': 3.2895291449913304e-06, 'epoch': 21.31}\n",
      "{'loss': 2.9999, 'learning_rate': 3.2361744697879156e-06, 'epoch': 21.37}\n",
      "{'loss': 2.9894, 'learning_rate': 3.182819794584501e-06, 'epoch': 21.43}\n",
      "{'loss': 3.0107, 'learning_rate': 3.129465119381086e-06, 'epoch': 21.49}\n",
      "{'loss': 2.9858, 'learning_rate': 3.076217153528078e-06, 'epoch': 21.55}\n",
      "{'loss': 3.0001, 'learning_rate': 3.0228624783246634e-06, 'epoch': 21.61}\n",
      "{'loss': 3.0013, 'learning_rate': 2.9695078031212487e-06, 'epoch': 21.67}\n",
      "{'loss': 3.0005, 'learning_rate': 2.916153127917834e-06, 'epoch': 21.73}\n",
      "{'loss': 2.9856, 'learning_rate': 2.8629051620648264e-06, 'epoch': 21.79}\n",
      "{'loss': 2.9838, 'learning_rate': 2.8095504868614117e-06, 'epoch': 21.85}\n",
      "{'loss': 2.9943, 'learning_rate': 2.756195811657997e-06, 'epoch': 21.91}\n",
      "{'loss': 3.0103, 'learning_rate': 2.702841136454582e-06, 'epoch': 21.97}\n",
      "{'loss': 3.0093, 'learning_rate': 2.6495931706015742e-06, 'epoch': 22.03}\n",
      "{'loss': 3.0013, 'learning_rate': 2.5962384953981595e-06, 'epoch': 22.09}\n",
      "{'loss': 3.0036, 'learning_rate': 2.5428838201947447e-06, 'epoch': 22.15}\n",
      "{'loss': 2.9948, 'learning_rate': 2.48952914499133e-06, 'epoch': 22.21}\n",
      "{'loss': 2.9856, 'learning_rate': 2.4362811791383225e-06, 'epoch': 22.27}\n",
      "{'loss': 2.983, 'learning_rate': 2.3829265039349077e-06, 'epoch': 22.33}\n",
      "{'loss': 3.0024, 'learning_rate': 2.329571828731493e-06, 'epoch': 22.39}\n",
      "{'loss': 2.9834, 'learning_rate': 2.2762171535280782e-06, 'epoch': 22.45}\n",
      "{'loss': 2.9919, 'learning_rate': 2.2228624783246635e-06, 'epoch': 22.51}\n",
      "{'loss': 2.987, 'learning_rate': 2.1696145124716555e-06, 'epoch': 22.57}\n",
      "{'loss': 2.9615, 'learning_rate': 2.116259837268241e-06, 'epoch': 22.63}\n",
      "{'loss': 2.9857, 'learning_rate': 2.062905162064826e-06, 'epoch': 22.69}\n",
      "{'loss': 3.0199, 'learning_rate': 2.0095504868614113e-06, 'epoch': 22.75}\n",
      "{'loss': 3.0075, 'learning_rate': 1.9563025210084034e-06, 'epoch': 22.81}\n",
      "{'loss': 2.9918, 'learning_rate': 1.9029478458049888e-06, 'epoch': 22.87}\n",
      "{'loss': 3.002, 'learning_rate': 1.849593170601574e-06, 'epoch': 22.93}\n",
      "{'loss': 3.0026, 'learning_rate': 1.7962384953981593e-06, 'epoch': 22.99}\n",
      "{'loss': 2.9789, 'learning_rate': 1.7429905295451516e-06, 'epoch': 23.05}\n",
      "{'loss': 3.0085, 'learning_rate': 1.6896358543417368e-06, 'epoch': 23.11}\n",
      "{'loss': 2.977, 'learning_rate': 1.636281179138322e-06, 'epoch': 23.17}\n",
      "{'loss': 2.9927, 'learning_rate': 1.5829265039349073e-06, 'epoch': 23.23}\n",
      "{'loss': 2.9773, 'learning_rate': 1.5296785380818996e-06, 'epoch': 23.29}\n",
      "{'loss': 3.0114, 'learning_rate': 1.4763238628784849e-06, 'epoch': 23.35}\n",
      "{'loss': 2.9899, 'learning_rate': 1.4229691876750701e-06, 'epoch': 23.41}\n",
      "{'loss': 2.9783, 'learning_rate': 1.3696145124716554e-06, 'epoch': 23.47}\n",
      "{'loss': 3.0222, 'learning_rate': 1.3162598372682408e-06, 'epoch': 23.53}\n",
      "{'loss': 2.9855, 'learning_rate': 1.263011871415233e-06, 'epoch': 23.59}\n",
      "{'loss': 2.9899, 'learning_rate': 1.2096571962118182e-06, 'epoch': 23.65}\n",
      "{'loss': 2.9914, 'learning_rate': 1.1563025210084034e-06, 'epoch': 23.71}\n",
      "{'loss': 2.9656, 'learning_rate': 1.1029478458049886e-06, 'epoch': 23.77}\n",
      "{'loss': 2.988, 'learning_rate': 1.049699879951981e-06, 'epoch': 23.83}\n",
      "{'loss': 3.0014, 'learning_rate': 9.963452047485662e-07, 'epoch': 23.89}\n",
      "{'loss': 2.9683, 'learning_rate': 9.429905295451515e-07, 'epoch': 23.95}\n",
      "{'loss': 2.9794, 'learning_rate': 8.896358543417368e-07, 'epoch': 24.01}\n",
      "{'loss': 2.9851, 'learning_rate': 8.363878884887289e-07, 'epoch': 24.07}\n",
      "{'loss': 2.9924, 'learning_rate': 7.830332132853142e-07, 'epoch': 24.13}\n",
      "{'loss': 2.9925, 'learning_rate': 7.296785380818995e-07, 'epoch': 24.19}\n",
      "{'loss': 2.9938, 'learning_rate': 6.763238628784848e-07, 'epoch': 24.25}\n",
      "{'loss': 2.9781, 'learning_rate': 6.230758970254769e-07, 'epoch': 24.31}\n",
      "{'loss': 2.9803, 'learning_rate': 5.697212218220622e-07, 'epoch': 24.37}\n",
      "{'loss': 2.9808, 'learning_rate': 5.163665466186475e-07, 'epoch': 24.43}\n",
      "{'loss': 2.9748, 'learning_rate': 4.630118714152328e-07, 'epoch': 24.49}\n",
      "{'loss': 2.9732, 'learning_rate': 4.096571962118181e-07, 'epoch': 24.55}\n",
      "{'loss': 3.006, 'learning_rate': 3.564092303588102e-07, 'epoch': 24.61}\n",
      "{'loss': 2.9714, 'learning_rate': 3.030545551553955e-07, 'epoch': 24.67}\n",
      "{'loss': 2.964, 'learning_rate': 2.496998799519808e-07, 'epoch': 24.73}\n",
      "{'loss': 2.9771, 'learning_rate': 1.9634520474856608e-07, 'epoch': 24.79}\n",
      "{'loss': 2.9828, 'learning_rate': 1.429905295451514e-07, 'epoch': 24.85}\n",
      "{'loss': 2.9724, 'learning_rate': 8.974256369214352e-08, 'epoch': 24.91}\n",
      "{'loss': 3.0069, 'learning_rate': 3.638788848872883e-08, 'epoch': 24.97}\n",
      "{'train_runtime': 43960.9775, 'train_samples_per_second': 85.263, 'train_steps_per_second': 4.737, 'train_loss': 3.354252106115884, 'epoch': 25.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacec312c95b482b960c2e54e093b008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 20.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [\"persuratan-dataset-final-fourth.txt\"]\n",
    "tokenizer_file = \"cahya/bert-base-indonesian-522M\"\n",
    "batch_size = 18\n",
    "model_checkpoint = \"cahya/bert-base-indonesian-522M\"\n",
    "model_name = \"wirawan-finetuned-persuratan-25\"\n",
    "\n",
    "run_finetune(data,tokenizer_file, batch_size, model_checkpoint, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/agus/.cache/huggingface/datasets/text/suffix_array-b1e8db2c7c338967/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4283ba522060438b968693e39677eab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 47783\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 11946\n",
      "    })\n",
      "})\n",
      "The max length for the tokenizer is: 1000000000000000019884624838656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f8a0b6e9f94729be808fef957301e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/47783 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b2c675b05b4232a3ddce1619d82c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/11946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1e4577aa284cd79cae71d762e5f9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/47783 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed46f6b5223848ac94e82b72e9248b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/11946 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_dataset DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 430194\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 108435\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cfc3cad6914365863f3d4d272e3f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/597500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.4241, 'learning_rate': 1.6736401673640168e-07, 'epoch': 0.02}\n",
      "{'loss': 6.0498, 'learning_rate': 3.3472803347280335e-07, 'epoch': 0.04}\n",
      "{'loss': 5.8664, 'learning_rate': 5.020920502092051e-07, 'epoch': 0.06}\n",
      "{'loss': 5.7809, 'learning_rate': 6.694560669456067e-07, 'epoch': 0.08}\n",
      "{'loss': 5.7279, 'learning_rate': 8.368200836820084e-07, 'epoch': 0.1}\n",
      "{'loss': 5.6836, 'learning_rate': 1.0041841004184101e-06, 'epoch': 0.13}\n",
      "{'loss': 5.6462, 'learning_rate': 1.1715481171548119e-06, 'epoch': 0.15}\n",
      "{'loss': 5.6026, 'learning_rate': 1.3389121338912134e-06, 'epoch': 0.17}\n",
      "{'loss': 5.5663, 'learning_rate': 1.5059414225941423e-06, 'epoch': 0.19}\n",
      "{'loss': 5.5561, 'learning_rate': 1.6733054393305439e-06, 'epoch': 0.21}\n",
      "{'loss': 5.5237, 'learning_rate': 1.8406694560669458e-06, 'epoch': 0.23}\n",
      "{'loss': 5.5171, 'learning_rate': 2.008033472803347e-06, 'epoch': 0.25}\n",
      "{'loss': 5.4901, 'learning_rate': 2.1750627615062763e-06, 'epoch': 0.27}\n",
      "{'loss': 5.4725, 'learning_rate': 2.342426778242678e-06, 'epoch': 0.29}\n",
      "{'loss': 5.4712, 'learning_rate': 2.5097907949790794e-06, 'epoch': 0.31}\n",
      "{'loss': 5.4428, 'learning_rate': 2.6771548117154816e-06, 'epoch': 0.33}\n",
      "{'loss': 5.4289, 'learning_rate': 2.8445188284518833e-06, 'epoch': 0.36}\n",
      "{'loss': 5.4108, 'learning_rate': 3.011548117154812e-06, 'epoch': 0.38}\n",
      "{'loss': 5.4078, 'learning_rate': 3.178912133891214e-06, 'epoch': 0.4}\n",
      "{'loss': 5.3886, 'learning_rate': 3.3462761506276156e-06, 'epoch': 0.42}\n",
      "{'loss': 5.3696, 'learning_rate': 3.513640167364017e-06, 'epoch': 0.44}\n",
      "{'loss': 5.3453, 'learning_rate': 3.6810041841004186e-06, 'epoch': 0.46}\n",
      "{'loss': 5.2988, 'learning_rate': 3.848033472803348e-06, 'epoch': 0.48}\n",
      "{'loss': 5.2666, 'learning_rate': 4.015397489539749e-06, 'epoch': 0.5}\n",
      "{'loss': 5.2299, 'learning_rate': 4.182761506276151e-06, 'epoch': 0.52}\n",
      "{'loss': 5.1999, 'learning_rate': 4.350125523012553e-06, 'epoch': 0.54}\n",
      "{'loss': 5.1478, 'learning_rate': 4.517489539748954e-06, 'epoch': 0.56}\n",
      "{'loss': 5.0858, 'learning_rate': 4.684853556485356e-06, 'epoch': 0.59}\n",
      "{'loss': 5.0296, 'learning_rate': 4.8522175732217575e-06, 'epoch': 0.61}\n",
      "{'loss': 4.9516, 'learning_rate': 5.019581589958159e-06, 'epoch': 0.63}\n",
      "{'loss': 4.8315, 'learning_rate': 5.186610878661088e-06, 'epoch': 0.65}\n",
      "{'loss': 4.7557, 'learning_rate': 5.3539748953974905e-06, 'epoch': 0.67}\n",
      "{'loss': 4.6422, 'learning_rate': 5.521338912133891e-06, 'epoch': 0.69}\n",
      "{'loss': 4.5312, 'learning_rate': 5.6883682008368206e-06, 'epoch': 0.71}\n",
      "{'loss': 4.4286, 'learning_rate': 5.855732217573222e-06, 'epoch': 0.73}\n",
      "{'loss': 4.3128, 'learning_rate': 6.023096234309624e-06, 'epoch': 0.75}\n",
      "{'loss': 4.2155, 'learning_rate': 6.190460251046025e-06, 'epoch': 0.77}\n",
      "{'loss': 4.0965, 'learning_rate': 6.357824267782428e-06, 'epoch': 0.79}\n",
      "{'loss': 3.9764, 'learning_rate': 6.525188284518829e-06, 'epoch': 0.82}\n",
      "{'loss': 3.8727, 'learning_rate': 6.692217573221758e-06, 'epoch': 0.84}\n",
      "{'loss': 3.766, 'learning_rate': 6.85958158995816e-06, 'epoch': 0.86}\n",
      "{'loss': 3.658, 'learning_rate': 7.02694560669456e-06, 'epoch': 0.88}\n",
      "{'loss': 3.5716, 'learning_rate': 7.1943096234309625e-06, 'epoch': 0.9}\n",
      "{'loss': 3.5137, 'learning_rate': 7.361673640167365e-06, 'epoch': 0.92}\n",
      "{'loss': 3.4294, 'learning_rate': 7.529037656903766e-06, 'epoch': 0.94}\n",
      "{'loss': 3.3607, 'learning_rate': 7.696401673640167e-06, 'epoch': 0.96}\n",
      "{'loss': 3.3068, 'learning_rate': 7.863430962343097e-06, 'epoch': 0.98}\n",
      "{'loss': 3.2692, 'learning_rate': 8.030794979079498e-06, 'epoch': 1.0}\n",
      "{'loss': 3.2142, 'learning_rate': 8.1981589958159e-06, 'epoch': 1.03}\n",
      "{'loss': 3.1836, 'learning_rate': 8.365523012552303e-06, 'epoch': 1.05}\n",
      "{'loss': 3.1525, 'learning_rate': 8.532887029288704e-06, 'epoch': 1.07}\n",
      "{'loss': 3.1212, 'learning_rate': 8.700251046025105e-06, 'epoch': 1.09}\n",
      "{'loss': 3.1007, 'learning_rate': 8.867615062761507e-06, 'epoch': 1.11}\n",
      "{'loss': 3.0739, 'learning_rate': 9.034644351464436e-06, 'epoch': 1.13}\n",
      "{'loss': 3.0585, 'learning_rate': 9.202008368200837e-06, 'epoch': 1.15}\n",
      "{'loss': 3.0446, 'learning_rate': 9.36937238493724e-06, 'epoch': 1.17}\n",
      "{'loss': 3.0272, 'learning_rate': 9.53673640167364e-06, 'epoch': 1.19}\n",
      "{'loss': 3.0037, 'learning_rate': 9.704100418410043e-06, 'epoch': 1.21}\n",
      "{'loss': 2.9891, 'learning_rate': 9.871464435146444e-06, 'epoch': 1.23}\n",
      "{'loss': 2.9629, 'learning_rate': 1.0038493723849374e-05, 'epoch': 1.26}\n",
      "{'loss': 2.9546, 'learning_rate': 1.0205857740585774e-05, 'epoch': 1.28}\n",
      "{'loss': 2.9509, 'learning_rate': 1.0373221757322177e-05, 'epoch': 1.3}\n",
      "{'loss': 2.9486, 'learning_rate': 1.0540585774058578e-05, 'epoch': 1.32}\n",
      "{'loss': 2.9061, 'learning_rate': 1.0707949790794981e-05, 'epoch': 1.34}\n",
      "{'loss': 2.9113, 'learning_rate': 1.0875313807531382e-05, 'epoch': 1.36}\n",
      "{'loss': 2.9077, 'learning_rate': 1.1042343096234312e-05, 'epoch': 1.38}\n",
      "{'loss': 2.9, 'learning_rate': 1.1209707112970712e-05, 'epoch': 1.4}\n",
      "{'loss': 2.8907, 'learning_rate': 1.1377071129707113e-05, 'epoch': 1.42}\n",
      "{'loss': 2.8496, 'learning_rate': 1.1544435146443516e-05, 'epoch': 1.44}\n",
      "{'loss': 2.8679, 'learning_rate': 1.1711799163179917e-05, 'epoch': 1.46}\n",
      "{'loss': 2.8293, 'learning_rate': 1.187916317991632e-05, 'epoch': 1.49}\n",
      "{'loss': 2.8242, 'learning_rate': 1.204652719665272e-05, 'epoch': 1.51}\n",
      "{'loss': 2.796, 'learning_rate': 1.221355648535565e-05, 'epoch': 1.53}\n",
      "{'loss': 2.7987, 'learning_rate': 1.238092050209205e-05, 'epoch': 1.55}\n",
      "{'loss': 2.7894, 'learning_rate': 1.2548284518828452e-05, 'epoch': 1.57}\n",
      "{'loss': 2.7557, 'learning_rate': 1.2715648535564855e-05, 'epoch': 1.59}\n",
      "{'loss': 2.7508, 'learning_rate': 1.2883012552301257e-05, 'epoch': 1.61}\n",
      "{'loss': 2.7665, 'learning_rate': 1.3050376569037658e-05, 'epoch': 1.63}\n",
      "{'loss': 2.7273, 'learning_rate': 1.321774058577406e-05, 'epoch': 1.65}\n",
      "{'loss': 2.7105, 'learning_rate': 1.3385104602510462e-05, 'epoch': 1.67}\n",
      "{'loss': 2.7172, 'learning_rate': 1.355213389121339e-05, 'epoch': 1.69}\n",
      "{'loss': 2.7211, 'learning_rate': 1.371916317991632e-05, 'epoch': 1.72}\n",
      "{'loss': 2.7113, 'learning_rate': 1.3886527196652721e-05, 'epoch': 1.74}\n",
      "{'loss': 2.6739, 'learning_rate': 1.405389121338912e-05, 'epoch': 1.76}\n",
      "{'loss': 2.6966, 'learning_rate': 1.4221255230125524e-05, 'epoch': 1.78}\n",
      "{'loss': 2.6851, 'learning_rate': 1.4388619246861925e-05, 'epoch': 1.8}\n",
      "{'loss': 2.656, 'learning_rate': 1.4555983263598328e-05, 'epoch': 1.82}\n",
      "{'loss': 2.6763, 'learning_rate': 1.472334728033473e-05, 'epoch': 1.84}\n",
      "{'loss': 2.6581, 'learning_rate': 1.4890376569037659e-05, 'epoch': 1.86}\n",
      "{'loss': 2.6554, 'learning_rate': 1.5057740585774059e-05, 'epoch': 1.88}\n",
      "{'loss': 2.6309, 'learning_rate': 1.5225104602510462e-05, 'epoch': 1.9}\n",
      "{'loss': 2.643, 'learning_rate': 1.5392468619246863e-05, 'epoch': 1.92}\n",
      "{'loss': 2.6355, 'learning_rate': 1.5559832635983264e-05, 'epoch': 1.95}\n",
      "{'loss': 2.6311, 'learning_rate': 1.572719665271967e-05, 'epoch': 1.97}\n",
      "{'loss': 2.6003, 'learning_rate': 1.5894225941422595e-05, 'epoch': 1.99}\n",
      "{'loss': 2.592, 'learning_rate': 1.6061589958158996e-05, 'epoch': 2.01}\n",
      "{'loss': 2.6086, 'learning_rate': 1.6228953974895398e-05, 'epoch': 2.03}\n",
      "{'loss': 2.6034, 'learning_rate': 1.63963179916318e-05, 'epoch': 2.05}\n",
      "{'loss': 2.6094, 'learning_rate': 1.6563682008368204e-05, 'epoch': 2.07}\n",
      "{'loss': 2.5898, 'learning_rate': 1.6731046025104605e-05, 'epoch': 2.09}\n",
      "{'loss': 2.5903, 'learning_rate': 1.6898410041841003e-05, 'epoch': 2.11}\n",
      "{'loss': 2.5792, 'learning_rate': 1.7065774058577408e-05, 'epoch': 2.13}\n",
      "{'loss': 2.5787, 'learning_rate': 1.7232803347280337e-05, 'epoch': 2.15}\n",
      "{'loss': 2.5761, 'learning_rate': 1.740016736401674e-05, 'epoch': 2.18}\n",
      "{'loss': 2.5583, 'learning_rate': 1.756753138075314e-05, 'epoch': 2.2}\n",
      "{'loss': 2.541, 'learning_rate': 1.773489539748954e-05, 'epoch': 2.22}\n",
      "{'loss': 2.5391, 'learning_rate': 1.790192468619247e-05, 'epoch': 2.24}\n",
      "{'loss': 2.5379, 'learning_rate': 1.8069288702928872e-05, 'epoch': 2.26}\n",
      "{'loss': 2.5533, 'learning_rate': 1.8236652719665274e-05, 'epoch': 2.28}\n",
      "{'loss': 2.544, 'learning_rate': 1.8404016736401675e-05, 'epoch': 2.3}\n",
      "{'loss': 2.5121, 'learning_rate': 1.8571380753138076e-05, 'epoch': 2.32}\n",
      "{'loss': 2.5333, 'learning_rate': 1.873874476987448e-05, 'epoch': 2.34}\n",
      "{'loss': 2.54, 'learning_rate': 1.890610878661088e-05, 'epoch': 2.36}\n",
      "{'loss': 2.5061, 'learning_rate': 1.907347280334728e-05, 'epoch': 2.38}\n",
      "{'loss': 2.5109, 'learning_rate': 1.924050209205021e-05, 'epoch': 2.41}\n",
      "{'loss': 2.4775, 'learning_rate': 1.940753138075314e-05, 'epoch': 2.43}\n",
      "{'loss': 2.5124, 'learning_rate': 1.957489539748954e-05, 'epoch': 2.45}\n",
      "{'loss': 2.4908, 'learning_rate': 1.9742259414225945e-05, 'epoch': 2.47}\n",
      "{'loss': 2.4895, 'learning_rate': 1.9909623430962343e-05, 'epoch': 2.49}\n",
      "{'loss': 2.4744, 'learning_rate': 1.9991445839144586e-05, 'epoch': 2.51}\n",
      "{'loss': 2.4913, 'learning_rate': 1.9972849837284984e-05, 'epoch': 2.53}\n",
      "{'loss': 2.4652, 'learning_rate': 1.9954253835425385e-05, 'epoch': 2.55}\n",
      "{'loss': 2.4738, 'learning_rate': 1.9935695025569505e-05, 'epoch': 2.57}\n",
      "{'loss': 2.477, 'learning_rate': 1.9917099023709906e-05, 'epoch': 2.59}\n",
      "{'loss': 2.4658, 'learning_rate': 1.9898503021850303e-05, 'epoch': 2.62}\n",
      "{'loss': 2.482, 'learning_rate': 1.9879907019990704e-05, 'epoch': 2.64}\n",
      "{'loss': 2.4569, 'learning_rate': 1.9861311018131105e-05, 'epoch': 2.66}\n",
      "{'loss': 2.4586, 'learning_rate': 1.984275220827522e-05, 'epoch': 2.68}\n",
      "{'loss': 2.4545, 'learning_rate': 1.9824156206415623e-05, 'epoch': 2.7}\n",
      "{'loss': 2.4521, 'learning_rate': 1.9805560204556024e-05, 'epoch': 2.72}\n",
      "{'loss': 2.4351, 'learning_rate': 1.978696420269642e-05, 'epoch': 2.74}\n",
      "{'loss': 2.4391, 'learning_rate': 1.976840539284054e-05, 'epoch': 2.76}\n",
      "{'loss': 2.4291, 'learning_rate': 1.9749809390980942e-05, 'epoch': 2.78}\n",
      "{'loss': 2.4341, 'learning_rate': 1.973121338912134e-05, 'epoch': 2.8}\n",
      "{'loss': 2.4133, 'learning_rate': 1.971261738726174e-05, 'epoch': 2.82}\n",
      "{'loss': 2.4278, 'learning_rate': 1.969402138540214e-05, 'epoch': 2.85}\n",
      "{'loss': 2.4259, 'learning_rate': 1.967546257554626e-05, 'epoch': 2.87}\n",
      "{'loss': 2.4073, 'learning_rate': 1.965686657368666e-05, 'epoch': 2.89}\n",
      "{'loss': 2.434, 'learning_rate': 1.963827057182706e-05, 'epoch': 2.91}\n",
      "{'loss': 2.3996, 'learning_rate': 1.961967456996746e-05, 'epoch': 2.93}\n",
      "{'loss': 2.4072, 'learning_rate': 1.9601078568107858e-05, 'epoch': 2.95}\n",
      "{'loss': 2.3778, 'learning_rate': 1.958248256624826e-05, 'epoch': 2.97}\n",
      "{'loss': 2.3945, 'learning_rate': 1.956388656438866e-05, 'epoch': 2.99}\n",
      "{'loss': 2.3909, 'learning_rate': 1.9545290562529058e-05, 'epoch': 3.01}\n",
      "{'loss': 2.3819, 'learning_rate': 1.9526694560669455e-05, 'epoch': 3.03}\n",
      "{'loss': 2.3823, 'learning_rate': 1.950813575081358e-05, 'epoch': 3.05}\n",
      "{'loss': 2.3668, 'learning_rate': 1.9489539748953976e-05, 'epoch': 3.08}\n",
      "{'loss': 2.392, 'learning_rate': 1.9470943747094377e-05, 'epoch': 3.1}\n",
      "{'loss': 2.3807, 'learning_rate': 1.9452347745234778e-05, 'epoch': 3.12}\n",
      "{'loss': 2.3904, 'learning_rate': 1.9433751743375176e-05, 'epoch': 3.14}\n",
      "{'loss': 2.3746, 'learning_rate': 1.9415192933519295e-05, 'epoch': 3.16}\n",
      "{'loss': 2.3701, 'learning_rate': 1.9396596931659696e-05, 'epoch': 3.18}\n",
      "{'loss': 2.3677, 'learning_rate': 1.9378000929800094e-05, 'epoch': 3.2}\n",
      "{'loss': 2.3516, 'learning_rate': 1.9359404927940495e-05, 'epoch': 3.22}\n",
      "{'loss': 2.3749, 'learning_rate': 1.9340846118084615e-05, 'epoch': 3.24}\n",
      "{'loss': 2.3674, 'learning_rate': 1.9322250116225016e-05, 'epoch': 3.26}\n",
      "{'loss': 2.3559, 'learning_rate': 1.9303654114365413e-05, 'epoch': 3.28}\n",
      "{'loss': 2.3507, 'learning_rate': 1.928505811250581e-05, 'epoch': 3.31}\n",
      "{'loss': 2.3525, 'learning_rate': 1.9266499302649934e-05, 'epoch': 3.33}\n",
      "{'loss': 2.3436, 'learning_rate': 1.924794049279405e-05, 'epoch': 3.35}\n",
      "{'loss': 2.3511, 'learning_rate': 1.922934449093445e-05, 'epoch': 3.37}\n",
      "{'loss': 2.3553, 'learning_rate': 1.9210748489074852e-05, 'epoch': 3.39}\n",
      "{'loss': 2.3505, 'learning_rate': 1.919215248721525e-05, 'epoch': 3.41}\n",
      "{'loss': 2.3585, 'learning_rate': 1.917355648535565e-05, 'epoch': 3.43}\n",
      "{'loss': 2.3362, 'learning_rate': 1.915496048349605e-05, 'epoch': 3.45}\n",
      "{'loss': 2.3361, 'learning_rate': 1.913636448163645e-05, 'epoch': 3.47}\n",
      "{'loss': 2.3147, 'learning_rate': 1.911776847977685e-05, 'epoch': 3.49}\n",
      "{'loss': 2.3334, 'learning_rate': 1.9099172477917248e-05, 'epoch': 3.51}\n",
      "{'loss': 2.3262, 'learning_rate': 1.908057647605765e-05, 'epoch': 3.54}\n",
      "{'loss': 2.3285, 'learning_rate': 1.906201766620177e-05, 'epoch': 3.56}\n",
      "{'loss': 2.3329, 'learning_rate': 1.9043421664342166e-05, 'epoch': 3.58}\n",
      "{'loss': 2.3324, 'learning_rate': 1.902482566248257e-05, 'epoch': 3.6}\n",
      "{'loss': 2.335, 'learning_rate': 1.9006229660622968e-05, 'epoch': 3.62}\n",
      "{'loss': 2.3144, 'learning_rate': 1.8987633658763366e-05, 'epoch': 3.64}\n",
      "{'loss': 2.3135, 'learning_rate': 1.896907484890749e-05, 'epoch': 3.66}\n",
      "{'loss': 2.2953, 'learning_rate': 1.8950478847047886e-05, 'epoch': 3.68}\n",
      "{'loss': 2.3112, 'learning_rate': 1.8931882845188284e-05, 'epoch': 3.7}\n",
      "{'loss': 2.3119, 'learning_rate': 1.8913286843328685e-05, 'epoch': 3.72}\n",
      "{'loss': 2.3138, 'learning_rate': 1.8894728033472805e-05, 'epoch': 3.74}\n",
      "{'loss': 2.3242, 'learning_rate': 1.8876132031613206e-05, 'epoch': 3.77}\n",
      "{'loss': 2.3277, 'learning_rate': 1.8857536029753603e-05, 'epoch': 3.79}\n",
      "{'loss': 2.3059, 'learning_rate': 1.8838940027894004e-05, 'epoch': 3.81}\n",
      "{'loss': 2.3142, 'learning_rate': 1.8820381218038124e-05, 'epoch': 3.83}\n",
      "{'loss': 2.3031, 'learning_rate': 1.880178521617852e-05, 'epoch': 3.85}\n",
      "{'loss': 2.3047, 'learning_rate': 1.8783189214318922e-05, 'epoch': 3.87}\n",
      "{'loss': 2.3049, 'learning_rate': 1.8764593212459323e-05, 'epoch': 3.89}\n",
      "{'loss': 2.3036, 'learning_rate': 1.874599721059972e-05, 'epoch': 3.91}\n",
      "{'loss': 2.2872, 'learning_rate': 1.8727401208740122e-05, 'epoch': 3.93}\n",
      "{'loss': 2.2969, 'learning_rate': 1.870884239888424e-05, 'epoch': 3.95}\n",
      "{'loss': 2.2956, 'learning_rate': 1.869024639702464e-05, 'epoch': 3.97}\n",
      "{'loss': 2.3013, 'learning_rate': 1.8671687587168762e-05, 'epoch': 4.0}\n",
      "{'loss': 2.2836, 'learning_rate': 1.865309158530916e-05, 'epoch': 4.02}\n",
      "{'loss': 2.2724, 'learning_rate': 1.8634495583449557e-05, 'epoch': 4.04}\n",
      "{'loss': 2.2805, 'learning_rate': 1.861589958158996e-05, 'epoch': 4.06}\n",
      "{'loss': 2.2756, 'learning_rate': 1.859730357973036e-05, 'epoch': 4.08}\n",
      "{'loss': 2.2672, 'learning_rate': 1.857870757787076e-05, 'epoch': 4.1}\n",
      "{'loss': 2.2831, 'learning_rate': 1.8560111576011158e-05, 'epoch': 4.12}\n",
      "{'loss': 2.2746, 'learning_rate': 1.854151557415156e-05, 'epoch': 4.14}\n",
      "{'loss': 2.2737, 'learning_rate': 1.852295676429568e-05, 'epoch': 4.16}\n",
      "{'loss': 2.2651, 'learning_rate': 1.8504360762436076e-05, 'epoch': 4.18}\n",
      "{'loss': 2.283, 'learning_rate': 1.8485764760576477e-05, 'epoch': 4.21}\n",
      "{'loss': 2.2595, 'learning_rate': 1.8467168758716878e-05, 'epoch': 4.23}\n",
      "{'loss': 2.2452, 'learning_rate': 1.8448572756857276e-05, 'epoch': 4.25}\n",
      "{'loss': 2.2658, 'learning_rate': 1.8429976754997677e-05, 'epoch': 4.27}\n",
      "{'loss': 2.2698, 'learning_rate': 1.8411380753138078e-05, 'epoch': 4.29}\n",
      "{'loss': 2.2526, 'learning_rate': 1.8392821943282194e-05, 'epoch': 4.31}\n",
      "{'loss': 2.2696, 'learning_rate': 1.8374225941422595e-05, 'epoch': 4.33}\n",
      "{'loss': 2.2689, 'learning_rate': 1.8355629939562996e-05, 'epoch': 4.35}\n",
      "{'loss': 2.2538, 'learning_rate': 1.8337033937703394e-05, 'epoch': 4.37}\n",
      "{'loss': 2.2681, 'learning_rate': 1.8318437935843795e-05, 'epoch': 4.39}\n",
      "{'loss': 2.2606, 'learning_rate': 1.8299879125987914e-05, 'epoch': 4.41}\n",
      "{'loss': 2.2526, 'learning_rate': 1.8281320316132034e-05, 'epoch': 4.44}\n",
      "{'loss': 2.2573, 'learning_rate': 1.826272431427243e-05, 'epoch': 4.46}\n",
      "{'loss': 2.2665, 'learning_rate': 1.8244128312412833e-05, 'epoch': 4.48}\n",
      "{'loss': 2.2608, 'learning_rate': 1.8225532310553234e-05, 'epoch': 4.5}\n",
      "{'loss': 2.2582, 'learning_rate': 1.820693630869363e-05, 'epoch': 4.52}\n",
      "{'loss': 2.2429, 'learning_rate': 1.8188340306834032e-05, 'epoch': 4.54}\n",
      "{'loss': 2.2505, 'learning_rate': 1.8169744304974433e-05, 'epoch': 4.56}\n",
      "{'loss': 2.2487, 'learning_rate': 1.815114830311483e-05, 'epoch': 4.58}\n",
      "{'loss': 2.2521, 'learning_rate': 1.813255230125523e-05, 'epoch': 4.6}\n",
      "{'loss': 2.267, 'learning_rate': 1.811399349139935e-05, 'epoch': 4.62}\n",
      "{'loss': 2.2647, 'learning_rate': 1.809539748953975e-05, 'epoch': 4.64}\n",
      "{'loss': 2.2209, 'learning_rate': 1.807680148768015e-05, 'epoch': 4.67}\n",
      "{'loss': 2.2518, 'learning_rate': 1.805820548582055e-05, 'epoch': 4.69}\n",
      "{'loss': 2.249, 'learning_rate': 1.8039646675964667e-05, 'epoch': 4.71}\n",
      "{'loss': 2.2424, 'learning_rate': 1.8021050674105068e-05, 'epoch': 4.73}\n",
      "{'loss': 2.2517, 'learning_rate': 1.800245467224547e-05, 'epoch': 4.75}\n",
      "{'loss': 2.2257, 'learning_rate': 1.7983858670385867e-05, 'epoch': 4.77}\n",
      "{'loss': 2.2349, 'learning_rate': 1.7965262668526268e-05, 'epoch': 4.79}\n",
      "{'loss': 2.2397, 'learning_rate': 1.7946703858670387e-05, 'epoch': 4.81}\n",
      "{'loss': 2.24, 'learning_rate': 1.792810785681079e-05, 'epoch': 4.83}\n",
      "{'loss': 2.2464, 'learning_rate': 1.7909511854951186e-05, 'epoch': 4.85}\n",
      "{'loss': 2.2313, 'learning_rate': 1.7890915853091587e-05, 'epoch': 4.87}\n",
      "{'loss': 2.2418, 'learning_rate': 1.7872357043235707e-05, 'epoch': 4.9}\n",
      "{'loss': 2.2086, 'learning_rate': 1.7853761041376104e-05, 'epoch': 4.92}\n",
      "{'loss': 2.2232, 'learning_rate': 1.7835165039516505e-05, 'epoch': 4.94}\n",
      "{'loss': 2.2272, 'learning_rate': 1.7816569037656906e-05, 'epoch': 4.96}\n",
      "{'loss': 2.2071, 'learning_rate': 1.7798010227801023e-05, 'epoch': 4.98}\n",
      "{'loss': 2.2219, 'learning_rate': 1.7779414225941424e-05, 'epoch': 5.0}\n",
      "{'loss': 2.215, 'learning_rate': 1.7760818224081825e-05, 'epoch': 5.02}\n",
      "{'loss': 2.1913, 'learning_rate': 1.7742222222222222e-05, 'epoch': 5.04}\n",
      "{'loss': 2.2185, 'learning_rate': 1.7723626220362623e-05, 'epoch': 5.06}\n",
      "{'loss': 2.2145, 'learning_rate': 1.7705030218503024e-05, 'epoch': 5.08}\n",
      "{'loss': 2.2103, 'learning_rate': 1.768643421664342e-05, 'epoch': 5.1}\n",
      "{'loss': 2.2131, 'learning_rate': 1.7667838214783823e-05, 'epoch': 5.13}\n",
      "{'loss': 2.2339, 'learning_rate': 1.7649279404927942e-05, 'epoch': 5.15}\n",
      "{'loss': 2.2183, 'learning_rate': 1.7630683403068343e-05, 'epoch': 5.17}\n",
      "{'loss': 2.2054, 'learning_rate': 1.761208740120874e-05, 'epoch': 5.19}\n",
      "{'loss': 2.2105, 'learning_rate': 1.7593491399349142e-05, 'epoch': 5.21}\n",
      "{'loss': 2.1997, 'learning_rate': 1.7574895397489543e-05, 'epoch': 5.23}\n",
      "{'loss': 2.1905, 'learning_rate': 1.755633658763366e-05, 'epoch': 5.25}\n",
      "{'loss': 2.215, 'learning_rate': 1.753774058577406e-05, 'epoch': 5.27}\n",
      "{'loss': 2.1907, 'learning_rate': 1.751914458391446e-05, 'epoch': 5.29}\n",
      "{'loss': 2.2201, 'learning_rate': 1.750054858205486e-05, 'epoch': 5.31}\n",
      "{'loss': 2.2129, 'learning_rate': 1.748195258019526e-05, 'epoch': 5.33}\n",
      "{'loss': 2.1973, 'learning_rate': 1.746335657833566e-05, 'epoch': 5.36}\n",
      "{'loss': 2.1904, 'learning_rate': 1.7444797768479777e-05, 'epoch': 5.38}\n",
      "{'loss': 2.1909, 'learning_rate': 1.7426201766620178e-05, 'epoch': 5.4}\n",
      "{'loss': 2.1902, 'learning_rate': 1.740760576476058e-05, 'epoch': 5.42}\n",
      "{'loss': 2.1914, 'learning_rate': 1.7389009762900977e-05, 'epoch': 5.44}\n",
      "{'loss': 2.1852, 'learning_rate': 1.7370413761041378e-05, 'epoch': 5.46}\n",
      "{'loss': 2.2156, 'learning_rate': 1.735181775918178e-05, 'epoch': 5.48}\n",
      "{'loss': 2.1952, 'learning_rate': 1.7333258949325898e-05, 'epoch': 5.5}\n",
      "{'loss': 2.2091, 'learning_rate': 1.7314662947466296e-05, 'epoch': 5.52}\n",
      "{'loss': 2.1951, 'learning_rate': 1.7296066945606697e-05, 'epoch': 5.54}\n",
      "{'loss': 2.1909, 'learning_rate': 1.7277470943747098e-05, 'epoch': 5.56}\n",
      "{'loss': 2.2133, 'learning_rate': 1.7258874941887495e-05, 'epoch': 5.59}\n",
      "{'loss': 2.199, 'learning_rate': 1.7240316132031615e-05, 'epoch': 5.61}\n",
      "{'loss': 2.1816, 'learning_rate': 1.7221720130172016e-05, 'epoch': 5.63}\n",
      "{'loss': 2.1921, 'learning_rate': 1.7203124128312414e-05, 'epoch': 5.65}\n",
      "{'loss': 2.1921, 'learning_rate': 1.7184528126452815e-05, 'epoch': 5.67}\n",
      "{'loss': 2.1875, 'learning_rate': 1.7165969316596934e-05, 'epoch': 5.69}\n",
      "{'loss': 2.1867, 'learning_rate': 1.7147373314737332e-05, 'epoch': 5.71}\n",
      "{'loss': 2.2007, 'learning_rate': 1.7128777312877733e-05, 'epoch': 5.73}\n",
      "{'loss': 2.1891, 'learning_rate': 1.7110181311018134e-05, 'epoch': 5.75}\n",
      "{'loss': 2.1897, 'learning_rate': 1.709158530915853e-05, 'epoch': 5.77}\n",
      "{'loss': 2.186, 'learning_rate': 1.7072989307298932e-05, 'epoch': 5.79}\n",
      "{'loss': 2.1627, 'learning_rate': 1.7054430497443052e-05, 'epoch': 5.82}\n",
      "{'loss': 2.1798, 'learning_rate': 1.7035834495583453e-05, 'epoch': 5.84}\n",
      "{'loss': 2.1757, 'learning_rate': 1.701723849372385e-05, 'epoch': 5.86}\n",
      "{'loss': 2.1759, 'learning_rate': 1.6998642491864252e-05, 'epoch': 5.88}\n",
      "{'loss': 2.1696, 'learning_rate': 1.6980046490004653e-05, 'epoch': 5.9}\n",
      "{'loss': 2.1703, 'learning_rate': 1.696145048814505e-05, 'epoch': 5.92}\n",
      "{'loss': 2.1737, 'learning_rate': 1.6942854486285448e-05, 'epoch': 5.94}\n",
      "{'loss': 2.1616, 'learning_rate': 1.6924258484425852e-05, 'epoch': 5.96}\n",
      "{'loss': 2.1842, 'learning_rate': 1.690569967456997e-05, 'epoch': 5.98}\n",
      "{'loss': 2.168, 'learning_rate': 1.6887103672710366e-05, 'epoch': 6.0}\n",
      "{'loss': 2.1702, 'learning_rate': 1.686850767085077e-05, 'epoch': 6.03}\n",
      "{'loss': 2.171, 'learning_rate': 1.6849948860994887e-05, 'epoch': 6.05}\n",
      "{'loss': 2.1741, 'learning_rate': 1.6831352859135288e-05, 'epoch': 6.07}\n",
      "{'loss': 2.168, 'learning_rate': 1.681275685727569e-05, 'epoch': 6.09}\n",
      "{'loss': 2.1689, 'learning_rate': 1.6794160855416086e-05, 'epoch': 6.11}\n",
      "{'loss': 2.1482, 'learning_rate': 1.6775564853556487e-05, 'epoch': 6.13}\n",
      "{'loss': 2.1701, 'learning_rate': 1.6757006043700607e-05, 'epoch': 6.15}\n",
      "{'loss': 2.1706, 'learning_rate': 1.6738410041841005e-05, 'epoch': 6.17}\n",
      "{'loss': 2.1659, 'learning_rate': 1.6719814039981406e-05, 'epoch': 6.19}\n",
      "{'loss': 2.1575, 'learning_rate': 1.6701218038121803e-05, 'epoch': 6.21}\n",
      "{'loss': 2.1645, 'learning_rate': 1.6682622036262208e-05, 'epoch': 6.23}\n",
      "{'loss': 2.1591, 'learning_rate': 1.6664063226406324e-05, 'epoch': 6.26}\n",
      "{'loss': 2.1661, 'learning_rate': 1.664546722454672e-05, 'epoch': 6.28}\n",
      "{'loss': 2.161, 'learning_rate': 1.6626871222687126e-05, 'epoch': 6.3}\n",
      "{'loss': 2.1589, 'learning_rate': 1.6608275220827523e-05, 'epoch': 6.32}\n",
      "{'loss': 2.1494, 'learning_rate': 1.658967921896792e-05, 'epoch': 6.34}\n",
      "{'loss': 2.1577, 'learning_rate': 1.6571083217108322e-05, 'epoch': 6.36}\n",
      "{'loss': 2.1503, 'learning_rate': 1.6552487215248723e-05, 'epoch': 6.38}\n",
      "{'loss': 2.129, 'learning_rate': 1.653389121338912e-05, 'epoch': 6.4}\n",
      "{'loss': 2.145, 'learning_rate': 1.651533240353324e-05, 'epoch': 6.42}\n",
      "{'loss': 2.1518, 'learning_rate': 1.649673640167364e-05, 'epoch': 6.44}\n",
      "{'loss': 2.1669, 'learning_rate': 1.6478140399814042e-05, 'epoch': 6.46}\n",
      "{'loss': 2.1442, 'learning_rate': 1.645958158995816e-05, 'epoch': 6.49}\n",
      "{'loss': 2.1544, 'learning_rate': 1.644098558809856e-05, 'epoch': 6.51}\n",
      "{'loss': 2.1541, 'learning_rate': 1.642238958623896e-05, 'epoch': 6.53}\n",
      "{'loss': 2.1673, 'learning_rate': 1.6403793584379358e-05, 'epoch': 6.55}\n",
      "{'loss': 2.1358, 'learning_rate': 1.638523477452348e-05, 'epoch': 6.57}\n",
      "{'loss': 2.145, 'learning_rate': 1.636663877266388e-05, 'epoch': 6.59}\n",
      "{'loss': 2.1453, 'learning_rate': 1.6348042770804276e-05, 'epoch': 6.61}\n",
      "{'loss': 2.157, 'learning_rate': 1.6329446768944677e-05, 'epoch': 6.63}\n",
      "{'loss': 2.1561, 'learning_rate': 1.631085076708508e-05, 'epoch': 6.65}\n",
      "{'loss': 2.1406, 'learning_rate': 1.6292291957229195e-05, 'epoch': 6.67}\n",
      "{'loss': 2.1406, 'learning_rate': 1.6273695955369596e-05, 'epoch': 6.69}\n",
      "{'loss': 2.1303, 'learning_rate': 1.6255099953509997e-05, 'epoch': 6.72}\n",
      "{'loss': 2.1478, 'learning_rate': 1.6236503951650398e-05, 'epoch': 6.74}\n",
      "{'loss': 2.1699, 'learning_rate': 1.6217907949790795e-05, 'epoch': 6.76}\n",
      "{'loss': 2.1432, 'learning_rate': 1.6199311947931196e-05, 'epoch': 6.78}\n",
      "{'loss': 2.1445, 'learning_rate': 1.6180715946071597e-05, 'epoch': 6.8}\n",
      "{'loss': 2.1441, 'learning_rate': 1.6162119944211995e-05, 'epoch': 6.82}\n",
      "{'loss': 2.1467, 'learning_rate': 1.6143561134356114e-05, 'epoch': 6.84}\n",
      "{'loss': 2.1492, 'learning_rate': 1.6124965132496515e-05, 'epoch': 6.86}\n",
      "{'loss': 2.1469, 'learning_rate': 1.6106369130636913e-05, 'epoch': 6.88}\n",
      "{'loss': 2.1176, 'learning_rate': 1.6087773128777314e-05, 'epoch': 6.9}\n",
      "{'loss': 2.1352, 'learning_rate': 1.6069214318921434e-05, 'epoch': 6.92}\n",
      "{'loss': 2.149, 'learning_rate': 1.605061831706183e-05, 'epoch': 6.95}\n",
      "{'loss': 2.1318, 'learning_rate': 1.6032022315202232e-05, 'epoch': 6.97}\n",
      "{'loss': 2.1479, 'learning_rate': 1.6013426313342633e-05, 'epoch': 6.99}\n",
      "{'loss': 2.1328, 'learning_rate': 1.599483031148303e-05, 'epoch': 7.01}\n",
      "{'loss': 2.124, 'learning_rate': 1.5976234309623432e-05, 'epoch': 7.03}\n",
      "{'loss': 2.1302, 'learning_rate': 1.595767549976755e-05, 'epoch': 7.05}\n",
      "{'loss': 2.1189, 'learning_rate': 1.5939079497907952e-05, 'epoch': 7.07}\n",
      "{'loss': 2.1067, 'learning_rate': 1.592048349604835e-05, 'epoch': 7.09}\n",
      "{'loss': 2.1079, 'learning_rate': 1.590188749418875e-05, 'epoch': 7.11}\n",
      "{'loss': 2.1269, 'learning_rate': 1.5883291492329152e-05, 'epoch': 7.13}\n",
      "{'loss': 2.1303, 'learning_rate': 1.586469549046955e-05, 'epoch': 7.15}\n",
      "{'loss': 2.1359, 'learning_rate': 1.584609948860995e-05, 'epoch': 7.18}\n",
      "{'loss': 2.113, 'learning_rate': 1.582754067875407e-05, 'epoch': 7.2}\n",
      "{'loss': 2.1301, 'learning_rate': 1.5808944676894468e-05, 'epoch': 7.22}\n",
      "{'loss': 2.1116, 'learning_rate': 1.579034867503487e-05, 'epoch': 7.24}\n",
      "{'loss': 2.1266, 'learning_rate': 1.577175267317527e-05, 'epoch': 7.26}\n",
      "{'loss': 2.1209, 'learning_rate': 1.5753156671315667e-05, 'epoch': 7.28}\n",
      "{'loss': 2.1322, 'learning_rate': 1.573456066945607e-05, 'epoch': 7.3}\n",
      "{'loss': 2.1171, 'learning_rate': 1.5716001859600188e-05, 'epoch': 7.32}\n",
      "{'loss': 2.1128, 'learning_rate': 1.5697405857740586e-05, 'epoch': 7.34}\n",
      "{'loss': 2.1274, 'learning_rate': 1.5678809855880987e-05, 'epoch': 7.36}\n",
      "{'loss': 2.1059, 'learning_rate': 1.5660213854021388e-05, 'epoch': 7.38}\n",
      "{'loss': 2.1172, 'learning_rate': 1.5641617852161785e-05, 'epoch': 7.41}\n",
      "{'loss': 2.1157, 'learning_rate': 1.5623059042305905e-05, 'epoch': 7.43}\n",
      "{'loss': 2.1086, 'learning_rate': 1.5604463040446306e-05, 'epoch': 7.45}\n",
      "{'loss': 2.1088, 'learning_rate': 1.5585867038586707e-05, 'epoch': 7.47}\n",
      "{'loss': 2.1322, 'learning_rate': 1.5567271036727104e-05, 'epoch': 7.49}\n",
      "{'loss': 2.1282, 'learning_rate': 1.5548675034867505e-05, 'epoch': 7.51}\n",
      "{'loss': 2.1157, 'learning_rate': 1.5530116225011625e-05, 'epoch': 7.53}\n",
      "{'loss': 2.117, 'learning_rate': 1.5511520223152023e-05, 'epoch': 7.55}\n",
      "{'loss': 2.133, 'learning_rate': 1.5492924221292424e-05, 'epoch': 7.57}\n",
      "{'loss': 2.1214, 'learning_rate': 1.5474328219432825e-05, 'epoch': 7.59}\n",
      "{'loss': 2.116, 'learning_rate': 1.5455732217573222e-05, 'epoch': 7.62}\n",
      "{'loss': 2.1512, 'learning_rate': 1.5437136215713623e-05, 'epoch': 7.64}\n",
      "{'loss': 2.096, 'learning_rate': 1.5418540213854024e-05, 'epoch': 7.66}\n",
      "{'loss': 2.109, 'learning_rate': 1.5399944211994422e-05, 'epoch': 7.68}\n",
      "{'loss': 2.1285, 'learning_rate': 1.538142259414226e-05, 'epoch': 7.7}\n",
      "{'loss': 2.0947, 'learning_rate': 1.536282659228266e-05, 'epoch': 7.72}\n",
      "{'loss': 2.1186, 'learning_rate': 1.534423059042306e-05, 'epoch': 7.74}\n",
      "{'loss': 2.1088, 'learning_rate': 1.532563458856346e-05, 'epoch': 7.76}\n",
      "{'loss': 2.1192, 'learning_rate': 1.530703858670386e-05, 'epoch': 7.78}\n",
      "{'loss': 2.1061, 'learning_rate': 1.5288442584844262e-05, 'epoch': 7.8}\n",
      "{'loss': 2.1031, 'learning_rate': 1.526984658298466e-05, 'epoch': 7.82}\n",
      "{'loss': 2.1205, 'learning_rate': 1.5251250581125059e-05, 'epoch': 7.85}\n",
      "{'loss': 2.1226, 'learning_rate': 1.5232691771269178e-05, 'epoch': 7.87}\n",
      "{'loss': 2.1036, 'learning_rate': 1.5214095769409578e-05, 'epoch': 7.89}\n",
      "{'loss': 2.1157, 'learning_rate': 1.5195536959553696e-05, 'epoch': 7.91}\n",
      "{'loss': 2.1185, 'learning_rate': 1.5176940957694097e-05, 'epoch': 7.93}\n",
      "{'loss': 2.0988, 'learning_rate': 1.5158344955834496e-05, 'epoch': 7.95}\n",
      "{'loss': 2.1122, 'learning_rate': 1.5139748953974897e-05, 'epoch': 7.97}\n",
      "{'loss': 2.1103, 'learning_rate': 1.5121152952115296e-05, 'epoch': 7.99}\n",
      "{'loss': 2.0928, 'learning_rate': 1.5102556950255695e-05, 'epoch': 8.01}\n",
      "{'loss': 2.0728, 'learning_rate': 1.5083960948396096e-05, 'epoch': 8.03}\n",
      "{'loss': 2.0966, 'learning_rate': 1.5065364946536496e-05, 'epoch': 8.05}\n",
      "{'loss': 2.078, 'learning_rate': 1.5046806136680614e-05, 'epoch': 8.08}\n",
      "{'loss': 2.1164, 'learning_rate': 1.5028210134821015e-05, 'epoch': 8.1}\n",
      "{'loss': 2.0983, 'learning_rate': 1.5009651324965133e-05, 'epoch': 8.12}\n",
      "{'loss': 2.086, 'learning_rate': 1.4991055323105534e-05, 'epoch': 8.14}\n",
      "{'loss': 2.1085, 'learning_rate': 1.4972459321245933e-05, 'epoch': 8.16}\n",
      "{'loss': 2.101, 'learning_rate': 1.4953863319386332e-05, 'epoch': 8.18}\n",
      "{'loss': 2.0949, 'learning_rate': 1.4935267317526733e-05, 'epoch': 8.2}\n",
      "{'loss': 2.0817, 'learning_rate': 1.4916671315667133e-05, 'epoch': 8.22}\n",
      "{'loss': 2.0893, 'learning_rate': 1.4898075313807532e-05, 'epoch': 8.24}\n",
      "{'loss': 2.0743, 'learning_rate': 1.4879479311947933e-05, 'epoch': 8.26}\n",
      "{'loss': 2.1086, 'learning_rate': 1.486092050209205e-05, 'epoch': 8.28}\n",
      "{'loss': 2.0813, 'learning_rate': 1.484236169223617e-05, 'epoch': 8.31}\n",
      "{'loss': 2.1008, 'learning_rate': 1.482376569037657e-05, 'epoch': 8.33}\n",
      "{'loss': 2.0955, 'learning_rate': 1.4805169688516969e-05, 'epoch': 8.35}\n",
      "{'loss': 2.1057, 'learning_rate': 1.478657368665737e-05, 'epoch': 8.37}\n",
      "{'loss': 2.1008, 'learning_rate': 1.4768014876801488e-05, 'epoch': 8.39}\n",
      "{'loss': 2.1019, 'learning_rate': 1.4749418874941887e-05, 'epoch': 8.41}\n",
      "{'loss': 2.0794, 'learning_rate': 1.4730860065086007e-05, 'epoch': 8.43}\n",
      "{'loss': 2.0931, 'learning_rate': 1.4712264063226406e-05, 'epoch': 8.45}\n",
      "{'loss': 2.0898, 'learning_rate': 1.4693668061366807e-05, 'epoch': 8.47}\n",
      "{'loss': 2.0867, 'learning_rate': 1.4675072059507207e-05, 'epoch': 8.49}\n",
      "{'loss': 2.0965, 'learning_rate': 1.4656476057647606e-05, 'epoch': 8.51}\n",
      "{'loss': 2.0886, 'learning_rate': 1.4637880055788007e-05, 'epoch': 8.54}\n",
      "{'loss': 2.0785, 'learning_rate': 1.4619284053928406e-05, 'epoch': 8.56}\n",
      "{'loss': 2.0784, 'learning_rate': 1.4600688052068805e-05, 'epoch': 8.58}\n",
      "{'loss': 2.0946, 'learning_rate': 1.4582092050209206e-05, 'epoch': 8.6}\n",
      "{'loss': 2.0916, 'learning_rate': 1.4563496048349606e-05, 'epoch': 8.62}\n",
      "{'loss': 2.0682, 'learning_rate': 1.4544900046490005e-05, 'epoch': 8.64}\n",
      "{'loss': 2.0961, 'learning_rate': 1.4526304044630406e-05, 'epoch': 8.66}\n",
      "{'loss': 2.0751, 'learning_rate': 1.4507745234774524e-05, 'epoch': 8.68}\n",
      "{'loss': 2.0808, 'learning_rate': 1.4489149232914925e-05, 'epoch': 8.7}\n",
      "{'loss': 2.0956, 'learning_rate': 1.4470553231055324e-05, 'epoch': 8.72}\n",
      "{'loss': 2.0858, 'learning_rate': 1.4451994421199442e-05, 'epoch': 8.74}\n",
      "{'loss': 2.0924, 'learning_rate': 1.4433398419339843e-05, 'epoch': 8.77}\n",
      "{'loss': 2.0935, 'learning_rate': 1.4414802417480242e-05, 'epoch': 8.79}\n",
      "{'loss': 2.0819, 'learning_rate': 1.4396206415620643e-05, 'epoch': 8.81}\n",
      "{'loss': 2.0902, 'learning_rate': 1.4377610413761043e-05, 'epoch': 8.83}\n",
      "{'loss': 2.0799, 'learning_rate': 1.4359014411901442e-05, 'epoch': 8.85}\n",
      "{'loss': 2.0635, 'learning_rate': 1.4340455602045562e-05, 'epoch': 8.87}\n",
      "{'loss': 2.0858, 'learning_rate': 1.4321859600185961e-05, 'epoch': 8.89}\n",
      "{'loss': 2.0908, 'learning_rate': 1.430326359832636e-05, 'epoch': 8.91}\n",
      "{'loss': 2.0738, 'learning_rate': 1.4284667596466761e-05, 'epoch': 8.93}\n",
      "{'loss': 2.0724, 'learning_rate': 1.426607159460716e-05, 'epoch': 8.95}\n",
      "{'loss': 2.0802, 'learning_rate': 1.424747559274756e-05, 'epoch': 8.97}\n",
      "{'loss': 2.0866, 'learning_rate': 1.4228879590887961e-05, 'epoch': 9.0}\n",
      "{'loss': 2.0614, 'learning_rate': 1.421028358902836e-05, 'epoch': 9.02}\n",
      "{'loss': 2.0724, 'learning_rate': 1.419172477917248e-05, 'epoch': 9.04}\n",
      "{'loss': 2.0841, 'learning_rate': 1.4173165969316598e-05, 'epoch': 9.06}\n",
      "{'loss': 2.0737, 'learning_rate': 1.4154569967456997e-05, 'epoch': 9.08}\n",
      "{'loss': 2.0583, 'learning_rate': 1.4135973965597398e-05, 'epoch': 9.1}\n",
      "{'loss': 2.0607, 'learning_rate': 1.4117377963737797e-05, 'epoch': 9.12}\n",
      "{'loss': 2.0773, 'learning_rate': 1.4098781961878197e-05, 'epoch': 9.14}\n",
      "{'loss': 2.0807, 'learning_rate': 1.4080223152022316e-05, 'epoch': 9.16}\n",
      "{'loss': 2.0583, 'learning_rate': 1.4061627150162716e-05, 'epoch': 9.18}\n",
      "{'loss': 2.0828, 'learning_rate': 1.4043031148303117e-05, 'epoch': 9.21}\n",
      "{'loss': 2.0694, 'learning_rate': 1.4024435146443516e-05, 'epoch': 9.23}\n",
      "{'loss': 2.0616, 'learning_rate': 1.4005839144583915e-05, 'epoch': 9.25}\n",
      "{'loss': 2.0835, 'learning_rate': 1.3987280334728035e-05, 'epoch': 9.27}\n",
      "{'loss': 2.0734, 'learning_rate': 1.3968684332868434e-05, 'epoch': 9.29}\n",
      "{'loss': 2.0842, 'learning_rate': 1.3950088331008835e-05, 'epoch': 9.31}\n",
      "{'loss': 2.0639, 'learning_rate': 1.3931492329149234e-05, 'epoch': 9.33}\n",
      "{'loss': 2.0514, 'learning_rate': 1.3912896327289634e-05, 'epoch': 9.35}\n",
      "{'loss': 2.0664, 'learning_rate': 1.3894300325430035e-05, 'epoch': 9.37}\n",
      "{'loss': 2.0813, 'learning_rate': 1.3875704323570434e-05, 'epoch': 9.39}\n",
      "{'loss': 2.0791, 'learning_rate': 1.3857145513714552e-05, 'epoch': 9.41}\n",
      "{'loss': 2.0595, 'learning_rate': 1.3838549511854953e-05, 'epoch': 9.44}\n",
      "{'loss': 2.0452, 'learning_rate': 1.3819953509995352e-05, 'epoch': 9.46}\n",
      "{'loss': 2.0639, 'learning_rate': 1.3801357508135752e-05, 'epoch': 9.48}\n",
      "{'loss': 2.058, 'learning_rate': 1.3782761506276153e-05, 'epoch': 9.5}\n",
      "{'loss': 2.0693, 'learning_rate': 1.3764165504416552e-05, 'epoch': 9.52}\n",
      "{'loss': 2.0639, 'learning_rate': 1.3745569502556953e-05, 'epoch': 9.54}\n",
      "{'loss': 2.0429, 'learning_rate': 1.3726973500697352e-05, 'epoch': 9.56}\n",
      "{'loss': 2.0564, 'learning_rate': 1.370841469084147e-05, 'epoch': 9.58}\n",
      "{'loss': 2.075, 'learning_rate': 1.368985588098559e-05, 'epoch': 9.6}\n",
      "{'loss': 2.0694, 'learning_rate': 1.3671259879125989e-05, 'epoch': 9.62}\n",
      "{'loss': 2.0612, 'learning_rate': 1.3652663877266388e-05, 'epoch': 9.64}\n",
      "{'loss': 2.0512, 'learning_rate': 1.363406787540679e-05, 'epoch': 9.67}\n",
      "{'loss': 2.0441, 'learning_rate': 1.3615471873547189e-05, 'epoch': 9.69}\n",
      "{'loss': 2.0566, 'learning_rate': 1.3596913063691308e-05, 'epoch': 9.71}\n",
      "{'loss': 2.0542, 'learning_rate': 1.3578317061831708e-05, 'epoch': 9.73}\n",
      "{'loss': 2.0784, 'learning_rate': 1.3559721059972107e-05, 'epoch': 9.75}\n",
      "{'loss': 2.0666, 'learning_rate': 1.3541125058112508e-05, 'epoch': 9.77}\n",
      "{'loss': 2.052, 'learning_rate': 1.3522529056252907e-05, 'epoch': 9.79}\n",
      "{'loss': 2.0463, 'learning_rate': 1.3503933054393305e-05, 'epoch': 9.81}\n",
      "{'loss': 2.0513, 'learning_rate': 1.3485337052533707e-05, 'epoch': 9.83}\n",
      "{'loss': 2.0585, 'learning_rate': 1.3466778242677825e-05, 'epoch': 9.85}\n",
      "{'loss': 2.0286, 'learning_rate': 1.3448182240818226e-05, 'epoch': 9.87}\n",
      "{'loss': 2.0578, 'learning_rate': 1.3429586238958626e-05, 'epoch': 9.9}\n",
      "{'loss': 2.0615, 'learning_rate': 1.3410990237099025e-05, 'epoch': 9.92}\n",
      "{'loss': 2.0597, 'learning_rate': 1.3392394235239426e-05, 'epoch': 9.94}\n",
      "{'loss': 2.0709, 'learning_rate': 1.3373835425383544e-05, 'epoch': 9.96}\n",
      "{'loss': 2.0484, 'learning_rate': 1.3355239423523943e-05, 'epoch': 9.98}\n",
      "{'loss': 2.0471, 'learning_rate': 1.3336643421664344e-05, 'epoch': 10.0}\n",
      "{'loss': 2.053, 'learning_rate': 1.3318047419804744e-05, 'epoch': 10.02}\n",
      "{'loss': 2.0509, 'learning_rate': 1.3299488609948863e-05, 'epoch': 10.04}\n",
      "{'loss': 2.0502, 'learning_rate': 1.3280892608089263e-05, 'epoch': 10.06}\n",
      "{'loss': 2.0522, 'learning_rate': 1.3262296606229662e-05, 'epoch': 10.08}\n",
      "{'loss': 2.0526, 'learning_rate': 1.3243700604370063e-05, 'epoch': 10.1}\n",
      "{'loss': 2.0485, 'learning_rate': 1.3225104602510462e-05, 'epoch': 10.13}\n",
      "{'loss': 2.042, 'learning_rate': 1.320650860065086e-05, 'epoch': 10.15}\n",
      "{'loss': 2.0542, 'learning_rate': 1.3187912598791262e-05, 'epoch': 10.17}\n",
      "{'loss': 2.051, 'learning_rate': 1.316931659693166e-05, 'epoch': 10.19}\n",
      "{'loss': 2.0409, 'learning_rate': 1.315072059507206e-05, 'epoch': 10.21}\n",
      "{'loss': 2.0451, 'learning_rate': 1.313216178521618e-05, 'epoch': 10.23}\n",
      "{'loss': 2.0486, 'learning_rate': 1.3113565783356578e-05, 'epoch': 10.25}\n",
      "{'loss': 2.0442, 'learning_rate': 1.3094969781496981e-05, 'epoch': 10.27}\n",
      "{'loss': 2.0581, 'learning_rate': 1.3076373779637378e-05, 'epoch': 10.29}\n",
      "{'loss': 2.0682, 'learning_rate': 1.3057777777777778e-05, 'epoch': 10.31}\n",
      "{'loss': 2.0437, 'learning_rate': 1.3039181775918179e-05, 'epoch': 10.33}\n",
      "{'loss': 2.0502, 'learning_rate': 1.3020585774058578e-05, 'epoch': 10.36}\n",
      "{'loss': 2.0548, 'learning_rate': 1.3001989772198977e-05, 'epoch': 10.38}\n",
      "{'loss': 2.0151, 'learning_rate': 1.2983430962343097e-05, 'epoch': 10.4}\n",
      "{'loss': 2.0527, 'learning_rate': 1.2964834960483496e-05, 'epoch': 10.42}\n",
      "{'loss': 2.0426, 'learning_rate': 1.2946238958623897e-05, 'epoch': 10.44}\n",
      "{'loss': 2.0331, 'learning_rate': 1.2927642956764297e-05, 'epoch': 10.46}\n",
      "{'loss': 2.0361, 'learning_rate': 1.2909084146908415e-05, 'epoch': 10.48}\n",
      "{'loss': 2.0575, 'learning_rate': 1.2890488145048816e-05, 'epoch': 10.5}\n",
      "{'loss': 2.0433, 'learning_rate': 1.2871892143189215e-05, 'epoch': 10.52}\n",
      "{'loss': 2.0458, 'learning_rate': 1.2853296141329614e-05, 'epoch': 10.54}\n",
      "{'loss': 2.0375, 'learning_rate': 1.2834737331473734e-05, 'epoch': 10.56}\n",
      "{'loss': 2.0394, 'learning_rate': 1.2816141329614133e-05, 'epoch': 10.59}\n",
      "{'loss': 2.0243, 'learning_rate': 1.2797545327754534e-05, 'epoch': 10.61}\n",
      "{'loss': 2.0363, 'learning_rate': 1.2778949325894933e-05, 'epoch': 10.63}\n",
      "{'loss': 2.0564, 'learning_rate': 1.2760390516039051e-05, 'epoch': 10.65}\n",
      "{'loss': 2.0479, 'learning_rate': 1.2741794514179452e-05, 'epoch': 10.67}\n",
      "{'loss': 2.0345, 'learning_rate': 1.2723198512319852e-05, 'epoch': 10.69}\n",
      "{'loss': 2.0466, 'learning_rate': 1.2704602510460251e-05, 'epoch': 10.71}\n",
      "{'loss': 2.0411, 'learning_rate': 1.268604370060437e-05, 'epoch': 10.73}\n",
      "{'loss': 2.0305, 'learning_rate': 1.266744769874477e-05, 'epoch': 10.75}\n",
      "{'loss': 2.0388, 'learning_rate': 1.2648851696885171e-05, 'epoch': 10.77}\n",
      "{'loss': 2.0426, 'learning_rate': 1.263025569502557e-05, 'epoch': 10.79}\n",
      "{'loss': 2.0332, 'learning_rate': 1.261165969316597e-05, 'epoch': 10.82}\n",
      "{'loss': 2.0154, 'learning_rate': 1.259306369130637e-05, 'epoch': 10.84}\n",
      "{'loss': 2.0407, 'learning_rate': 1.257446768944677e-05, 'epoch': 10.86}\n",
      "{'loss': 2.0279, 'learning_rate': 1.2555871687587169e-05, 'epoch': 10.88}\n",
      "{'loss': 2.0441, 'learning_rate': 1.2537312877731289e-05, 'epoch': 10.9}\n",
      "{'loss': 2.0374, 'learning_rate': 1.2518754067875407e-05, 'epoch': 10.92}\n",
      "{'loss': 2.0389, 'learning_rate': 1.2500158066015808e-05, 'epoch': 10.94}\n",
      "{'loss': 2.0165, 'learning_rate': 1.2481562064156207e-05, 'epoch': 10.96}\n",
      "{'loss': 2.0272, 'learning_rate': 1.2462966062296606e-05, 'epoch': 10.98}\n",
      "{'loss': 2.0343, 'learning_rate': 1.2444407252440726e-05, 'epoch': 11.0}\n",
      "{'loss': 2.0322, 'learning_rate': 1.2425811250581125e-05, 'epoch': 11.03}\n",
      "{'loss': 2.0409, 'learning_rate': 1.2407215248721526e-05, 'epoch': 11.05}\n",
      "{'loss': 2.0223, 'learning_rate': 1.2388619246861925e-05, 'epoch': 11.07}\n",
      "{'loss': 2.0343, 'learning_rate': 1.2370023245002325e-05, 'epoch': 11.09}\n",
      "{'loss': 2.0312, 'learning_rate': 1.2351427243142726e-05, 'epoch': 11.11}\n",
      "{'loss': 2.0132, 'learning_rate': 1.2332868433286844e-05, 'epoch': 11.13}\n",
      "{'loss': 2.033, 'learning_rate': 1.2314272431427243e-05, 'epoch': 11.15}\n",
      "{'loss': 2.0134, 'learning_rate': 1.2295676429567644e-05, 'epoch': 11.17}\n",
      "{'loss': 2.03, 'learning_rate': 1.2277080427708043e-05, 'epoch': 11.19}\n",
      "{'loss': 2.0342, 'learning_rate': 1.2258484425848443e-05, 'epoch': 11.21}\n",
      "{'loss': 2.0309, 'learning_rate': 1.2239925615992562e-05, 'epoch': 11.23}\n",
      "{'loss': 2.0377, 'learning_rate': 1.2221329614132962e-05, 'epoch': 11.26}\n",
      "{'loss': 2.0391, 'learning_rate': 1.2202733612273363e-05, 'epoch': 11.28}\n",
      "{'loss': 2.028, 'learning_rate': 1.2184137610413762e-05, 'epoch': 11.3}\n",
      "{'loss': 2.0424, 'learning_rate': 1.2165541608554161e-05, 'epoch': 11.32}\n",
      "{'loss': 2.0396, 'learning_rate': 1.2146945606694562e-05, 'epoch': 11.34}\n",
      "{'loss': 2.0142, 'learning_rate': 1.2128349604834961e-05, 'epoch': 11.36}\n",
      "{'loss': 2.0165, 'learning_rate': 1.210975360297536e-05, 'epoch': 11.38}\n",
      "{'loss': 2.0419, 'learning_rate': 1.209119479311948e-05, 'epoch': 11.4}\n",
      "{'loss': 2.0281, 'learning_rate': 1.207259879125988e-05, 'epoch': 11.42}\n",
      "{'loss': 2.0206, 'learning_rate': 1.205400278940028e-05, 'epoch': 11.44}\n",
      "{'loss': 2.0243, 'learning_rate': 1.203540678754068e-05, 'epoch': 11.46}\n",
      "{'loss': 2.0272, 'learning_rate': 1.2016847977684798e-05, 'epoch': 11.49}\n",
      "{'loss': 2.0108, 'learning_rate': 1.1998251975825199e-05, 'epoch': 11.51}\n",
      "{'loss': 2.0284, 'learning_rate': 1.1979655973965598e-05, 'epoch': 11.53}\n",
      "{'loss': 2.045, 'learning_rate': 1.1961059972105997e-05, 'epoch': 11.55}\n",
      "{'loss': 2.0196, 'learning_rate': 1.1942501162250117e-05, 'epoch': 11.57}\n",
      "{'loss': 2.0177, 'learning_rate': 1.1923905160390516e-05, 'epoch': 11.59}\n",
      "{'loss': 2.0188, 'learning_rate': 1.1905309158530917e-05, 'epoch': 11.61}\n",
      "{'loss': 2.0132, 'learning_rate': 1.1886750348675035e-05, 'epoch': 11.63}\n",
      "{'loss': 2.0215, 'learning_rate': 1.1868154346815435e-05, 'epoch': 11.65}\n",
      "{'loss': 2.0096, 'learning_rate': 1.1849558344955836e-05, 'epoch': 11.67}\n",
      "{'loss': 2.0233, 'learning_rate': 1.1830962343096235e-05, 'epoch': 11.69}\n",
      "{'loss': 2.0245, 'learning_rate': 1.1812366341236634e-05, 'epoch': 11.72}\n",
      "{'loss': 2.0288, 'learning_rate': 1.1793770339377035e-05, 'epoch': 11.74}\n",
      "{'loss': 2.0, 'learning_rate': 1.1775174337517435e-05, 'epoch': 11.76}\n",
      "{'loss': 1.9976, 'learning_rate': 1.1756578335657836e-05, 'epoch': 11.78}\n",
      "{'loss': 2.0271, 'learning_rate': 1.1738019525801954e-05, 'epoch': 11.8}\n",
      "{'loss': 2.021, 'learning_rate': 1.1719423523942353e-05, 'epoch': 11.82}\n",
      "{'loss': 2.0208, 'learning_rate': 1.1700827522082754e-05, 'epoch': 11.84}\n",
      "{'loss': 2.005, 'learning_rate': 1.1682268712226872e-05, 'epoch': 11.86}\n",
      "{'loss': 2.0341, 'learning_rate': 1.1663672710367271e-05, 'epoch': 11.88}\n",
      "{'loss': 1.9974, 'learning_rate': 1.1645076708507672e-05, 'epoch': 11.9}\n",
      "{'loss': 2.0068, 'learning_rate': 1.162651789865179e-05, 'epoch': 11.92}\n",
      "{'loss': 2.009, 'learning_rate': 1.1607921896792191e-05, 'epoch': 11.95}\n",
      "{'loss': 2.0239, 'learning_rate': 1.158932589493259e-05, 'epoch': 11.97}\n",
      "{'loss': 2.0219, 'learning_rate': 1.157072989307299e-05, 'epoch': 11.99}\n",
      "{'loss': 2.0194, 'learning_rate': 1.155213389121339e-05, 'epoch': 12.01}\n",
      "{'loss': 2.0143, 'learning_rate': 1.153353788935379e-05, 'epoch': 12.03}\n",
      "{'loss': 2.0103, 'learning_rate': 1.151494188749419e-05, 'epoch': 12.05}\n",
      "{'loss': 1.9991, 'learning_rate': 1.149634588563459e-05, 'epoch': 12.07}\n",
      "{'loss': 2.0285, 'learning_rate': 1.147774988377499e-05, 'epoch': 12.09}\n",
      "{'loss': 2.0308, 'learning_rate': 1.1459153881915389e-05, 'epoch': 12.11}\n",
      "{'loss': 1.9978, 'learning_rate': 1.144055788005579e-05, 'epoch': 12.13}\n",
      "{'loss': 2.0084, 'learning_rate': 1.1421961878196189e-05, 'epoch': 12.15}\n",
      "{'loss': 2.0094, 'learning_rate': 1.1403403068340309e-05, 'epoch': 12.18}\n",
      "{'loss': 2.0059, 'learning_rate': 1.1384807066480708e-05, 'epoch': 12.2}\n",
      "{'loss': 2.013, 'learning_rate': 1.1366248256624826e-05, 'epoch': 12.22}\n",
      "{'loss': 1.9999, 'learning_rate': 1.1347652254765227e-05, 'epoch': 12.24}\n",
      "{'loss': 2.0182, 'learning_rate': 1.1329056252905626e-05, 'epoch': 12.26}\n",
      "{'loss': 2.0053, 'learning_rate': 1.1310460251046027e-05, 'epoch': 12.28}\n",
      "{'loss': 2.0286, 'learning_rate': 1.1291864249186427e-05, 'epoch': 12.3}\n",
      "{'loss': 1.995, 'learning_rate': 1.1273268247326826e-05, 'epoch': 12.32}\n",
      "{'loss': 2.0174, 'learning_rate': 1.1254709437470945e-05, 'epoch': 12.34}\n",
      "{'loss': 2.0204, 'learning_rate': 1.1236113435611345e-05, 'epoch': 12.36}\n",
      "{'loss': 2.0013, 'learning_rate': 1.1217517433751744e-05, 'epoch': 12.38}\n",
      "{'loss': 1.9982, 'learning_rate': 1.1198921431892145e-05, 'epoch': 12.41}\n",
      "{'loss': 2.0039, 'learning_rate': 1.1180325430032544e-05, 'epoch': 12.43}\n",
      "{'loss': 2.0079, 'learning_rate': 1.1161729428172942e-05, 'epoch': 12.45}\n",
      "{'loss': 2.0081, 'learning_rate': 1.1143170618317063e-05, 'epoch': 12.47}\n",
      "{'loss': 1.9926, 'learning_rate': 1.1124574616457463e-05, 'epoch': 12.49}\n",
      "{'loss': 2.004, 'learning_rate': 1.1105978614597864e-05, 'epoch': 12.51}\n",
      "{'loss': 2.0126, 'learning_rate': 1.1087382612738263e-05, 'epoch': 12.53}\n",
      "{'loss': 1.9987, 'learning_rate': 1.106878661087866e-05, 'epoch': 12.55}\n",
      "{'loss': 1.9943, 'learning_rate': 1.1050190609019063e-05, 'epoch': 12.57}\n",
      "{'loss': 1.9883, 'learning_rate': 1.103159460715946e-05, 'epoch': 12.59}\n",
      "{'loss': 2.0156, 'learning_rate': 1.1013035797303579e-05, 'epoch': 12.62}\n",
      "{'loss': 1.9927, 'learning_rate': 1.0994439795443981e-05, 'epoch': 12.64}\n",
      "{'loss': 2.0163, 'learning_rate': 1.0975843793584379e-05, 'epoch': 12.66}\n",
      "{'loss': 1.9954, 'learning_rate': 1.0957247791724782e-05, 'epoch': 12.68}\n",
      "{'loss': 2.0033, 'learning_rate': 1.093865178986518e-05, 'epoch': 12.7}\n",
      "{'loss': 2.0132, 'learning_rate': 1.0920055788005579e-05, 'epoch': 12.72}\n",
      "{'loss': 2.0272, 'learning_rate': 1.090145978614598e-05, 'epoch': 12.74}\n",
      "{'loss': 2.0017, 'learning_rate': 1.0882863784286379e-05, 'epoch': 12.76}\n",
      "{'loss': 2.0061, 'learning_rate': 1.0864304974430497e-05, 'epoch': 12.78}\n",
      "{'loss': 1.9924, 'learning_rate': 1.0845708972570898e-05, 'epoch': 12.8}\n",
      "{'loss': 1.9904, 'learning_rate': 1.0827112970711297e-05, 'epoch': 12.82}\n",
      "{'loss': 1.9968, 'learning_rate': 1.0808516968851698e-05, 'epoch': 12.85}\n",
      "{'loss': 2.0125, 'learning_rate': 1.0789958158995816e-05, 'epoch': 12.87}\n",
      "{'loss': 2.0021, 'learning_rate': 1.0771362157136215e-05, 'epoch': 12.89}\n",
      "{'loss': 1.9998, 'learning_rate': 1.0752803347280337e-05, 'epoch': 12.91}\n",
      "{'loss': 2.0004, 'learning_rate': 1.0734207345420734e-05, 'epoch': 12.93}\n",
      "{'loss': 2.0201, 'learning_rate': 1.0715611343561134e-05, 'epoch': 12.95}\n",
      "{'loss': 1.9864, 'learning_rate': 1.0697015341701535e-05, 'epoch': 12.97}\n",
      "{'loss': 2.0075, 'learning_rate': 1.0678419339841934e-05, 'epoch': 12.99}\n",
      "{'loss': 2.0119, 'learning_rate': 1.0659823337982335e-05, 'epoch': 13.01}\n",
      "{'loss': 1.9908, 'learning_rate': 1.0641227336122734e-05, 'epoch': 13.03}\n",
      "{'loss': 1.9982, 'learning_rate': 1.0622631334263133e-05, 'epoch': 13.05}\n",
      "{'loss': 1.983, 'learning_rate': 1.0604072524407255e-05, 'epoch': 13.08}\n",
      "{'loss': 1.9875, 'learning_rate': 1.0585513714551373e-05, 'epoch': 13.1}\n",
      "{'loss': 1.9889, 'learning_rate': 1.056691771269177e-05, 'epoch': 13.12}\n",
      "{'loss': 1.9973, 'learning_rate': 1.0548321710832173e-05, 'epoch': 13.14}\n",
      "{'loss': 2.0064, 'learning_rate': 1.052972570897257e-05, 'epoch': 13.16}\n",
      "{'loss': 1.9925, 'learning_rate': 1.0511129707112973e-05, 'epoch': 13.18}\n",
      "{'loss': 1.9855, 'learning_rate': 1.0492570897257091e-05, 'epoch': 13.2}\n",
      "{'loss': 2.0014, 'learning_rate': 1.0473974895397489e-05, 'epoch': 13.22}\n",
      "{'loss': 1.9872, 'learning_rate': 1.0455378893537892e-05, 'epoch': 13.24}\n",
      "{'loss': 1.9917, 'learning_rate': 1.043678289167829e-05, 'epoch': 13.26}\n",
      "{'loss': 1.9765, 'learning_rate': 1.0418186889818689e-05, 'epoch': 13.28}\n",
      "{'loss': 2.0062, 'learning_rate': 1.039959088795909e-05, 'epoch': 13.31}\n",
      "{'loss': 2.008, 'learning_rate': 1.0380994886099489e-05, 'epoch': 13.33}\n",
      "{'loss': 1.9763, 'learning_rate': 1.036239888423989e-05, 'epoch': 13.35}\n",
      "{'loss': 1.9953, 'learning_rate': 1.0343840074384008e-05, 'epoch': 13.37}\n",
      "{'loss': 2.0012, 'learning_rate': 1.0325244072524407e-05, 'epoch': 13.39}\n",
      "{'loss': 1.9938, 'learning_rate': 1.0306648070664808e-05, 'epoch': 13.41}\n",
      "{'loss': 1.995, 'learning_rate': 1.0288089260808926e-05, 'epoch': 13.43}\n",
      "{'loss': 2.0032, 'learning_rate': 1.0269493258949325e-05, 'epoch': 13.45}\n",
      "{'loss': 1.9868, 'learning_rate': 1.0250897257089726e-05, 'epoch': 13.47}\n",
      "{'loss': 1.9968, 'learning_rate': 1.0232301255230126e-05, 'epoch': 13.49}\n",
      "{'loss': 2.0057, 'learning_rate': 1.0213705253370527e-05, 'epoch': 13.51}\n",
      "{'loss': 1.9772, 'learning_rate': 1.0195109251510926e-05, 'epoch': 13.54}\n",
      "{'loss': 1.987, 'learning_rate': 1.0176550441655044e-05, 'epoch': 13.56}\n",
      "{'loss': 1.9969, 'learning_rate': 1.0157954439795445e-05, 'epoch': 13.58}\n",
      "{'loss': 1.9969, 'learning_rate': 1.0139358437935844e-05, 'epoch': 13.6}\n",
      "{'loss': 1.9754, 'learning_rate': 1.0120762436076243e-05, 'epoch': 13.62}\n",
      "{'loss': 1.9734, 'learning_rate': 1.0102166434216644e-05, 'epoch': 13.64}\n",
      "{'loss': 1.9782, 'learning_rate': 1.0083570432357044e-05, 'epoch': 13.66}\n",
      "{'loss': 1.994, 'learning_rate': 1.0064974430497443e-05, 'epoch': 13.68}\n",
      "{'loss': 1.9878, 'learning_rate': 1.0046378428637844e-05, 'epoch': 13.7}\n",
      "{'loss': 1.9865, 'learning_rate': 1.0027819618781962e-05, 'epoch': 13.72}\n",
      "{'loss': 1.9766, 'learning_rate': 1.0009223616922363e-05, 'epoch': 13.74}\n",
      "{'loss': 1.9818, 'learning_rate': 9.990627615062762e-06, 'epoch': 13.77}\n",
      "{'loss': 1.9955, 'learning_rate': 9.972031613203163e-06, 'epoch': 13.79}\n",
      "{'loss': 2.0047, 'learning_rate': 9.953472803347281e-06, 'epoch': 13.81}\n",
      "{'loss': 1.9943, 'learning_rate': 9.9349139934914e-06, 'epoch': 13.83}\n",
      "{'loss': 1.9965, 'learning_rate': 9.9163179916318e-06, 'epoch': 13.85}\n",
      "{'loss': 1.9843, 'learning_rate': 9.8977219897722e-06, 'epoch': 13.87}\n",
      "{'loss': 1.9787, 'learning_rate': 9.8791259879126e-06, 'epoch': 13.89}\n",
      "{'loss': 1.9988, 'learning_rate': 9.860567178056718e-06, 'epoch': 13.91}\n",
      "{'loss': 1.99, 'learning_rate': 9.841971176197118e-06, 'epoch': 13.93}\n",
      "{'loss': 2.0007, 'learning_rate': 9.823375174337519e-06, 'epoch': 13.95}\n",
      "{'loss': 1.98, 'learning_rate': 9.804779172477918e-06, 'epoch': 13.97}\n",
      "{'loss': 1.9857, 'learning_rate': 9.786183170618317e-06, 'epoch': 14.0}\n",
      "{'loss': 1.9777, 'learning_rate': 9.767587168758718e-06, 'epoch': 14.02}\n",
      "{'loss': 1.9698, 'learning_rate': 9.748991166899118e-06, 'epoch': 14.04}\n",
      "{'loss': 1.98, 'learning_rate': 9.730395165039517e-06, 'epoch': 14.06}\n",
      "{'loss': 1.9811, 'learning_rate': 9.711836355183637e-06, 'epoch': 14.08}\n",
      "{'loss': 1.9881, 'learning_rate': 9.693240353324036e-06, 'epoch': 14.1}\n",
      "{'loss': 1.9888, 'learning_rate': 9.674644351464437e-06, 'epoch': 14.12}\n",
      "{'loss': 1.9761, 'learning_rate': 9.656048349604836e-06, 'epoch': 14.14}\n",
      "{'loss': 1.9963, 'learning_rate': 9.637489539748954e-06, 'epoch': 14.16}\n",
      "{'loss': 1.9653, 'learning_rate': 9.618893537889355e-06, 'epoch': 14.18}\n",
      "{'loss': 1.9706, 'learning_rate': 9.600297536029754e-06, 'epoch': 14.21}\n",
      "{'loss': 1.983, 'learning_rate': 9.581701534170155e-06, 'epoch': 14.23}\n",
      "{'loss': 2.0005, 'learning_rate': 9.563105532310553e-06, 'epoch': 14.25}\n",
      "{'loss': 1.9971, 'learning_rate': 9.544509530450954e-06, 'epoch': 14.27}\n",
      "{'loss': 1.9803, 'learning_rate': 9.525913528591353e-06, 'epoch': 14.29}\n",
      "{'loss': 1.971, 'learning_rate': 9.507317526731752e-06, 'epoch': 14.31}\n",
      "{'loss': 1.9764, 'learning_rate': 9.488758716875872e-06, 'epoch': 14.33}\n",
      "{'loss': 1.9817, 'learning_rate': 9.470162715016271e-06, 'epoch': 14.35}\n",
      "{'loss': 1.9824, 'learning_rate': 9.451603905160391e-06, 'epoch': 14.37}\n",
      "{'loss': 1.9745, 'learning_rate': 9.433007903300792e-06, 'epoch': 14.39}\n",
      "{'loss': 1.9668, 'learning_rate': 9.41441190144119e-06, 'epoch': 14.41}\n",
      "{'loss': 1.9842, 'learning_rate': 9.39581589958159e-06, 'epoch': 14.44}\n",
      "{'loss': 1.9783, 'learning_rate': 9.37721989772199e-06, 'epoch': 14.46}\n",
      "{'loss': 1.9848, 'learning_rate': 9.35862389586239e-06, 'epoch': 14.48}\n",
      "{'loss': 1.9756, 'learning_rate': 9.34002789400279e-06, 'epoch': 14.5}\n",
      "{'loss': 1.9764, 'learning_rate': 9.32143189214319e-06, 'epoch': 14.52}\n",
      "{'loss': 1.9555, 'learning_rate': 9.30287308228731e-06, 'epoch': 14.54}\n",
      "{'loss': 1.9761, 'learning_rate': 9.284277080427709e-06, 'epoch': 14.56}\n",
      "{'loss': 1.9955, 'learning_rate': 9.265681078568108e-06, 'epoch': 14.58}\n",
      "{'loss': 1.9695, 'learning_rate': 9.247085076708509e-06, 'epoch': 14.6}\n",
      "{'loss': 1.9764, 'learning_rate': 9.228489074848908e-06, 'epoch': 14.62}\n",
      "{'loss': 1.9819, 'learning_rate': 9.209930264993028e-06, 'epoch': 14.64}\n",
      "{'loss': 2.0033, 'learning_rate': 9.191334263133427e-06, 'epoch': 14.67}\n",
      "{'loss': 1.9547, 'learning_rate': 9.172775453277547e-06, 'epoch': 14.69}\n",
      "{'loss': 1.9657, 'learning_rate': 9.154179451417946e-06, 'epoch': 14.71}\n",
      "{'loss': 1.9644, 'learning_rate': 9.135583449558347e-06, 'epoch': 14.73}\n",
      "{'loss': 1.9748, 'learning_rate': 9.116987447698745e-06, 'epoch': 14.75}\n",
      "{'loss': 1.9593, 'learning_rate': 9.098391445839146e-06, 'epoch': 14.77}\n",
      "{'loss': 1.9781, 'learning_rate': 9.079795443979545e-06, 'epoch': 14.79}\n",
      "{'loss': 1.9733, 'learning_rate': 9.061199442119944e-06, 'epoch': 14.81}\n",
      "{'loss': 1.9868, 'learning_rate': 9.042603440260345e-06, 'epoch': 14.83}\n",
      "{'loss': 1.9856, 'learning_rate': 9.024081822408184e-06, 'epoch': 14.85}\n",
      "{'loss': 1.9813, 'learning_rate': 9.005485820548583e-06, 'epoch': 14.87}\n",
      "{'loss': 1.9803, 'learning_rate': 8.986889818688984e-06, 'epoch': 14.9}\n",
      "{'loss': 1.9697, 'learning_rate': 8.968293816829381e-06, 'epoch': 14.92}\n",
      "{'loss': 1.9766, 'learning_rate': 8.949697814969782e-06, 'epoch': 14.94}\n",
      "{'loss': 1.9618, 'learning_rate': 8.931101813110182e-06, 'epoch': 14.96}\n",
      "{'loss': 1.9617, 'learning_rate': 8.912505811250581e-06, 'epoch': 14.98}\n",
      "{'loss': 1.9691, 'learning_rate': 8.893909809390982e-06, 'epoch': 15.0}\n",
      "{'loss': 1.9701, 'learning_rate': 8.8753509995351e-06, 'epoch': 15.02}\n",
      "{'loss': 1.9641, 'learning_rate': 8.856754997675501e-06, 'epoch': 15.04}\n",
      "{'loss': 1.9725, 'learning_rate': 8.8381589958159e-06, 'epoch': 15.06}\n",
      "{'loss': 1.9691, 'learning_rate': 8.8195629939563e-06, 'epoch': 15.08}\n",
      "{'loss': 1.9808, 'learning_rate': 8.80100418410042e-06, 'epoch': 15.1}\n",
      "{'loss': 1.969, 'learning_rate': 8.782408182240818e-06, 'epoch': 15.13}\n",
      "{'loss': 1.9644, 'learning_rate': 8.76381218038122e-06, 'epoch': 15.15}\n",
      "{'loss': 1.9597, 'learning_rate': 8.745216178521619e-06, 'epoch': 15.17}\n",
      "{'loss': 1.9613, 'learning_rate': 8.726657368665737e-06, 'epoch': 15.19}\n",
      "{'loss': 1.9755, 'learning_rate': 8.708061366806138e-06, 'epoch': 15.21}\n",
      "{'loss': 1.9596, 'learning_rate': 8.689465364946537e-06, 'epoch': 15.23}\n",
      "{'loss': 1.9637, 'learning_rate': 8.670869363086936e-06, 'epoch': 15.25}\n",
      "{'loss': 1.9867, 'learning_rate': 8.652310553231056e-06, 'epoch': 15.27}\n",
      "{'loss': 1.9413, 'learning_rate': 8.633714551371455e-06, 'epoch': 15.29}\n",
      "{'loss': 1.967, 'learning_rate': 8.615155741515575e-06, 'epoch': 15.31}\n",
      "{'loss': 1.9572, 'learning_rate': 8.596559739655974e-06, 'epoch': 15.33}\n",
      "{'loss': 1.9693, 'learning_rate': 8.577963737796374e-06, 'epoch': 15.36}\n",
      "{'loss': 1.9565, 'learning_rate': 8.559367735936775e-06, 'epoch': 15.38}\n",
      "{'loss': 1.9727, 'learning_rate': 8.540771734077174e-06, 'epoch': 15.4}\n",
      "{'loss': 1.9592, 'learning_rate': 8.522175732217573e-06, 'epoch': 15.42}\n",
      "{'loss': 1.9732, 'learning_rate': 8.503579730357974e-06, 'epoch': 15.44}\n",
      "{'loss': 1.9658, 'learning_rate': 8.485020920502092e-06, 'epoch': 15.46}\n",
      "{'loss': 1.9707, 'learning_rate': 8.466424918642493e-06, 'epoch': 15.48}\n",
      "{'loss': 1.9509, 'learning_rate': 8.447828916782892e-06, 'epoch': 15.5}\n",
      "{'loss': 1.9709, 'learning_rate': 8.429232914923292e-06, 'epoch': 15.52}\n",
      "{'loss': 1.9843, 'learning_rate': 8.410636913063693e-06, 'epoch': 15.54}\n",
      "{'loss': 1.9702, 'learning_rate': 8.39207810320781e-06, 'epoch': 15.56}\n",
      "{'loss': 1.9447, 'learning_rate': 8.37348210134821e-06, 'epoch': 15.59}\n",
      "{'loss': 1.9648, 'learning_rate': 8.354886099488611e-06, 'epoch': 15.61}\n",
      "{'loss': 1.9728, 'learning_rate': 8.33629009762901e-06, 'epoch': 15.63}\n",
      "{'loss': 1.9709, 'learning_rate': 8.317694095769411e-06, 'epoch': 15.65}\n",
      "{'loss': 1.9707, 'learning_rate': 8.299135285913529e-06, 'epoch': 15.67}\n",
      "{'loss': 1.9619, 'learning_rate': 8.280539284053928e-06, 'epoch': 15.69}\n",
      "{'loss': 1.9652, 'learning_rate': 8.26194328219433e-06, 'epoch': 15.71}\n",
      "{'loss': 1.9717, 'learning_rate': 8.243347280334729e-06, 'epoch': 15.73}\n",
      "{'loss': 1.9672, 'learning_rate': 8.224751278475128e-06, 'epoch': 15.75}\n",
      "{'loss': 1.9757, 'learning_rate': 8.206155276615529e-06, 'epoch': 15.77}\n",
      "{'loss': 1.9716, 'learning_rate': 8.187559274755928e-06, 'epoch': 15.79}\n",
      "{'loss': 1.9553, 'learning_rate': 8.168963272896328e-06, 'epoch': 15.82}\n",
      "{'loss': 1.9647, 'learning_rate': 8.150404463040447e-06, 'epoch': 15.84}\n",
      "{'loss': 1.9731, 'learning_rate': 8.131845653184565e-06, 'epoch': 15.86}\n",
      "{'loss': 1.9686, 'learning_rate': 8.113249651324966e-06, 'epoch': 15.88}\n",
      "{'loss': 1.9514, 'learning_rate': 8.094653649465365e-06, 'epoch': 15.9}\n",
      "{'loss': 1.9662, 'learning_rate': 8.076057647605765e-06, 'epoch': 15.92}\n",
      "{'loss': 1.9567, 'learning_rate': 8.057461645746166e-06, 'epoch': 15.94}\n",
      "{'loss': 1.9561, 'learning_rate': 8.038865643886565e-06, 'epoch': 15.96}\n",
      "{'loss': 1.9642, 'learning_rate': 8.020269642026964e-06, 'epoch': 15.98}\n",
      "{'loss': 1.9682, 'learning_rate': 8.001673640167365e-06, 'epoch': 16.0}\n",
      "{'loss': 1.963, 'learning_rate': 7.983077638307765e-06, 'epoch': 16.03}\n",
      "{'loss': 1.9421, 'learning_rate': 7.964518828451884e-06, 'epoch': 16.05}\n",
      "{'loss': 1.9492, 'learning_rate': 7.945960018596002e-06, 'epoch': 16.07}\n",
      "{'loss': 1.9699, 'learning_rate': 7.927364016736402e-06, 'epoch': 16.09}\n",
      "{'loss': 1.9577, 'learning_rate': 7.908768014876803e-06, 'epoch': 16.11}\n",
      "{'loss': 1.9592, 'learning_rate': 7.890172013017202e-06, 'epoch': 16.13}\n",
      "{'loss': 1.954, 'learning_rate': 7.871576011157603e-06, 'epoch': 16.15}\n",
      "{'loss': 1.9444, 'learning_rate': 7.852980009298002e-06, 'epoch': 16.17}\n",
      "{'loss': 1.9809, 'learning_rate': 7.834384007438401e-06, 'epoch': 16.19}\n",
      "{'loss': 1.9821, 'learning_rate': 7.815825197582521e-06, 'epoch': 16.21}\n",
      "{'loss': 1.939, 'learning_rate': 7.79722919572292e-06, 'epoch': 16.23}\n",
      "{'loss': 1.9436, 'learning_rate': 7.77863319386332e-06, 'epoch': 16.26}\n",
      "{'loss': 1.9639, 'learning_rate': 7.76003719200372e-06, 'epoch': 16.28}\n",
      "{'loss': 1.9594, 'learning_rate': 7.74144119014412e-06, 'epoch': 16.3}\n",
      "{'loss': 1.9615, 'learning_rate': 7.72284518828452e-06, 'epoch': 16.32}\n",
      "{'loss': 1.9507, 'learning_rate': 7.704286378428639e-06, 'epoch': 16.34}\n",
      "{'loss': 1.9444, 'learning_rate': 7.685690376569038e-06, 'epoch': 16.36}\n",
      "{'loss': 1.9558, 'learning_rate': 7.66709437470944e-06, 'epoch': 16.38}\n",
      "{'loss': 1.9526, 'learning_rate': 7.648498372849837e-06, 'epoch': 16.4}\n",
      "{'loss': 1.954, 'learning_rate': 7.629902370990238e-06, 'epoch': 16.42}\n",
      "{'loss': 1.959, 'learning_rate': 7.611306369130638e-06, 'epoch': 16.44}\n",
      "{'loss': 1.9522, 'learning_rate': 7.592710367271038e-06, 'epoch': 16.46}\n",
      "{'loss': 1.9614, 'learning_rate': 7.574151557415156e-06, 'epoch': 16.49}\n",
      "{'loss': 1.9317, 'learning_rate': 7.555555555555556e-06, 'epoch': 16.51}\n",
      "{'loss': 1.9615, 'learning_rate': 7.536959553695956e-06, 'epoch': 16.53}\n",
      "{'loss': 1.9362, 'learning_rate': 7.518363551836356e-06, 'epoch': 16.55}\n",
      "{'loss': 1.9509, 'learning_rate': 7.499767549976755e-06, 'epoch': 16.57}\n",
      "{'loss': 1.9439, 'learning_rate': 7.4812087401208746e-06, 'epoch': 16.59}\n",
      "{'loss': 1.9626, 'learning_rate': 7.462612738261275e-06, 'epoch': 16.61}\n",
      "{'loss': 1.9491, 'learning_rate': 7.444016736401675e-06, 'epoch': 16.63}\n",
      "{'loss': 1.964, 'learning_rate': 7.425420734542073e-06, 'epoch': 16.65}\n",
      "{'loss': 1.9726, 'learning_rate': 7.406824732682473e-06, 'epoch': 16.67}\n",
      "{'loss': 1.9695, 'learning_rate': 7.3882287308228735e-06, 'epoch': 16.69}\n",
      "{'loss': 1.9498, 'learning_rate': 7.369632728963273e-06, 'epoch': 16.72}\n",
      "{'loss': 1.9442, 'learning_rate': 7.3510739191073925e-06, 'epoch': 16.74}\n",
      "{'loss': 1.9474, 'learning_rate': 7.332477917247793e-06, 'epoch': 16.76}\n",
      "{'loss': 1.957, 'learning_rate': 7.313881915388193e-06, 'epoch': 16.78}\n",
      "{'loss': 1.9465, 'learning_rate': 7.295285913528593e-06, 'epoch': 16.8}\n",
      "{'loss': 1.936, 'learning_rate': 7.276689911668991e-06, 'epoch': 16.82}\n",
      "{'loss': 1.9454, 'learning_rate': 7.258131101813111e-06, 'epoch': 16.84}\n",
      "{'loss': 1.9513, 'learning_rate': 7.239535099953511e-06, 'epoch': 16.86}\n",
      "{'loss': 1.9644, 'learning_rate': 7.220939098093911e-06, 'epoch': 16.88}\n",
      "{'loss': 1.9493, 'learning_rate': 7.20234309623431e-06, 'epoch': 16.9}\n",
      "{'loss': 1.9691, 'learning_rate': 7.1837842863784294e-06, 'epoch': 16.92}\n",
      "{'loss': 1.9522, 'learning_rate': 7.16518828451883e-06, 'epoch': 16.95}\n",
      "{'loss': 1.9626, 'learning_rate': 7.14659228265923e-06, 'epoch': 16.97}\n",
      "{'loss': 1.949, 'learning_rate': 7.127996280799628e-06, 'epoch': 16.99}\n",
      "{'loss': 1.9315, 'learning_rate': 7.109400278940028e-06, 'epoch': 17.01}\n",
      "{'loss': 1.9501, 'learning_rate': 7.090804277080428e-06, 'epoch': 17.03}\n",
      "{'loss': 1.9591, 'learning_rate': 7.072208275220828e-06, 'epoch': 17.05}\n",
      "{'loss': 1.9415, 'learning_rate': 7.053612273361228e-06, 'epoch': 17.07}\n",
      "{'loss': 1.9293, 'learning_rate': 7.035016271501628e-06, 'epoch': 17.09}\n",
      "{'loss': 1.9437, 'learning_rate': 7.016457461645747e-06, 'epoch': 17.11}\n",
      "{'loss': 1.9505, 'learning_rate': 6.997861459786146e-06, 'epoch': 17.13}\n",
      "{'loss': 1.9482, 'learning_rate': 6.979265457926546e-06, 'epoch': 17.15}\n",
      "{'loss': 1.9348, 'learning_rate': 6.960669456066946e-06, 'epoch': 17.18}\n",
      "{'loss': 1.9503, 'learning_rate': 6.942110646211065e-06, 'epoch': 17.2}\n",
      "{'loss': 1.9465, 'learning_rate': 6.9235146443514645e-06, 'epoch': 17.22}\n",
      "{'loss': 1.9575, 'learning_rate': 6.904918642491865e-06, 'epoch': 17.24}\n",
      "{'loss': 1.9489, 'learning_rate': 6.886322640632265e-06, 'epoch': 17.26}\n",
      "{'loss': 1.9573, 'learning_rate': 6.867726638772665e-06, 'epoch': 17.28}\n",
      "{'loss': 1.944, 'learning_rate': 6.849167828916784e-06, 'epoch': 17.3}\n",
      "{'loss': 1.9491, 'learning_rate': 6.830571827057183e-06, 'epoch': 17.32}\n",
      "{'loss': 1.9498, 'learning_rate': 6.811975825197583e-06, 'epoch': 17.34}\n",
      "{'loss': 1.9395, 'learning_rate': 6.793379823337983e-06, 'epoch': 17.36}\n",
      "{'loss': 1.9189, 'learning_rate': 6.774783821478383e-06, 'epoch': 17.38}\n",
      "{'loss': 1.9316, 'learning_rate': 6.7562250116225014e-06, 'epoch': 17.41}\n",
      "{'loss': 1.9401, 'learning_rate': 6.737629009762902e-06, 'epoch': 17.43}\n",
      "{'loss': 1.9436, 'learning_rate': 6.719033007903302e-06, 'epoch': 17.45}\n",
      "{'loss': 1.9277, 'learning_rate': 6.700437006043701e-06, 'epoch': 17.47}\n",
      "{'loss': 1.9664, 'learning_rate': 6.681841004184101e-06, 'epoch': 17.49}\n",
      "{'loss': 1.9337, 'learning_rate': 6.66328219432822e-06, 'epoch': 17.51}\n",
      "{'loss': 1.9484, 'learning_rate': 6.64468619246862e-06, 'epoch': 17.53}\n",
      "{'loss': 1.9549, 'learning_rate': 6.626090190609019e-06, 'epoch': 17.55}\n",
      "{'loss': 1.9278, 'learning_rate': 6.6074941887494195e-06, 'epoch': 17.57}\n",
      "{'loss': 1.9476, 'learning_rate': 6.58889818688982e-06, 'epoch': 17.59}\n",
      "{'loss': 1.9408, 'learning_rate': 6.57030218503022e-06, 'epoch': 17.62}\n",
      "{'loss': 1.9401, 'learning_rate': 6.551706183170618e-06, 'epoch': 17.64}\n",
      "{'loss': 1.9649, 'learning_rate': 6.533110181311018e-06, 'epoch': 17.66}\n",
      "{'loss': 1.9419, 'learning_rate': 6.514551371455138e-06, 'epoch': 17.68}\n",
      "{'loss': 1.9371, 'learning_rate': 6.495955369595538e-06, 'epoch': 17.7}\n",
      "{'loss': 1.9468, 'learning_rate': 6.477396559739656e-06, 'epoch': 17.72}\n",
      "{'loss': 1.9752, 'learning_rate': 6.458800557880056e-06, 'epoch': 17.74}\n",
      "{'loss': 1.9367, 'learning_rate': 6.4402045560204565e-06, 'epoch': 17.76}\n",
      "{'loss': 1.9367, 'learning_rate': 6.421608554160857e-06, 'epoch': 17.78}\n",
      "{'loss': 1.9383, 'learning_rate': 6.403012552301255e-06, 'epoch': 17.8}\n",
      "{'loss': 1.9437, 'learning_rate': 6.384416550441655e-06, 'epoch': 17.82}\n",
      "{'loss': 1.9446, 'learning_rate': 6.365820548582055e-06, 'epoch': 17.85}\n",
      "{'loss': 1.9366, 'learning_rate': 6.347224546722455e-06, 'epoch': 17.87}\n",
      "{'loss': 1.9265, 'learning_rate': 6.3286657368665734e-06, 'epoch': 17.89}\n",
      "{'loss': 1.9427, 'learning_rate': 6.310069735006974e-06, 'epoch': 17.91}\n",
      "{'loss': 1.9564, 'learning_rate': 6.291473733147374e-06, 'epoch': 17.93}\n",
      "{'loss': 1.9172, 'learning_rate': 6.272877731287773e-06, 'epoch': 17.95}\n",
      "{'loss': 1.9398, 'learning_rate': 6.254318921431892e-06, 'epoch': 17.97}\n",
      "{'loss': 1.9378, 'learning_rate': 6.235722919572292e-06, 'epoch': 17.99}\n",
      "{'loss': 1.9538, 'learning_rate': 6.217126917712692e-06, 'epoch': 18.01}\n",
      "{'loss': 1.9453, 'learning_rate': 6.198530915853092e-06, 'epoch': 18.03}\n",
      "{'loss': 1.9419, 'learning_rate': 6.17997210599721e-06, 'epoch': 18.05}\n",
      "{'loss': 1.921, 'learning_rate': 6.16141329614133e-06, 'epoch': 18.08}\n",
      "{'loss': 1.9213, 'learning_rate': 6.14281729428173e-06, 'epoch': 18.1}\n",
      "{'loss': 1.9451, 'learning_rate': 6.12422129242213e-06, 'epoch': 18.12}\n",
      "{'loss': 1.9359, 'learning_rate': 6.105625290562529e-06, 'epoch': 18.14}\n",
      "{'loss': 1.9471, 'learning_rate': 6.087029288702929e-06, 'epoch': 18.16}\n",
      "{'loss': 1.9394, 'learning_rate': 6.068433286843329e-06, 'epoch': 18.18}\n",
      "{'loss': 1.9372, 'learning_rate': 6.049837284983729e-06, 'epoch': 18.2}\n",
      "{'loss': 1.9498, 'learning_rate': 6.031241283124128e-06, 'epoch': 18.22}\n",
      "{'loss': 1.943, 'learning_rate': 6.0126452812645285e-06, 'epoch': 18.24}\n",
      "{'loss': 1.9319, 'learning_rate': 5.994086471408648e-06, 'epoch': 18.26}\n",
      "{'loss': 1.9312, 'learning_rate': 5.975490469549048e-06, 'epoch': 18.28}\n",
      "{'loss': 1.9444, 'learning_rate': 5.956894467689447e-06, 'epoch': 18.31}\n",
      "{'loss': 1.9415, 'learning_rate': 5.938298465829847e-06, 'epoch': 18.33}\n",
      "{'loss': 1.9329, 'learning_rate': 5.9197396559739666e-06, 'epoch': 18.35}\n",
      "{'loss': 1.9377, 'learning_rate': 5.901180846118085e-06, 'epoch': 18.37}\n",
      "{'loss': 1.9286, 'learning_rate': 5.8825848442584855e-06, 'epoch': 18.39}\n",
      "{'loss': 1.9412, 'learning_rate': 5.863988842398885e-06, 'epoch': 18.41}\n",
      "{'loss': 1.9277, 'learning_rate': 5.845392840539285e-06, 'epoch': 18.43}\n",
      "{'loss': 1.9326, 'learning_rate': 5.826796838679685e-06, 'epoch': 18.45}\n",
      "{'loss': 1.9361, 'learning_rate': 5.8082008368200835e-06, 'epoch': 18.47}\n",
      "{'loss': 1.9452, 'learning_rate': 5.789604834960484e-06, 'epoch': 18.49}\n",
      "{'loss': 1.923, 'learning_rate': 5.771008833100884e-06, 'epoch': 18.51}\n",
      "{'loss': 1.9277, 'learning_rate': 5.752412831241284e-06, 'epoch': 18.54}\n",
      "{'loss': 1.9248, 'learning_rate': 5.733854021385402e-06, 'epoch': 18.56}\n",
      "{'loss': 1.9305, 'learning_rate': 5.715258019525802e-06, 'epoch': 18.58}\n",
      "{'loss': 1.9237, 'learning_rate': 5.696662017666202e-06, 'epoch': 18.6}\n",
      "{'loss': 1.9338, 'learning_rate': 5.678066015806602e-06, 'epoch': 18.62}\n",
      "{'loss': 1.9297, 'learning_rate': 5.65950720595072e-06, 'epoch': 18.64}\n",
      "{'loss': 1.9272, 'learning_rate': 5.6409112040911205e-06, 'epoch': 18.66}\n",
      "{'loss': 1.9441, 'learning_rate': 5.622315202231521e-06, 'epoch': 18.68}\n",
      "{'loss': 1.9344, 'learning_rate': 5.603719200371921e-06, 'epoch': 18.7}\n",
      "{'loss': 1.9289, 'learning_rate': 5.585160390516039e-06, 'epoch': 18.72}\n",
      "{'loss': 1.936, 'learning_rate': 5.566564388656439e-06, 'epoch': 18.74}\n",
      "{'loss': 1.933, 'learning_rate': 5.547968386796839e-06, 'epoch': 18.77}\n",
      "{'loss': 1.9331, 'learning_rate': 5.529372384937239e-06, 'epoch': 18.79}\n",
      "{'loss': 1.9393, 'learning_rate': 5.510813575081359e-06, 'epoch': 18.81}\n",
      "{'loss': 1.9383, 'learning_rate': 5.492217573221757e-06, 'epoch': 18.83}\n",
      "{'loss': 1.9239, 'learning_rate': 5.473621571362157e-06, 'epoch': 18.85}\n",
      "{'loss': 1.9184, 'learning_rate': 5.4550255695025575e-06, 'epoch': 18.87}\n",
      "{'loss': 1.9301, 'learning_rate': 5.436429567642957e-06, 'epoch': 18.89}\n",
      "{'loss': 1.9364, 'learning_rate': 5.417870757787076e-06, 'epoch': 18.91}\n",
      "{'loss': 1.9167, 'learning_rate': 5.399274755927476e-06, 'epoch': 18.93}\n",
      "{'loss': 1.9345, 'learning_rate': 5.3807159460715955e-06, 'epoch': 18.95}\n",
      "{'loss': 1.9325, 'learning_rate': 5.362119944211996e-06, 'epoch': 18.97}\n",
      "{'loss': 1.9161, 'learning_rate': 5.343523942352394e-06, 'epoch': 19.0}\n",
      "{'loss': 1.9377, 'learning_rate': 5.324927940492794e-06, 'epoch': 19.02}\n",
      "{'loss': 1.9416, 'learning_rate': 5.306331938633194e-06, 'epoch': 19.04}\n",
      "{'loss': 1.9354, 'learning_rate': 5.287735936773594e-06, 'epoch': 19.06}\n",
      "{'loss': 1.9248, 'learning_rate': 5.269139934913994e-06, 'epoch': 19.08}\n",
      "{'loss': 1.9263, 'learning_rate': 5.250543933054394e-06, 'epoch': 19.1}\n",
      "{'loss': 1.9143, 'learning_rate': 5.231985123198513e-06, 'epoch': 19.12}\n",
      "{'loss': 1.9432, 'learning_rate': 5.213389121338912e-06, 'epoch': 19.14}\n",
      "{'loss': 1.9264, 'learning_rate': 5.194793119479312e-06, 'epoch': 19.16}\n",
      "{'loss': 1.9237, 'learning_rate': 5.176197117619712e-06, 'epoch': 19.18}\n",
      "{'loss': 1.9255, 'learning_rate': 5.157638307763831e-06, 'epoch': 19.21}\n",
      "{'loss': 1.9164, 'learning_rate': 5.1390423059042304e-06, 'epoch': 19.23}\n",
      "{'loss': 1.9136, 'learning_rate': 5.120483496048349e-06, 'epoch': 19.25}\n",
      "{'loss': 1.9259, 'learning_rate': 5.101887494188749e-06, 'epoch': 19.27}\n",
      "{'loss': 1.914, 'learning_rate': 5.0832914923291495e-06, 'epoch': 19.29}\n",
      "{'loss': 1.9167, 'learning_rate': 5.06469549046955e-06, 'epoch': 19.31}\n",
      "{'loss': 1.9299, 'learning_rate': 5.046099488609949e-06, 'epoch': 19.33}\n",
      "{'loss': 1.9407, 'learning_rate': 5.027540678754068e-06, 'epoch': 19.35}\n",
      "{'loss': 1.9201, 'learning_rate': 5.008944676894468e-06, 'epoch': 19.37}\n",
      "{'loss': 1.9059, 'learning_rate': 4.990348675034868e-06, 'epoch': 19.39}\n",
      "{'loss': 1.9447, 'learning_rate': 4.971752673175268e-06, 'epoch': 19.41}\n",
      "{'loss': 1.9376, 'learning_rate': 4.9531566713156675e-06, 'epoch': 19.44}\n",
      "{'loss': 1.9274, 'learning_rate': 4.934560669456067e-06, 'epoch': 19.46}\n",
      "{'loss': 1.9162, 'learning_rate': 4.915964667596467e-06, 'epoch': 19.48}\n",
      "{'loss': 1.9276, 'learning_rate': 4.897368665736867e-06, 'epoch': 19.5}\n",
      "{'loss': 1.9316, 'learning_rate': 4.878809855880986e-06, 'epoch': 19.52}\n",
      "{'loss': 1.9111, 'learning_rate': 4.860213854021385e-06, 'epoch': 19.54}\n",
      "{'loss': 1.941, 'learning_rate': 4.841617852161785e-06, 'epoch': 19.56}\n",
      "{'loss': 1.9219, 'learning_rate': 4.8230218503021854e-06, 'epoch': 19.58}\n",
      "{'loss': 1.9127, 'learning_rate': 4.804463040446304e-06, 'epoch': 19.6}\n",
      "{'loss': 1.9349, 'learning_rate': 4.785867038586704e-06, 'epoch': 19.62}\n",
      "{'loss': 1.9061, 'learning_rate': 4.767271036727104e-06, 'epoch': 19.64}\n",
      "{'loss': 1.9255, 'learning_rate': 4.748675034867504e-06, 'epoch': 19.67}\n",
      "{'loss': 1.9178, 'learning_rate': 4.730116225011623e-06, 'epoch': 19.69}\n",
      "{'loss': 1.9266, 'learning_rate': 4.711520223152023e-06, 'epoch': 19.71}\n",
      "{'loss': 1.9335, 'learning_rate': 4.692924221292422e-06, 'epoch': 19.73}\n",
      "{'loss': 1.9244, 'learning_rate': 4.674328219432822e-06, 'epoch': 19.75}\n",
      "{'loss': 1.9198, 'learning_rate': 4.655769409576941e-06, 'epoch': 19.77}\n",
      "{'loss': 1.9286, 'learning_rate': 4.63721059972106e-06, 'epoch': 19.79}\n",
      "{'loss': 1.9333, 'learning_rate': 4.61861459786146e-06, 'epoch': 19.81}\n",
      "{'loss': 1.9248, 'learning_rate': 4.60001859600186e-06, 'epoch': 19.83}\n",
      "{'loss': 1.9115, 'learning_rate': 4.5814225941422595e-06, 'epoch': 19.85}\n",
      "{'loss': 1.9312, 'learning_rate': 4.56282659228266e-06, 'epoch': 19.87}\n",
      "{'loss': 1.9211, 'learning_rate': 4.54423059042306e-06, 'epoch': 19.9}\n",
      "{'loss': 1.9187, 'learning_rate': 4.52563458856346e-06, 'epoch': 19.92}\n",
      "{'loss': 1.9334, 'learning_rate': 4.5071129707112975e-06, 'epoch': 19.94}\n",
      "{'loss': 1.9225, 'learning_rate': 4.488516968851698e-06, 'epoch': 19.96}\n",
      "{'loss': 1.9271, 'learning_rate': 4.469920966992098e-06, 'epoch': 19.98}\n",
      "{'loss': 1.916, 'learning_rate': 4.451324965132497e-06, 'epoch': 20.0}\n",
      "{'loss': 1.9378, 'learning_rate': 4.432728963272896e-06, 'epoch': 20.02}\n",
      "{'loss': 1.9196, 'learning_rate': 4.4141329614132964e-06, 'epoch': 20.04}\n",
      "{'loss': 1.9462, 'learning_rate': 4.3955369595536966e-06, 'epoch': 20.06}\n",
      "{'loss': 1.9244, 'learning_rate': 4.376940957694097e-06, 'epoch': 20.08}\n",
      "{'loss': 1.924, 'learning_rate': 4.358344955834496e-06, 'epoch': 20.1}\n",
      "{'loss': 1.9187, 'learning_rate': 4.339748953974895e-06, 'epoch': 20.13}\n",
      "{'loss': 1.9245, 'learning_rate': 4.321190144119015e-06, 'epoch': 20.15}\n",
      "{'loss': 1.9085, 'learning_rate': 4.302594142259415e-06, 'epoch': 20.17}\n",
      "{'loss': 1.9281, 'learning_rate': 4.283998140399814e-06, 'epoch': 20.19}\n",
      "{'loss': 1.9315, 'learning_rate': 4.2654021385402145e-06, 'epoch': 20.21}\n",
      "{'loss': 1.9027, 'learning_rate': 4.246806136680614e-06, 'epoch': 20.23}\n",
      "{'loss': 1.9135, 'learning_rate': 4.228210134821014e-06, 'epoch': 20.25}\n",
      "{'loss': 1.9227, 'learning_rate': 4.209614132961414e-06, 'epoch': 20.27}\n",
      "{'loss': 1.9426, 'learning_rate': 4.191018131101813e-06, 'epoch': 20.29}\n",
      "{'loss': 1.9106, 'learning_rate': 4.172496513249652e-06, 'epoch': 20.31}\n",
      "{'loss': 1.9239, 'learning_rate': 4.153900511390052e-06, 'epoch': 20.33}\n",
      "{'loss': 1.9147, 'learning_rate': 4.135304509530451e-06, 'epoch': 20.36}\n",
      "{'loss': 1.9185, 'learning_rate': 4.116708507670851e-06, 'epoch': 20.38}\n",
      "{'loss': 1.9239, 'learning_rate': 4.098112505811251e-06, 'epoch': 20.4}\n",
      "{'loss': 1.909, 'learning_rate': 4.079516503951651e-06, 'epoch': 20.42}\n",
      "{'loss': 1.9263, 'learning_rate': 4.060920502092051e-06, 'epoch': 20.44}\n",
      "{'loss': 1.9327, 'learning_rate': 4.04232450023245e-06, 'epoch': 20.46}\n",
      "{'loss': 1.9188, 'learning_rate': 4.023765690376569e-06, 'epoch': 20.48}\n",
      "{'loss': 1.9367, 'learning_rate': 4.005206880520689e-06, 'epoch': 20.5}\n",
      "{'loss': 1.9209, 'learning_rate': 3.986610878661088e-06, 'epoch': 20.52}\n",
      "{'loss': 1.9132, 'learning_rate': 3.968014876801488e-06, 'epoch': 20.54}\n",
      "{'loss': 1.9117, 'learning_rate': 3.949418874941887e-06, 'epoch': 20.56}\n",
      "{'loss': 1.9192, 'learning_rate': 3.9308228730822875e-06, 'epoch': 20.59}\n",
      "{'loss': 1.9166, 'learning_rate': 3.912226871222688e-06, 'epoch': 20.61}\n",
      "{'loss': 1.9164, 'learning_rate': 3.893630869363087e-06, 'epoch': 20.63}\n",
      "{'loss': 1.9167, 'learning_rate': 3.875034867503487e-06, 'epoch': 20.65}\n",
      "{'loss': 1.9059, 'learning_rate': 3.856476057647606e-06, 'epoch': 20.67}\n",
      "{'loss': 1.925, 'learning_rate': 3.837880055788006e-06, 'epoch': 20.69}\n",
      "{'loss': 1.9075, 'learning_rate': 3.819284053928406e-06, 'epoch': 20.71}\n",
      "{'loss': 1.8939, 'learning_rate': 3.8006880520688055e-06, 'epoch': 20.73}\n",
      "{'loss': 1.9233, 'learning_rate': 3.7821292422129248e-06, 'epoch': 20.75}\n",
      "{'loss': 1.8897, 'learning_rate': 3.763533240353324e-06, 'epoch': 20.77}\n",
      "{'loss': 1.9281, 'learning_rate': 3.744937238493724e-06, 'epoch': 20.79}\n",
      "{'loss': 1.9274, 'learning_rate': 3.726341236634124e-06, 'epoch': 20.82}\n",
      "{'loss': 1.9057, 'learning_rate': 3.7077452347745236e-06, 'epoch': 20.84}\n",
      "{'loss': 1.9068, 'learning_rate': 3.6891864249186425e-06, 'epoch': 20.86}\n",
      "{'loss': 1.9196, 'learning_rate': 3.6705904230590426e-06, 'epoch': 20.88}\n",
      "{'loss': 1.9039, 'learning_rate': 3.6519944211994423e-06, 'epoch': 20.9}\n",
      "{'loss': 1.9163, 'learning_rate': 3.6333984193398424e-06, 'epoch': 20.92}\n",
      "{'loss': 1.9245, 'learning_rate': 3.6148396094839613e-06, 'epoch': 20.94}\n",
      "{'loss': 1.9044, 'learning_rate': 3.5962436076243614e-06, 'epoch': 20.96}\n",
      "{'loss': 1.9071, 'learning_rate': 3.5776476057647607e-06, 'epoch': 20.98}\n",
      "{'loss': 1.9086, 'learning_rate': 3.559051603905161e-06, 'epoch': 21.0}\n",
      "{'loss': 1.9027, 'learning_rate': 3.5404556020455605e-06, 'epoch': 21.03}\n",
      "{'loss': 1.9114, 'learning_rate': 3.52189679218968e-06, 'epoch': 21.05}\n",
      "{'loss': 1.9005, 'learning_rate': 3.503300790330079e-06, 'epoch': 21.07}\n",
      "{'loss': 1.9118, 'learning_rate': 3.4847047884704792e-06, 'epoch': 21.09}\n",
      "{'loss': 1.9026, 'learning_rate': 3.466108786610879e-06, 'epoch': 21.11}\n",
      "{'loss': 1.9243, 'learning_rate': 3.447549976754998e-06, 'epoch': 21.13}\n",
      "{'loss': 1.9017, 'learning_rate': 3.4289539748953975e-06, 'epoch': 21.15}\n",
      "{'loss': 1.9163, 'learning_rate': 3.4103579730357976e-06, 'epoch': 21.17}\n",
      "{'loss': 1.9267, 'learning_rate': 3.3917619711761973e-06, 'epoch': 21.19}\n",
      "{'loss': 1.916, 'learning_rate': 3.3732031613203166e-06, 'epoch': 21.21}\n",
      "{'loss': 1.9049, 'learning_rate': 3.354607159460716e-06, 'epoch': 21.23}\n",
      "{'loss': 1.9033, 'learning_rate': 3.336011157601116e-06, 'epoch': 21.26}\n",
      "{'loss': 1.8944, 'learning_rate': 3.3174151557415157e-06, 'epoch': 21.28}\n",
      "{'loss': 1.9162, 'learning_rate': 3.298856345885635e-06, 'epoch': 21.3}\n",
      "{'loss': 1.9192, 'learning_rate': 3.2802603440260343e-06, 'epoch': 21.32}\n",
      "{'loss': 1.9109, 'learning_rate': 3.2616643421664344e-06, 'epoch': 21.34}\n",
      "{'loss': 1.9113, 'learning_rate': 3.2431055323105537e-06, 'epoch': 21.36}\n",
      "{'loss': 1.9117, 'learning_rate': 3.2245095304509534e-06, 'epoch': 21.38}\n",
      "{'loss': 1.9142, 'learning_rate': 3.2059135285913527e-06, 'epoch': 21.4}\n",
      "{'loss': 1.8988, 'learning_rate': 3.187317526731753e-06, 'epoch': 21.42}\n",
      "{'loss': 1.9146, 'learning_rate': 3.1687215248721525e-06, 'epoch': 21.44}\n",
      "{'loss': 1.91, 'learning_rate': 3.1501255230125527e-06, 'epoch': 21.46}\n",
      "{'loss': 1.9008, 'learning_rate': 3.1315295211529524e-06, 'epoch': 21.49}\n",
      "{'loss': 1.9327, 'learning_rate': 3.1129335192933525e-06, 'epoch': 21.51}\n",
      "{'loss': 1.9235, 'learning_rate': 3.094337517433752e-06, 'epoch': 21.53}\n",
      "{'loss': 1.9058, 'learning_rate': 3.075778707577871e-06, 'epoch': 21.55}\n",
      "{'loss': 1.921, 'learning_rate': 3.0571827057182708e-06, 'epoch': 21.57}\n",
      "{'loss': 1.9126, 'learning_rate': 3.038586703858671e-06, 'epoch': 21.59}\n",
      "{'loss': 1.9068, 'learning_rate': 3.01999070199907e-06, 'epoch': 21.61}\n",
      "{'loss': 1.9253, 'learning_rate': 3.0014318921431895e-06, 'epoch': 21.63}\n",
      "{'loss': 1.9039, 'learning_rate': 2.982835890283589e-06, 'epoch': 21.65}\n",
      "{'loss': 1.9176, 'learning_rate': 2.9642398884239893e-06, 'epoch': 21.67}\n",
      "{'loss': 1.9028, 'learning_rate': 2.945643886564389e-06, 'epoch': 21.69}\n",
      "{'loss': 1.9034, 'learning_rate': 2.927047884704789e-06, 'epoch': 21.72}\n",
      "{'loss': 1.9154, 'learning_rate': 2.9084890748489076e-06, 'epoch': 21.74}\n",
      "{'loss': 1.9132, 'learning_rate': 2.8898930729893077e-06, 'epoch': 21.76}\n",
      "{'loss': 1.9101, 'learning_rate': 2.8712970711297074e-06, 'epoch': 21.78}\n",
      "{'loss': 1.9058, 'learning_rate': 2.8527382612738263e-06, 'epoch': 21.8}\n",
      "{'loss': 1.8957, 'learning_rate': 2.834142259414226e-06, 'epoch': 21.82}\n",
      "{'loss': 1.9057, 'learning_rate': 2.815546257554626e-06, 'epoch': 21.84}\n",
      "{'loss': 1.9096, 'learning_rate': 2.796950255695026e-06, 'epoch': 21.86}\n",
      "{'loss': 1.9146, 'learning_rate': 2.778354253835426e-06, 'epoch': 21.88}\n",
      "{'loss': 1.9185, 'learning_rate': 2.7597582519758253e-06, 'epoch': 21.9}\n",
      "{'loss': 1.8918, 'learning_rate': 2.7411622501162254e-06, 'epoch': 21.92}\n",
      "{'loss': 1.9217, 'learning_rate': 2.722566248256625e-06, 'epoch': 21.95}\n",
      "{'loss': 1.8954, 'learning_rate': 2.703970246397025e-06, 'epoch': 21.97}\n",
      "{'loss': 1.9166, 'learning_rate': 2.685448628544863e-06, 'epoch': 21.99}\n",
      "{'loss': 1.9038, 'learning_rate': 2.666852626685263e-06, 'epoch': 22.01}\n",
      "{'loss': 1.9294, 'learning_rate': 2.6482566248256626e-06, 'epoch': 22.03}\n",
      "{'loss': 1.8989, 'learning_rate': 2.6296606229660628e-06, 'epoch': 22.05}\n",
      "{'loss': 1.8948, 'learning_rate': 2.611064621106462e-06, 'epoch': 22.07}\n",
      "{'loss': 1.894, 'learning_rate': 2.592468619246862e-06, 'epoch': 22.09}\n",
      "{'loss': 1.8967, 'learning_rate': 2.573872617387262e-06, 'epoch': 22.11}\n",
      "{'loss': 1.9357, 'learning_rate': 2.555313807531381e-06, 'epoch': 22.13}\n",
      "{'loss': 1.8991, 'learning_rate': 2.5367178056717805e-06, 'epoch': 22.15}\n",
      "{'loss': 1.9031, 'learning_rate': 2.5181218038121806e-06, 'epoch': 22.18}\n",
      "{'loss': 1.918, 'learning_rate': 2.4995258019525803e-06, 'epoch': 22.2}\n",
      "{'loss': 1.9278, 'learning_rate': 2.48092980009298e-06, 'epoch': 22.22}\n",
      "{'loss': 1.9084, 'learning_rate': 2.46233379823338e-06, 'epoch': 22.24}\n",
      "{'loss': 1.9087, 'learning_rate': 2.44373779637378e-06, 'epoch': 22.26}\n",
      "{'loss': 1.8879, 'learning_rate': 2.4251417945141796e-06, 'epoch': 22.28}\n",
      "{'loss': 1.8976, 'learning_rate': 2.4065457926545793e-06, 'epoch': 22.3}\n",
      "{'loss': 1.9063, 'learning_rate': 2.3879869827986985e-06, 'epoch': 22.32}\n",
      "{'loss': 1.9043, 'learning_rate': 2.3693909809390983e-06, 'epoch': 22.34}\n",
      "{'loss': 1.9128, 'learning_rate': 2.350794979079498e-06, 'epoch': 22.36}\n",
      "{'loss': 1.9028, 'learning_rate': 2.332198977219898e-06, 'epoch': 22.38}\n",
      "{'loss': 1.8984, 'learning_rate': 2.313640167364017e-06, 'epoch': 22.41}\n",
      "{'loss': 1.8986, 'learning_rate': 2.2950441655044167e-06, 'epoch': 22.43}\n",
      "{'loss': 1.9047, 'learning_rate': 2.2764481636448168e-06, 'epoch': 22.45}\n",
      "{'loss': 1.9154, 'learning_rate': 2.2578521617852165e-06, 'epoch': 22.47}\n",
      "{'loss': 1.8859, 'learning_rate': 2.2392933519293353e-06, 'epoch': 22.49}\n",
      "{'loss': 1.9132, 'learning_rate': 2.220697350069735e-06, 'epoch': 22.51}\n",
      "{'loss': 1.8976, 'learning_rate': 2.2021385402138543e-06, 'epoch': 22.53}\n",
      "{'loss': 1.8899, 'learning_rate': 2.183542538354254e-06, 'epoch': 22.55}\n",
      "{'loss': 1.9131, 'learning_rate': 2.1649465364946537e-06, 'epoch': 22.57}\n",
      "{'loss': 1.9027, 'learning_rate': 2.1463505346350535e-06, 'epoch': 22.59}\n",
      "{'loss': 1.9126, 'learning_rate': 2.1277545327754536e-06, 'epoch': 22.62}\n",
      "{'loss': 1.9019, 'learning_rate': 2.1091585309158533e-06, 'epoch': 22.64}\n",
      "{'loss': 1.9105, 'learning_rate': 2.090562529056253e-06, 'epoch': 22.66}\n",
      "{'loss': 1.9078, 'learning_rate': 2.071966527196653e-06, 'epoch': 22.68}\n",
      "{'loss': 1.92, 'learning_rate': 2.053407717340772e-06, 'epoch': 22.7}\n",
      "{'loss': 1.8931, 'learning_rate': 2.0348117154811717e-06, 'epoch': 22.72}\n",
      "{'loss': 1.9065, 'learning_rate': 2.016252905625291e-06, 'epoch': 22.74}\n",
      "{'loss': 1.9114, 'learning_rate': 1.9976569037656907e-06, 'epoch': 22.76}\n",
      "{'loss': 1.9178, 'learning_rate': 1.9790609019060904e-06, 'epoch': 22.78}\n",
      "{'loss': 1.9052, 'learning_rate': 1.96046490004649e-06, 'epoch': 22.8}\n",
      "{'loss': 1.9057, 'learning_rate': 1.94186889818689e-06, 'epoch': 22.82}\n",
      "{'loss': 1.906, 'learning_rate': 1.92327289632729e-06, 'epoch': 22.85}\n",
      "{'loss': 1.8929, 'learning_rate': 1.9046768944676897e-06, 'epoch': 22.87}\n",
      "{'loss': 1.8954, 'learning_rate': 1.8860808926080896e-06, 'epoch': 22.89}\n",
      "{'loss': 1.8895, 'learning_rate': 1.8675220827522084e-06, 'epoch': 22.91}\n",
      "{'loss': 1.8934, 'learning_rate': 1.8489260808926081e-06, 'epoch': 22.93}\n",
      "{'loss': 1.907, 'learning_rate': 1.830330079033008e-06, 'epoch': 22.95}\n",
      "{'loss': 1.8979, 'learning_rate': 1.8117712691771271e-06, 'epoch': 22.97}\n",
      "{'loss': 1.9031, 'learning_rate': 1.7931752673175268e-06, 'epoch': 22.99}\n",
      "{'loss': 1.8856, 'learning_rate': 1.7745792654579265e-06, 'epoch': 23.01}\n",
      "{'loss': 1.9053, 'learning_rate': 1.7559832635983265e-06, 'epoch': 23.03}\n",
      "{'loss': 1.8948, 'learning_rate': 1.7373872617387264e-06, 'epoch': 23.05}\n",
      "{'loss': 1.8945, 'learning_rate': 1.7187912598791263e-06, 'epoch': 23.08}\n",
      "{'loss': 1.8854, 'learning_rate': 1.700195258019526e-06, 'epoch': 23.1}\n",
      "{'loss': 1.8797, 'learning_rate': 1.6815992561599257e-06, 'epoch': 23.12}\n",
      "{'loss': 1.9052, 'learning_rate': 1.6630032543003254e-06, 'epoch': 23.14}\n",
      "{'loss': 1.9097, 'learning_rate': 1.6444444444444447e-06, 'epoch': 23.16}\n",
      "{'loss': 1.9001, 'learning_rate': 1.6258484425848444e-06, 'epoch': 23.18}\n",
      "{'loss': 1.8961, 'learning_rate': 1.6072524407252443e-06, 'epoch': 23.2}\n",
      "{'loss': 1.9053, 'learning_rate': 1.5886564388656438e-06, 'epoch': 23.22}\n",
      "{'loss': 1.9033, 'learning_rate': 1.5701348210134822e-06, 'epoch': 23.24}\n",
      "{'loss': 1.8823, 'learning_rate': 1.5515388191538822e-06, 'epoch': 23.26}\n",
      "{'loss': 1.8937, 'learning_rate': 1.5329428172942817e-06, 'epoch': 23.28}\n",
      "{'loss': 1.9085, 'learning_rate': 1.5143468154346816e-06, 'epoch': 23.31}\n",
      "{'loss': 1.9215, 'learning_rate': 1.4957508135750815e-06, 'epoch': 23.33}\n",
      "{'loss': 1.9033, 'learning_rate': 1.4771548117154812e-06, 'epoch': 23.35}\n",
      "{'loss': 1.8859, 'learning_rate': 1.4585588098558811e-06, 'epoch': 23.37}\n",
      "{'loss': 1.8947, 'learning_rate': 1.439962807996281e-06, 'epoch': 23.39}\n",
      "{'loss': 1.91, 'learning_rate': 1.4213668061366806e-06, 'epoch': 23.41}\n",
      "{'loss': 1.8887, 'learning_rate': 1.4028079962807998e-06, 'epoch': 23.43}\n",
      "{'loss': 1.9048, 'learning_rate': 1.3842119944211995e-06, 'epoch': 23.45}\n",
      "{'loss': 1.9067, 'learning_rate': 1.3656159925615995e-06, 'epoch': 23.47}\n",
      "{'loss': 1.9112, 'learning_rate': 1.3470199907019994e-06, 'epoch': 23.49}\n",
      "{'loss': 1.8732, 'learning_rate': 1.3284611808461182e-06, 'epoch': 23.51}\n",
      "{'loss': 1.9152, 'learning_rate': 1.309865178986518e-06, 'epoch': 23.54}\n",
      "{'loss': 1.8775, 'learning_rate': 1.2912691771269179e-06, 'epoch': 23.56}\n",
      "{'loss': 1.901, 'learning_rate': 1.2726731752673178e-06, 'epoch': 23.58}\n",
      "{'loss': 1.8832, 'learning_rate': 1.2541143654114366e-06, 'epoch': 23.6}\n",
      "{'loss': 1.9177, 'learning_rate': 1.2355183635518363e-06, 'epoch': 23.62}\n",
      "{'loss': 1.8986, 'learning_rate': 1.2169223616922363e-06, 'epoch': 23.64}\n",
      "{'loss': 1.9009, 'learning_rate': 1.1983263598326362e-06, 'epoch': 23.66}\n",
      "{'loss': 1.9143, 'learning_rate': 1.1797303579730359e-06, 'epoch': 23.68}\n",
      "{'loss': 1.9092, 'learning_rate': 1.161171548117155e-06, 'epoch': 23.7}\n",
      "{'loss': 1.8991, 'learning_rate': 1.1425755462575547e-06, 'epoch': 23.72}\n",
      "{'loss': 1.9007, 'learning_rate': 1.1239795443979546e-06, 'epoch': 23.74}\n",
      "{'loss': 1.8965, 'learning_rate': 1.1053835425383543e-06, 'epoch': 23.77}\n",
      "{'loss': 1.8881, 'learning_rate': 1.0868247326824733e-06, 'epoch': 23.79}\n",
      "{'loss': 1.8722, 'learning_rate': 1.0682287308228733e-06, 'epoch': 23.81}\n",
      "{'loss': 1.8808, 'learning_rate': 1.049632728963273e-06, 'epoch': 23.83}\n",
      "{'loss': 1.9016, 'learning_rate': 1.031036727103673e-06, 'epoch': 23.85}\n",
      "{'loss': 1.8895, 'learning_rate': 1.0124407252440726e-06, 'epoch': 23.87}\n",
      "{'loss': 1.9048, 'learning_rate': 9.938447233844723e-07, 'epoch': 23.89}\n",
      "{'loss': 1.9154, 'learning_rate': 9.752487215248722e-07, 'epoch': 23.91}\n",
      "{'loss': 1.8845, 'learning_rate': 9.566527196652722e-07, 'epoch': 23.93}\n",
      "{'loss': 1.8978, 'learning_rate': 9.380939098093911e-07, 'epoch': 23.95}\n",
      "{'loss': 1.8903, 'learning_rate': 9.194979079497909e-07, 'epoch': 23.97}\n",
      "{'loss': 1.9064, 'learning_rate': 9.009019060901906e-07, 'epoch': 24.0}\n",
      "{'loss': 1.9189, 'learning_rate': 8.823059042305905e-07, 'epoch': 24.02}\n",
      "{'loss': 1.8849, 'learning_rate': 8.637470943747095e-07, 'epoch': 24.04}\n",
      "{'loss': 1.8893, 'learning_rate': 8.451510925151093e-07, 'epoch': 24.06}\n",
      "{'loss': 1.8955, 'learning_rate': 8.265922826592283e-07, 'epoch': 24.08}\n",
      "{'loss': 1.8987, 'learning_rate': 8.079962807996282e-07, 'epoch': 24.1}\n",
      "{'loss': 1.9144, 'learning_rate': 7.894002789400279e-07, 'epoch': 24.12}\n",
      "{'loss': 1.8822, 'learning_rate': 7.708042770804277e-07, 'epoch': 24.14}\n",
      "{'loss': 1.8994, 'learning_rate': 7.522082752208277e-07, 'epoch': 24.16}\n",
      "{'loss': 1.9029, 'learning_rate': 7.336122733612274e-07, 'epoch': 24.18}\n",
      "{'loss': 1.8881, 'learning_rate': 7.150162715016272e-07, 'epoch': 24.21}\n",
      "{'loss': 1.8946, 'learning_rate': 6.96420269642027e-07, 'epoch': 24.23}\n",
      "{'loss': 1.9065, 'learning_rate': 6.778614597861461e-07, 'epoch': 24.25}\n",
      "{'loss': 1.9075, 'learning_rate': 6.592654579265459e-07, 'epoch': 24.27}\n",
      "{'loss': 1.8892, 'learning_rate': 6.406694560669456e-07, 'epoch': 24.29}\n",
      "{'loss': 1.8966, 'learning_rate': 6.220734542073455e-07, 'epoch': 24.31}\n",
      "{'loss': 1.8693, 'learning_rate': 6.034774523477452e-07, 'epoch': 24.33}\n",
      "{'loss': 1.8961, 'learning_rate': 5.849186424918643e-07, 'epoch': 24.35}\n",
      "{'loss': 1.9016, 'learning_rate': 5.663226406322641e-07, 'epoch': 24.37}\n",
      "{'loss': 1.898, 'learning_rate': 5.477638307763831e-07, 'epoch': 24.39}\n",
      "{'loss': 1.8959, 'learning_rate': 5.29167828916783e-07, 'epoch': 24.41}\n",
      "{'loss': 1.8911, 'learning_rate': 5.105718270571827e-07, 'epoch': 24.44}\n",
      "{'loss': 1.8942, 'learning_rate': 4.919758251975826e-07, 'epoch': 24.46}\n",
      "{'loss': 1.8914, 'learning_rate': 4.7337982333798236e-07, 'epoch': 24.48}\n",
      "{'loss': 1.893, 'learning_rate': 4.547838214783822e-07, 'epoch': 24.5}\n",
      "{'loss': 1.8832, 'learning_rate': 4.36187819618782e-07, 'epoch': 24.52}\n",
      "{'loss': 1.9042, 'learning_rate': 4.175918177591818e-07, 'epoch': 24.54}\n",
      "{'loss': 1.9049, 'learning_rate': 3.9903300790330087e-07, 'epoch': 24.56}\n",
      "{'loss': 1.9045, 'learning_rate': 3.8043700604370063e-07, 'epoch': 24.58}\n",
      "{'loss': 1.8986, 'learning_rate': 3.6187819618781963e-07, 'epoch': 24.6}\n",
      "{'loss': 1.9014, 'learning_rate': 3.432821943282195e-07, 'epoch': 24.62}\n",
      "{'loss': 1.9031, 'learning_rate': 3.2468619246861927e-07, 'epoch': 24.64}\n",
      "{'loss': 1.8865, 'learning_rate': 3.060901906090191e-07, 'epoch': 24.67}\n",
      "{'loss': 1.8855, 'learning_rate': 2.874941887494189e-07, 'epoch': 24.69}\n",
      "{'loss': 1.8832, 'learning_rate': 2.689353788935379e-07, 'epoch': 24.71}\n",
      "{'loss': 1.8809, 'learning_rate': 2.503393770339377e-07, 'epoch': 24.73}\n",
      "{'loss': 1.878, 'learning_rate': 2.3174337517433754e-07, 'epoch': 24.75}\n",
      "{'loss': 1.9074, 'learning_rate': 2.1314737331473735e-07, 'epoch': 24.77}\n",
      "{'loss': 1.8918, 'learning_rate': 1.9455137145513714e-07, 'epoch': 24.79}\n",
      "{'loss': 1.8969, 'learning_rate': 1.7595536959553696e-07, 'epoch': 24.81}\n",
      "{'loss': 1.8897, 'learning_rate': 1.573593677359368e-07, 'epoch': 24.83}\n",
      "{'loss': 1.8994, 'learning_rate': 1.387633658763366e-07, 'epoch': 24.85}\n",
      "{'loss': 1.9096, 'learning_rate': 1.2020455602045562e-07, 'epoch': 24.87}\n",
      "{'loss': 1.8863, 'learning_rate': 1.0160855416085541e-07, 'epoch': 24.9}\n",
      "{'loss': 1.8855, 'learning_rate': 8.304974430497444e-08, 'epoch': 24.92}\n",
      "{'loss': 1.8811, 'learning_rate': 6.445374244537424e-08, 'epoch': 24.94}\n",
      "{'loss': 1.8982, 'learning_rate': 4.585774058577406e-08, 'epoch': 24.96}\n",
      "{'loss': 1.893, 'learning_rate': 2.7261738726173875e-08, 'epoch': 24.98}\n",
      "{'loss': 1.8946, 'learning_rate': 8.665736866573688e-09, 'epoch': 25.0}\n",
      "{'train_runtime': 125096.3042, 'train_samples_per_second': 85.973, 'train_steps_per_second': 4.776, 'train_loss': 2.190191639562631, 'epoch': 25.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cff511e7a742b28fb9d94b91137472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6025 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 6.49\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [\"peraturan-dataset-final-fifth.txt\"]\n",
    "tokenizer_file = \"cahya/bert-base-indonesian-522M\"\n",
    "batch_size = 18\n",
    "model_checkpoint = \"cahya/bert-base-indonesian-522M\"\n",
    "model_name = \"wirawan-finetuned-peraturan-25\"\n",
    "\n",
    "run_finetune(data,tokenizer_file, batch_size, model_checkpoint, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/agus/.cache/huggingface/datasets/text/suffix_array-0bb18389d41e00ae/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3708aa6b52425795888a3e06b75a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 17750\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 4438\n",
      "    })\n",
      "})\n",
      "The max length for the tokenizer is: 1000000000000000019884624838656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a28e80719e8403d80957e50ae119e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/17750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160c556d993a4b5fb72e35cc2772b776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/4438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d601a503b33744c6b83ab0dce6f1d80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/17750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de9a7e2313e4216ac8596905577322d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/4438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_dataset DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 127554\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 30658\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5eebd1bb7d4ae0b62bc406d943d4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/177175 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.5344, 'learning_rate': 5.643977875606728e-07, 'epoch': 0.07}\n",
      "{'loss': 6.515, 'learning_rate': 1.1287955751213456e-06, 'epoch': 0.14}\n",
      "{'loss': 6.4878, 'learning_rate': 1.6931933626820184e-06, 'epoch': 0.21}\n",
      "{'loss': 6.4527, 'learning_rate': 2.257591150242691e-06, 'epoch': 0.28}\n",
      "{'loss': 6.4404, 'learning_rate': 2.821988937803364e-06, 'epoch': 0.35}\n",
      "{'loss': 6.4256, 'learning_rate': 3.386386725364037e-06, 'epoch': 0.42}\n",
      "{'loss': 6.4042, 'learning_rate': 3.950784512924709e-06, 'epoch': 0.49}\n",
      "{'loss': 6.3797, 'learning_rate': 4.515182300485382e-06, 'epoch': 0.56}\n",
      "{'loss': 6.3739, 'learning_rate': 5.079580088046055e-06, 'epoch': 0.63}\n",
      "{'loss': 6.3282, 'learning_rate': 5.643977875606728e-06, 'epoch': 0.71}\n",
      "{'loss': 6.327, 'learning_rate': 6.208375663167401e-06, 'epoch': 0.78}\n",
      "{'loss': 6.3279, 'learning_rate': 6.7716446551529525e-06, 'epoch': 0.85}\n",
      "{'loss': 6.2785, 'learning_rate': 7.336042442713625e-06, 'epoch': 0.92}\n",
      "{'loss': 6.2908, 'learning_rate': 7.900440230274298e-06, 'epoch': 0.99}\n",
      "{'loss': 6.2865, 'learning_rate': 8.464838017834971e-06, 'epoch': 1.06}\n",
      "{'loss': 6.2675, 'learning_rate': 9.029235805395642e-06, 'epoch': 1.13}\n",
      "{'loss': 6.2524, 'learning_rate': 9.593633592956317e-06, 'epoch': 1.2}\n",
      "{'loss': 6.2468, 'learning_rate': 1.0158031380516988e-05, 'epoch': 1.27}\n",
      "{'loss': 6.2301, 'learning_rate': 1.0722429168077661e-05, 'epoch': 1.34}\n",
      "{'loss': 6.2265, 'learning_rate': 1.1286826955638334e-05, 'epoch': 1.41}\n",
      "{'loss': 6.2041, 'learning_rate': 1.1850095947623885e-05, 'epoch': 1.48}\n",
      "{'loss': 6.1883, 'learning_rate': 1.241449373518456e-05, 'epoch': 1.55}\n",
      "{'loss': 6.1952, 'learning_rate': 1.2978891522745232e-05, 'epoch': 1.62}\n",
      "{'loss': 6.1871, 'learning_rate': 1.3543289310305905e-05, 'epoch': 1.69}\n",
      "{'loss': 6.1768, 'learning_rate': 1.4106558302291456e-05, 'epoch': 1.76}\n",
      "{'loss': 6.1532, 'learning_rate': 1.4670956089852129e-05, 'epoch': 1.83}\n",
      "{'loss': 6.1632, 'learning_rate': 1.5235353877412802e-05, 'epoch': 1.9}\n",
      "{'loss': 6.1379, 'learning_rate': 1.5799751664973475e-05, 'epoch': 1.98}\n",
      "{'loss': 6.143, 'learning_rate': 1.6363020656959025e-05, 'epoch': 2.05}\n",
      "{'loss': 6.1157, 'learning_rate': 1.6927418444519698e-05, 'epoch': 2.12}\n",
      "{'loss': 6.1317, 'learning_rate': 1.749181623208037e-05, 'epoch': 2.19}\n",
      "{'loss': 6.1285, 'learning_rate': 1.8056214019641044e-05, 'epoch': 2.26}\n",
      "{'loss': 6.1065, 'learning_rate': 1.8619483011626595e-05, 'epoch': 2.33}\n",
      "{'loss': 6.1086, 'learning_rate': 1.9183880799187268e-05, 'epoch': 2.4}\n",
      "{'loss': 6.0859, 'learning_rate': 1.974827858674794e-05, 'epoch': 2.47}\n",
      "{'loss': 6.0832, 'learning_rate': 1.9965257091253444e-05, 'epoch': 2.54}\n",
      "{'loss': 6.0785, 'learning_rate': 1.99026696852443e-05, 'epoch': 2.61}\n",
      "{'loss': 6.0723, 'learning_rate': 1.9840082279235156e-05, 'epoch': 2.68}\n",
      "{'loss': 6.0532, 'learning_rate': 1.9777369447562665e-05, 'epoch': 2.75}\n",
      "{'loss': 6.0588, 'learning_rate': 1.971465661589018e-05, 'epoch': 2.82}\n",
      "{'loss': 6.0339, 'learning_rate': 1.965194378421769e-05, 'epoch': 2.89}\n",
      "{'loss': 6.0397, 'learning_rate': 1.9589230952545203e-05, 'epoch': 2.96}\n",
      "{'loss': 6.0294, 'learning_rate': 1.9526518120872712e-05, 'epoch': 3.03}\n",
      "{'loss': 6.0143, 'learning_rate': 1.9463805289200225e-05, 'epoch': 3.1}\n",
      "{'loss': 6.0101, 'learning_rate': 1.9401092457527738e-05, 'epoch': 3.17}\n",
      "{'loss': 6.0062, 'learning_rate': 1.9338505051518592e-05, 'epoch': 3.25}\n",
      "{'loss': 5.9705, 'learning_rate': 1.9275792219846105e-05, 'epoch': 3.32}\n",
      "{'loss': 5.9794, 'learning_rate': 1.9213079388173617e-05, 'epoch': 3.39}\n",
      "{'loss': 5.9843, 'learning_rate': 1.9150366556501127e-05, 'epoch': 3.46}\n",
      "{'loss': 5.9592, 'learning_rate': 1.908765372482864e-05, 'epoch': 3.53}\n",
      "{'loss': 5.975, 'learning_rate': 1.9025066318819497e-05, 'epoch': 3.6}\n",
      "{'loss': 5.9557, 'learning_rate': 1.8962353487147006e-05, 'epoch': 3.67}\n",
      "{'loss': 5.9419, 'learning_rate': 1.889964065547452e-05, 'epoch': 3.74}\n",
      "{'loss': 5.9251, 'learning_rate': 1.8836927823802028e-05, 'epoch': 3.81}\n",
      "{'loss': 5.9317, 'learning_rate': 1.8774340417792886e-05, 'epoch': 3.88}\n",
      "{'loss': 5.9224, 'learning_rate': 1.87116275861204e-05, 'epoch': 3.95}\n",
      "{'loss': 5.9091, 'learning_rate': 1.8648914754447908e-05, 'epoch': 4.02}\n",
      "{'loss': 5.8687, 'learning_rate': 1.858620192277542e-05, 'epoch': 4.09}\n",
      "{'loss': 5.8171, 'learning_rate': 1.8523489091102933e-05, 'epoch': 4.16}\n",
      "{'loss': 5.7867, 'learning_rate': 1.8460901685093788e-05, 'epoch': 4.23}\n",
      "{'loss': 5.7813, 'learning_rate': 1.83981888534213e-05, 'epoch': 4.3}\n",
      "{'loss': 5.7652, 'learning_rate': 1.8335476021748813e-05, 'epoch': 4.37}\n",
      "{'loss': 5.7416, 'learning_rate': 1.8272763190076322e-05, 'epoch': 4.44}\n",
      "{'loss': 5.7232, 'learning_rate': 1.8210050358403835e-05, 'epoch': 4.52}\n",
      "{'loss': 5.6907, 'learning_rate': 1.8147337526731344e-05, 'epoch': 4.59}\n",
      "{'loss': 5.6676, 'learning_rate': 1.8084750120722202e-05, 'epoch': 4.66}\n",
      "{'loss': 5.6503, 'learning_rate': 1.8022037289049715e-05, 'epoch': 4.73}\n",
      "{'loss': 5.639, 'learning_rate': 1.7959324457377224e-05, 'epoch': 4.8}\n",
      "{'loss': 5.613, 'learning_rate': 1.7896611625704737e-05, 'epoch': 4.87}\n",
      "{'loss': 5.5801, 'learning_rate': 1.7834024219695594e-05, 'epoch': 4.94}\n",
      "{'loss': 5.5822, 'learning_rate': 1.7771311388023103e-05, 'epoch': 5.01}\n",
      "{'loss': 5.5448, 'learning_rate': 1.7708598556350616e-05, 'epoch': 5.08}\n",
      "{'loss': 5.5336, 'learning_rate': 1.7645885724678125e-05, 'epoch': 5.15}\n",
      "{'loss': 5.5146, 'learning_rate': 1.758317289300564e-05, 'epoch': 5.22}\n",
      "{'loss': 5.5216, 'learning_rate': 1.752046006133315e-05, 'epoch': 5.29}\n",
      "{'loss': 5.5032, 'learning_rate': 1.7457747229660664e-05, 'epoch': 5.36}\n",
      "{'loss': 5.489, 'learning_rate': 1.739515982365152e-05, 'epoch': 5.43}\n",
      "{'loss': 5.4609, 'learning_rate': 1.733244699197903e-05, 'epoch': 5.5}\n",
      "{'loss': 5.467, 'learning_rate': 1.7269734160306543e-05, 'epoch': 5.57}\n",
      "{'loss': 5.4442, 'learning_rate': 1.7207021328634052e-05, 'epoch': 5.64}\n",
      "{'loss': 5.4282, 'learning_rate': 1.7144308496961565e-05, 'epoch': 5.71}\n",
      "{'loss': 5.4191, 'learning_rate': 1.7081595665289078e-05, 'epoch': 5.79}\n",
      "{'loss': 5.4123, 'learning_rate': 1.7018882833616587e-05, 'epoch': 5.86}\n",
      "{'loss': 5.3909, 'learning_rate': 1.69561700019441e-05, 'epoch': 5.93}\n",
      "{'loss': 5.3874, 'learning_rate': 1.68937080215983e-05, 'epoch': 6.0}\n",
      "{'loss': 5.346, 'learning_rate': 1.6830995189925812e-05, 'epoch': 6.07}\n",
      "{'loss': 5.3401, 'learning_rate': 1.676828235825332e-05, 'epoch': 6.14}\n",
      "{'loss': 5.3428, 'learning_rate': 1.6705569526580837e-05, 'epoch': 6.21}\n",
      "{'loss': 5.3288, 'learning_rate': 1.6642856694908346e-05, 'epoch': 6.28}\n",
      "{'loss': 5.32, 'learning_rate': 1.658014386323586e-05, 'epoch': 6.35}\n",
      "{'loss': 5.3114, 'learning_rate': 1.651743103156337e-05, 'epoch': 6.42}\n",
      "{'loss': 5.3074, 'learning_rate': 1.645471819989088e-05, 'epoch': 6.49}\n",
      "{'loss': 5.3107, 'learning_rate': 1.6392005368218394e-05, 'epoch': 6.56}\n",
      "{'loss': 5.2798, 'learning_rate': 1.6329417962209248e-05, 'epoch': 6.63}\n",
      "{'loss': 5.2811, 'learning_rate': 1.6266830556200106e-05, 'epoch': 6.7}\n",
      "{'loss': 5.2642, 'learning_rate': 1.620411772452762e-05, 'epoch': 6.77}\n",
      "{'loss': 5.2564, 'learning_rate': 1.6141404892855128e-05, 'epoch': 6.84}\n",
      "{'loss': 5.2389, 'learning_rate': 1.607869206118264e-05, 'epoch': 6.91}\n",
      "{'loss': 5.2379, 'learning_rate': 1.6015979229510153e-05, 'epoch': 6.98}\n",
      "{'loss': 5.1954, 'learning_rate': 1.5953266397837662e-05, 'epoch': 7.06}\n",
      "{'loss': 5.1702, 'learning_rate': 1.5890553566165175e-05, 'epoch': 7.13}\n",
      "{'loss': 5.1651, 'learning_rate': 1.5827840734492684e-05, 'epoch': 7.2}\n",
      "{'loss': 5.1526, 'learning_rate': 1.5765127902820197e-05, 'epoch': 7.27}\n",
      "{'loss': 5.1294, 'learning_rate': 1.57026659224744e-05, 'epoch': 7.34}\n",
      "{'loss': 5.0974, 'learning_rate': 1.563995309080191e-05, 'epoch': 7.41}\n",
      "{'loss': 5.0896, 'learning_rate': 1.5577240259129422e-05, 'epoch': 7.48}\n",
      "{'loss': 5.0798, 'learning_rate': 1.5514527427456934e-05, 'epoch': 7.55}\n",
      "{'loss': 5.0574, 'learning_rate': 1.5451814595784444e-05, 'epoch': 7.62}\n",
      "{'loss': 5.027, 'learning_rate': 1.5389101764111956e-05, 'epoch': 7.69}\n",
      "{'loss': 5.0102, 'learning_rate': 1.532638893243947e-05, 'epoch': 7.76}\n",
      "{'loss': 4.9801, 'learning_rate': 1.526367610076698e-05, 'epoch': 7.83}\n",
      "{'loss': 4.9672, 'learning_rate': 1.5200963269094491e-05, 'epoch': 7.9}\n",
      "{'loss': 4.982, 'learning_rate': 1.5138375863085345e-05, 'epoch': 7.97}\n",
      "{'loss': 4.9439, 'learning_rate': 1.507566303141286e-05, 'epoch': 8.04}\n",
      "{'loss': 4.9484, 'learning_rate': 1.501295019974037e-05, 'epoch': 8.11}\n",
      "{'loss': 4.9303, 'learning_rate': 1.4950237368067882e-05, 'epoch': 8.18}\n",
      "{'loss': 4.8658, 'learning_rate': 1.4887524536395393e-05, 'epoch': 8.25}\n",
      "{'loss': 4.8945, 'learning_rate': 1.4824811704722905e-05, 'epoch': 8.33}\n",
      "{'loss': 4.8643, 'learning_rate': 1.4762098873050416e-05, 'epoch': 8.4}\n",
      "{'loss': 4.8514, 'learning_rate': 1.4699511467041272e-05, 'epoch': 8.47}\n",
      "{'loss': 4.8609, 'learning_rate': 1.4636798635368783e-05, 'epoch': 8.54}\n",
      "{'loss': 4.8356, 'learning_rate': 1.4574085803696296e-05, 'epoch': 8.61}\n",
      "{'loss': 4.8259, 'learning_rate': 1.4511372972023807e-05, 'epoch': 8.68}\n",
      "{'loss': 4.813, 'learning_rate': 1.4448785566014663e-05, 'epoch': 8.75}\n",
      "{'loss': 4.8102, 'learning_rate': 1.4386072734342176e-05, 'epoch': 8.82}\n",
      "{'loss': 4.7862, 'learning_rate': 1.4323359902669687e-05, 'epoch': 8.89}\n",
      "{'loss': 4.7803, 'learning_rate': 1.4260647070997198e-05, 'epoch': 8.96}\n",
      "{'loss': 4.7747, 'learning_rate': 1.4197934239324709e-05, 'epoch': 9.03}\n",
      "{'loss': 4.7644, 'learning_rate': 1.4135346833315566e-05, 'epoch': 9.1}\n",
      "{'loss': 4.7306, 'learning_rate': 1.4072634001643077e-05, 'epoch': 9.17}\n",
      "{'loss': 4.7059, 'learning_rate': 1.4009921169970588e-05, 'epoch': 9.24}\n",
      "{'loss': 4.7065, 'learning_rate': 1.39472083382981e-05, 'epoch': 9.31}\n",
      "{'loss': 4.6939, 'learning_rate': 1.3884495506625612e-05, 'epoch': 9.38}\n",
      "{'loss': 4.7167, 'learning_rate': 1.3821782674953123e-05, 'epoch': 9.45}\n",
      "{'loss': 4.6984, 'learning_rate': 1.3759069843280634e-05, 'epoch': 9.52}\n",
      "{'loss': 4.6779, 'learning_rate': 1.3696357011608145e-05, 'epoch': 9.6}\n",
      "{'loss': 4.6824, 'learning_rate': 1.3633769605599003e-05, 'epoch': 9.67}\n",
      "{'loss': 4.6705, 'learning_rate': 1.3571182199589859e-05, 'epoch': 9.74}\n",
      "{'loss': 4.6568, 'learning_rate': 1.3508469367917371e-05, 'epoch': 9.81}\n",
      "{'loss': 4.6441, 'learning_rate': 1.3445756536244882e-05, 'epoch': 9.88}\n",
      "{'loss': 4.6382, 'learning_rate': 1.3383043704572393e-05, 'epoch': 9.95}\n",
      "{'loss': 4.6474, 'learning_rate': 1.3320330872899904e-05, 'epoch': 10.02}\n",
      "{'loss': 4.6031, 'learning_rate': 1.3257618041227415e-05, 'epoch': 10.09}\n",
      "{'loss': 4.6243, 'learning_rate': 1.319490520955493e-05, 'epoch': 10.16}\n",
      "{'loss': 4.6064, 'learning_rate': 1.313219237788244e-05, 'epoch': 10.23}\n",
      "{'loss': 4.6088, 'learning_rate': 1.3069604971873295e-05, 'epoch': 10.3}\n",
      "{'loss': 4.584, 'learning_rate': 1.300689214020081e-05, 'epoch': 10.37}\n",
      "{'loss': 4.5697, 'learning_rate': 1.294417930852832e-05, 'epoch': 10.44}\n",
      "{'loss': 4.5969, 'learning_rate': 1.2881466476855831e-05, 'epoch': 10.51}\n",
      "{'loss': 4.5738, 'learning_rate': 1.2818753645183342e-05, 'epoch': 10.58}\n",
      "{'loss': 4.5465, 'learning_rate': 1.27561662391742e-05, 'epoch': 10.65}\n",
      "{'loss': 4.5681, 'learning_rate': 1.2693453407501711e-05, 'epoch': 10.72}\n",
      "{'loss': 4.5529, 'learning_rate': 1.2630740575829222e-05, 'epoch': 10.79}\n",
      "{'loss': 4.5445, 'learning_rate': 1.2568027744156733e-05, 'epoch': 10.86}\n",
      "{'loss': 4.54, 'learning_rate': 1.2505314912484246e-05, 'epoch': 10.94}\n",
      "{'loss': 4.5449, 'learning_rate': 1.2442727506475102e-05, 'epoch': 11.01}\n",
      "{'loss': 4.5382, 'learning_rate': 1.2380014674802613e-05, 'epoch': 11.08}\n",
      "{'loss': 4.5148, 'learning_rate': 1.2317301843130124e-05, 'epoch': 11.15}\n",
      "{'loss': 4.5013, 'learning_rate': 1.2254589011457636e-05, 'epoch': 11.22}\n",
      "{'loss': 4.5245, 'learning_rate': 1.2191876179785147e-05, 'epoch': 11.29}\n",
      "{'loss': 4.5043, 'learning_rate': 1.2129288773776002e-05, 'epoch': 11.36}\n",
      "{'loss': 4.4815, 'learning_rate': 1.2066575942103516e-05, 'epoch': 11.43}\n",
      "{'loss': 4.5021, 'learning_rate': 1.2003863110431027e-05, 'epoch': 11.5}\n",
      "{'loss': 4.4816, 'learning_rate': 1.1941150278758538e-05, 'epoch': 11.57}\n",
      "{'loss': 4.4795, 'learning_rate': 1.1878437447086049e-05, 'epoch': 11.64}\n",
      "{'loss': 4.4682, 'learning_rate': 1.1815850041076907e-05, 'epoch': 11.71}\n",
      "{'loss': 4.4698, 'learning_rate': 1.1753137209404418e-05, 'epoch': 11.78}\n",
      "{'loss': 4.4485, 'learning_rate': 1.1690424377731929e-05, 'epoch': 11.85}\n",
      "{'loss': 4.4709, 'learning_rate': 1.162771154605944e-05, 'epoch': 11.92}\n",
      "{'loss': 4.4513, 'learning_rate': 1.1564998714386952e-05, 'epoch': 11.99}\n",
      "{'loss': 4.4391, 'learning_rate': 1.1502285882714463e-05, 'epoch': 12.06}\n",
      "{'loss': 4.4469, 'learning_rate': 1.1439573051041974e-05, 'epoch': 12.13}\n",
      "{'loss': 4.4163, 'learning_rate': 1.1376985645032832e-05, 'epoch': 12.21}\n",
      "{'loss': 4.4478, 'learning_rate': 1.1314272813360343e-05, 'epoch': 12.28}\n",
      "{'loss': 4.4378, 'learning_rate': 1.1251559981687854e-05, 'epoch': 12.35}\n",
      "{'loss': 4.4147, 'learning_rate': 1.1188847150015365e-05, 'epoch': 12.42}\n",
      "{'loss': 4.4355, 'learning_rate': 1.1126134318342876e-05, 'epoch': 12.49}\n",
      "{'loss': 4.4162, 'learning_rate': 1.1063546912333733e-05, 'epoch': 12.56}\n",
      "{'loss': 4.4235, 'learning_rate': 1.1000834080661244e-05, 'epoch': 12.63}\n",
      "{'loss': 4.4285, 'learning_rate': 1.0938121248988755e-05, 'epoch': 12.7}\n",
      "{'loss': 4.3942, 'learning_rate': 1.0875408417316268e-05, 'epoch': 12.77}\n",
      "{'loss': 4.3975, 'learning_rate': 1.0812695585643779e-05, 'epoch': 12.84}\n",
      "{'loss': 4.388, 'learning_rate': 1.0750108179634635e-05, 'epoch': 12.91}\n",
      "{'loss': 4.4133, 'learning_rate': 1.0687395347962148e-05, 'epoch': 12.98}\n",
      "{'loss': 4.4118, 'learning_rate': 1.0624682516289659e-05, 'epoch': 13.05}\n",
      "{'loss': 4.3661, 'learning_rate': 1.056196968461717e-05, 'epoch': 13.12}\n",
      "{'loss': 4.366, 'learning_rate': 1.049925685294468e-05, 'epoch': 13.19}\n",
      "{'loss': 4.3936, 'learning_rate': 1.0436669446935538e-05, 'epoch': 13.26}\n",
      "{'loss': 4.3724, 'learning_rate': 1.037395661526305e-05, 'epoch': 13.33}\n",
      "{'loss': 4.3686, 'learning_rate': 1.031124378359056e-05, 'epoch': 13.4}\n",
      "{'loss': 4.3724, 'learning_rate': 1.0248530951918071e-05, 'epoch': 13.48}\n",
      "{'loss': 4.366, 'learning_rate': 1.0185818120245586e-05, 'epoch': 13.55}\n",
      "{'loss': 4.3527, 'learning_rate': 1.012323071423644e-05, 'epoch': 13.62}\n",
      "{'loss': 4.3562, 'learning_rate': 1.0060517882563951e-05, 'epoch': 13.69}\n",
      "{'loss': 4.3686, 'learning_rate': 9.997805050891464e-06, 'epoch': 13.76}\n",
      "{'loss': 4.3597, 'learning_rate': 9.935092219218975e-06, 'epoch': 13.83}\n",
      "{'loss': 4.3617, 'learning_rate': 9.87250481320983e-06, 'epoch': 13.9}\n",
      "{'loss': 4.3562, 'learning_rate': 9.809791981537343e-06, 'epoch': 13.97}\n",
      "{'loss': 4.3464, 'learning_rate': 9.747079149864854e-06, 'epoch': 14.04}\n",
      "{'loss': 4.3279, 'learning_rate': 9.684366318192367e-06, 'epoch': 14.11}\n",
      "{'loss': 4.366, 'learning_rate': 9.621778912183223e-06, 'epoch': 14.18}\n",
      "{'loss': 4.3573, 'learning_rate': 9.559066080510734e-06, 'epoch': 14.25}\n",
      "{'loss': 4.336, 'learning_rate': 9.496353248838247e-06, 'epoch': 14.32}\n",
      "{'loss': 4.3252, 'learning_rate': 9.433640417165758e-06, 'epoch': 14.39}\n",
      "{'loss': 4.3277, 'learning_rate': 9.370927585493269e-06, 'epoch': 14.46}\n",
      "{'loss': 4.32, 'learning_rate': 9.308340179484125e-06, 'epoch': 14.53}\n",
      "{'loss': 4.3092, 'learning_rate': 9.245627347811636e-06, 'epoch': 14.6}\n",
      "{'loss': 4.3166, 'learning_rate': 9.182914516139147e-06, 'epoch': 14.67}\n",
      "{'loss': 4.3065, 'learning_rate': 9.12020168446666e-06, 'epoch': 14.75}\n",
      "{'loss': 4.3201, 'learning_rate': 9.057614278457515e-06, 'epoch': 14.82}\n",
      "{'loss': 4.2963, 'learning_rate': 8.994901446785026e-06, 'epoch': 14.89}\n",
      "{'loss': 4.3124, 'learning_rate': 8.932188615112539e-06, 'epoch': 14.96}\n",
      "{'loss': 4.2947, 'learning_rate': 8.86947578344005e-06, 'epoch': 15.03}\n",
      "{'loss': 4.2775, 'learning_rate': 8.806762951767563e-06, 'epoch': 15.1}\n",
      "{'loss': 4.2991, 'learning_rate': 8.744175545758419e-06, 'epoch': 15.17}\n",
      "{'loss': 4.2847, 'learning_rate': 8.68146271408593e-06, 'epoch': 15.24}\n",
      "{'loss': 4.2987, 'learning_rate': 8.61874988241344e-06, 'epoch': 15.31}\n",
      "{'loss': 4.2821, 'learning_rate': 8.556037050740953e-06, 'epoch': 15.38}\n",
      "{'loss': 4.2928, 'learning_rate': 8.49344964473181e-06, 'epoch': 15.45}\n",
      "{'loss': 4.2914, 'learning_rate': 8.43073681305932e-06, 'epoch': 15.52}\n",
      "{'loss': 4.27, 'learning_rate': 8.368023981386833e-06, 'epoch': 15.59}\n",
      "{'loss': 4.2952, 'learning_rate': 8.305311149714344e-06, 'epoch': 15.66}\n",
      "{'loss': 4.2953, 'learning_rate': 8.2427237437052e-06, 'epoch': 15.73}\n",
      "{'loss': 4.2681, 'learning_rate': 8.180010912032713e-06, 'epoch': 15.8}\n",
      "{'loss': 4.2788, 'learning_rate': 8.117298080360224e-06, 'epoch': 15.87}\n",
      "{'loss': 4.271, 'learning_rate': 8.054585248687735e-06, 'epoch': 15.94}\n",
      "{'loss': 4.2886, 'learning_rate': 7.991997842678592e-06, 'epoch': 16.02}\n",
      "{'loss': 4.2657, 'learning_rate': 7.929285011006103e-06, 'epoch': 16.09}\n",
      "{'loss': 4.2691, 'learning_rate': 7.866572179333614e-06, 'epoch': 16.16}\n",
      "{'loss': 4.2591, 'learning_rate': 7.803859347661125e-06, 'epoch': 16.23}\n",
      "{'loss': 4.2619, 'learning_rate': 7.741146515988636e-06, 'epoch': 16.3}\n",
      "{'loss': 4.2654, 'learning_rate': 7.678433684316149e-06, 'epoch': 16.37}\n",
      "{'loss': 4.2501, 'learning_rate': 7.615846278307005e-06, 'epoch': 16.44}\n",
      "{'loss': 4.2624, 'learning_rate': 7.553133446634516e-06, 'epoch': 16.51}\n",
      "{'loss': 4.2577, 'learning_rate': 7.490420614962029e-06, 'epoch': 16.58}\n",
      "{'loss': 4.2601, 'learning_rate': 7.42770778328954e-06, 'epoch': 16.65}\n",
      "{'loss': 4.2414, 'learning_rate': 7.364994951617051e-06, 'epoch': 16.72}\n",
      "{'loss': 4.2522, 'learning_rate': 7.3024075456079066e-06, 'epoch': 16.79}\n",
      "{'loss': 4.2673, 'learning_rate': 7.239694713935419e-06, 'epoch': 16.86}\n",
      "{'loss': 4.2262, 'learning_rate': 7.17698188226293e-06, 'epoch': 16.93}\n",
      "{'loss': 4.2275, 'learning_rate': 7.114269050590442e-06, 'epoch': 17.0}\n",
      "{'loss': 4.2304, 'learning_rate': 7.051556218917953e-06, 'epoch': 17.07}\n",
      "{'loss': 4.246, 'learning_rate': 6.98896881290881e-06, 'epoch': 17.14}\n",
      "{'loss': 4.2355, 'learning_rate': 6.926255981236322e-06, 'epoch': 17.21}\n",
      "{'loss': 4.238, 'learning_rate': 6.863543149563833e-06, 'epoch': 17.29}\n",
      "{'loss': 4.2099, 'learning_rate': 6.8008303178913446e-06, 'epoch': 17.36}\n",
      "{'loss': 4.2371, 'learning_rate': 6.738242911882201e-06, 'epoch': 17.43}\n",
      "{'loss': 4.2186, 'learning_rate': 6.675530080209712e-06, 'epoch': 17.5}\n",
      "{'loss': 4.2307, 'learning_rate': 6.612817248537223e-06, 'epoch': 17.57}\n",
      "{'loss': 4.2127, 'learning_rate': 6.550104416864735e-06, 'epoch': 17.64}\n",
      "{'loss': 4.2058, 'learning_rate': 6.487391585192246e-06, 'epoch': 17.71}\n",
      "{'loss': 4.2166, 'learning_rate': 6.424678753519759e-06, 'epoch': 17.78}\n",
      "{'loss': 4.2118, 'learning_rate': 6.362091347510615e-06, 'epoch': 17.85}\n",
      "{'loss': 4.2326, 'learning_rate': 6.299378515838126e-06, 'epoch': 17.92}\n",
      "{'loss': 4.2117, 'learning_rate': 6.2366656841656385e-06, 'epoch': 17.99}\n",
      "{'loss': 4.1799, 'learning_rate': 6.1739528524931495e-06, 'epoch': 18.06}\n",
      "{'loss': 4.2155, 'learning_rate': 6.1113654464840055e-06, 'epoch': 18.13}\n",
      "{'loss': 4.1961, 'learning_rate': 6.048778040474862e-06, 'epoch': 18.2}\n",
      "{'loss': 4.1965, 'learning_rate': 5.986065208802374e-06, 'epoch': 18.27}\n",
      "{'loss': 4.2373, 'learning_rate': 5.923352377129885e-06, 'epoch': 18.34}\n",
      "{'loss': 4.2171, 'learning_rate': 5.860639545457396e-06, 'epoch': 18.41}\n",
      "{'loss': 4.1971, 'learning_rate': 5.797926713784908e-06, 'epoch': 18.48}\n",
      "{'loss': 4.1876, 'learning_rate': 5.735213882112419e-06, 'epoch': 18.56}\n",
      "{'loss': 4.1907, 'learning_rate': 5.672501050439932e-06, 'epoch': 18.63}\n",
      "{'loss': 4.2154, 'learning_rate': 5.609788218767443e-06, 'epoch': 18.7}\n",
      "{'loss': 4.1881, 'learning_rate': 5.547075387094954e-06, 'epoch': 18.77}\n",
      "{'loss': 4.1905, 'learning_rate': 5.4843625554224655e-06, 'epoch': 18.84}\n",
      "{'loss': 4.1807, 'learning_rate': 5.421775149413322e-06, 'epoch': 18.91}\n",
      "{'loss': 4.2138, 'learning_rate': 5.359062317740833e-06, 'epoch': 18.98}\n",
      "{'loss': 4.1985, 'learning_rate': 5.296349486068345e-06, 'epoch': 19.05}\n",
      "{'loss': 4.1817, 'learning_rate': 5.233636654395856e-06, 'epoch': 19.12}\n",
      "{'loss': 4.1998, 'learning_rate': 5.171049248386712e-06, 'epoch': 19.19}\n",
      "{'loss': 4.1997, 'learning_rate': 5.108336416714225e-06, 'epoch': 19.26}\n",
      "{'loss': 4.1864, 'learning_rate': 5.045623585041736e-06, 'epoch': 19.33}\n",
      "{'loss': 4.1735, 'learning_rate': 4.982910753369248e-06, 'epoch': 19.4}\n",
      "{'loss': 4.1953, 'learning_rate': 4.920197921696759e-06, 'epoch': 19.47}\n",
      "{'loss': 4.1765, 'learning_rate': 4.8576105156876154e-06, 'epoch': 19.54}\n",
      "{'loss': 4.1644, 'learning_rate': 4.794897684015126e-06, 'epoch': 19.61}\n",
      "{'loss': 4.1731, 'learning_rate': 4.732184852342638e-06, 'epoch': 19.68}\n",
      "{'loss': 4.1898, 'learning_rate': 4.66947202067015e-06, 'epoch': 19.75}\n",
      "{'loss': 4.1473, 'learning_rate': 4.606759188997661e-06, 'epoch': 19.83}\n",
      "{'loss': 4.1586, 'learning_rate': 4.544046357325173e-06, 'epoch': 19.9}\n",
      "{'loss': 4.1781, 'learning_rate': 4.481458951316029e-06, 'epoch': 19.97}\n",
      "{'loss': 4.169, 'learning_rate': 4.418746119643541e-06, 'epoch': 20.04}\n",
      "{'loss': 4.1862, 'learning_rate': 4.356033287971052e-06, 'epoch': 20.11}\n",
      "{'loss': 4.1815, 'learning_rate': 4.2933204562985636e-06, 'epoch': 20.18}\n",
      "{'loss': 4.1664, 'learning_rate': 4.23073305028942e-06, 'epoch': 20.25}\n",
      "{'loss': 4.1467, 'learning_rate': 4.168020218616931e-06, 'epoch': 20.32}\n",
      "{'loss': 4.1744, 'learning_rate': 4.105307386944443e-06, 'epoch': 20.39}\n",
      "{'loss': 4.1508, 'learning_rate': 4.042594555271955e-06, 'epoch': 20.46}\n",
      "{'loss': 4.1547, 'learning_rate': 3.979881723599466e-06, 'epoch': 20.53}\n",
      "{'loss': 4.1739, 'learning_rate': 3.917168891926977e-06, 'epoch': 20.6}\n",
      "{'loss': 4.1463, 'learning_rate': 3.854581485917834e-06, 'epoch': 20.67}\n",
      "{'loss': 4.1723, 'learning_rate': 3.7918686542453453e-06, 'epoch': 20.74}\n",
      "{'loss': 4.1684, 'learning_rate': 3.7291558225728567e-06, 'epoch': 20.81}\n",
      "{'loss': 4.1525, 'learning_rate': 3.6664429909003685e-06, 'epoch': 20.88}\n",
      "{'loss': 4.1375, 'learning_rate': 3.60373015922788e-06, 'epoch': 20.95}\n",
      "{'loss': 4.1403, 'learning_rate': 3.541017327555392e-06, 'epoch': 21.02}\n",
      "{'loss': 4.1419, 'learning_rate': 3.478429921546248e-06, 'epoch': 21.09}\n",
      "{'loss': 4.1483, 'learning_rate': 3.4157170898737596e-06, 'epoch': 21.17}\n",
      "{'loss': 4.1436, 'learning_rate': 3.3530042582012706e-06, 'epoch': 21.24}\n",
      "{'loss': 4.1703, 'learning_rate': 3.290291426528782e-06, 'epoch': 21.31}\n",
      "{'loss': 4.1373, 'learning_rate': 3.2277040205196384e-06, 'epoch': 21.38}\n",
      "{'loss': 4.1403, 'learning_rate': 3.1649911888471502e-06, 'epoch': 21.45}\n",
      "{'loss': 4.1291, 'learning_rate': 3.1022783571746617e-06, 'epoch': 21.52}\n",
      "{'loss': 4.1677, 'learning_rate': 3.0395655255021735e-06, 'epoch': 21.59}\n",
      "{'loss': 4.1208, 'learning_rate': 2.97697811949303e-06, 'epoch': 21.66}\n",
      "{'loss': 4.1386, 'learning_rate': 2.9142652878205413e-06, 'epoch': 21.73}\n",
      "{'loss': 4.141, 'learning_rate': 2.8515524561480527e-06, 'epoch': 21.8}\n",
      "{'loss': 4.1394, 'learning_rate': 2.7888396244755646e-06, 'epoch': 21.87}\n",
      "{'loss': 4.1556, 'learning_rate': 2.7261267928030756e-06, 'epoch': 21.94}\n",
      "{'loss': 4.1574, 'learning_rate': 2.663539386793932e-06, 'epoch': 22.01}\n",
      "{'loss': 4.1299, 'learning_rate': 2.6008265551214434e-06, 'epoch': 22.08}\n",
      "{'loss': 4.1412, 'learning_rate': 2.5381137234489552e-06, 'epoch': 22.15}\n",
      "{'loss': 4.1346, 'learning_rate': 2.4754008917764666e-06, 'epoch': 22.22}\n",
      "{'loss': 4.1256, 'learning_rate': 2.412813485767323e-06, 'epoch': 22.29}\n",
      "{'loss': 4.1447, 'learning_rate': 2.3501006540948344e-06, 'epoch': 22.36}\n",
      "{'loss': 4.1207, 'learning_rate': 2.2873878224223463e-06, 'epoch': 22.44}\n",
      "{'loss': 4.1574, 'learning_rate': 2.2246749907498573e-06, 'epoch': 22.51}\n",
      "{'loss': 4.1383, 'learning_rate': 2.1620875847407137e-06, 'epoch': 22.58}\n",
      "{'loss': 4.1203, 'learning_rate': 2.0993747530682255e-06, 'epoch': 22.65}\n",
      "{'loss': 4.1171, 'learning_rate': 2.036661921395737e-06, 'epoch': 22.72}\n",
      "{'loss': 4.1337, 'learning_rate': 1.9739490897232488e-06, 'epoch': 22.79}\n",
      "{'loss': 4.1431, 'learning_rate': 1.9112362580507598e-06, 'epoch': 22.86}\n",
      "{'loss': 4.1456, 'learning_rate': 1.8486488520416164e-06, 'epoch': 22.93}\n",
      "{'loss': 4.1237, 'learning_rate': 1.7859360203691278e-06, 'epoch': 23.0}\n",
      "{'loss': 4.1174, 'learning_rate': 1.7232231886966394e-06, 'epoch': 23.07}\n",
      "{'loss': 4.127, 'learning_rate': 1.660510357024151e-06, 'epoch': 23.14}\n",
      "{'loss': 4.1129, 'learning_rate': 1.5979229510150074e-06, 'epoch': 23.21}\n",
      "{'loss': 4.1311, 'learning_rate': 1.5352101193425186e-06, 'epoch': 23.28}\n",
      "{'loss': 4.1161, 'learning_rate': 1.4724972876700303e-06, 'epoch': 23.35}\n",
      "{'loss': 4.1058, 'learning_rate': 1.4097844559975419e-06, 'epoch': 23.42}\n",
      "{'loss': 4.1321, 'learning_rate': 1.3470716243250533e-06, 'epoch': 23.49}\n",
      "{'loss': 4.1485, 'learning_rate': 1.2844842183159097e-06, 'epoch': 23.56}\n",
      "{'loss': 4.0989, 'learning_rate': 1.2217713866434213e-06, 'epoch': 23.63}\n",
      "{'loss': 4.1108, 'learning_rate': 1.1590585549709327e-06, 'epoch': 23.71}\n",
      "{'loss': 4.1193, 'learning_rate': 1.0963457232984442e-06, 'epoch': 23.78}\n",
      "{'loss': 4.1289, 'learning_rate': 1.0337583172893006e-06, 'epoch': 23.85}\n",
      "{'loss': 4.1271, 'learning_rate': 9.711709112801572e-07, 'epoch': 23.92}\n",
      "{'loss': 4.1334, 'learning_rate': 9.084580796076687e-07, 'epoch': 23.99}\n",
      "{'loss': 4.1144, 'learning_rate': 8.457452479351801e-07, 'epoch': 24.06}\n",
      "{'loss': 4.0891, 'learning_rate': 7.830324162626916e-07, 'epoch': 24.13}\n",
      "{'loss': 4.1233, 'learning_rate': 7.20319584590203e-07, 'epoch': 24.2}\n",
      "{'loss': 4.1222, 'learning_rate': 6.576067529177145e-07, 'epoch': 24.27}\n",
      "{'loss': 4.1224, 'learning_rate': 5.94893921245226e-07, 'epoch': 24.34}\n",
      "{'loss': 4.12, 'learning_rate': 5.321810895727375e-07, 'epoch': 24.41}\n",
      "{'loss': 4.1087, 'learning_rate': 4.69468257900249e-07, 'epoch': 24.48}\n",
      "{'loss': 4.1346, 'learning_rate': 4.0688085189110547e-07, 'epoch': 24.55}\n",
      "{'loss': 4.1316, 'learning_rate': 3.44168020218617e-07, 'epoch': 24.62}\n",
      "{'loss': 4.1278, 'learning_rate': 2.8145518854612846e-07, 'epoch': 24.69}\n",
      "{'loss': 4.1337, 'learning_rate': 2.1874235687363993e-07, 'epoch': 24.76}\n",
      "{'loss': 4.1232, 'learning_rate': 1.5602952520115142e-07, 'epoch': 24.83}\n",
      "{'loss': 4.1133, 'learning_rate': 9.34421191920079e-08, 'epoch': 24.9}\n",
      "{'loss': 4.1051, 'learning_rate': 3.072928751951937e-08, 'epoch': 24.98}\n",
      "{'train_runtime': 38753.8753, 'train_samples_per_second': 82.285, 'train_steps_per_second': 4.572, 'train_loss': 4.790056192993664, 'epoch': 25.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3bad46892f42b0b66681c568574b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 62.34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = \"persuratan-dataset-final-fourth.txt\"\n",
    "tokenizer_file = \"/media/agus/DATA/DDALM/script/IndoGovBERT-final/vocab/peraturan/\"\n",
    "batch_size = 18\n",
    "model_checkpoint = \"../../script/IndoGovBERT-final/models/peraturan-final-25/\"\n",
    "model_name = \"peraturan-finetuned-persuratan-25\"\n",
    "\n",
    "run_finetune(data,tokenizer_file, batch_size, model_checkpoint, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/agus/.cache/huggingface/datasets/text/suffix_array-b1e8db2c7c338967/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000fd612877e4062b13e1964d5550638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/agus/.cache/huggingface/datasets/text/suffix_array-b1e8db2c7c338967/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-b5c9ef00b1ba87bb.arrow and /home/agus/.cache/huggingface/datasets/text/suffix_array-b1e8db2c7c338967/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-a735864a71d26cc3.arrow\n",
      "Loading cached processed dataset at /home/agus/.cache/huggingface/datasets/text/suffix_array-b1e8db2c7c338967/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-0d366a34d4272e3a_*_of_00028.arrow\n",
      "Loading cached processed dataset at /home/agus/.cache/huggingface/datasets/text/suffix_array-b1e8db2c7c338967/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-6489cf1e19a8ec00_*_of_00028.arrow\n",
      "Loading cached processed dataset at /home/agus/.cache/huggingface/datasets/text/suffix_array-b1e8db2c7c338967/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-14f03cdfedf06c93_*_of_00028.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 47783\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 11946\n",
      "    })\n",
      "})\n",
      "The max length for the tokenizer is: 1000000000000000019884624838656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/agus/.cache/huggingface/datasets/text/suffix_array-b1e8db2c7c338967/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-93eadb566dd7eadc_*_of_00028.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_dataset DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 400154\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 97735\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f880e318fb2f4bb78162706dd235f792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/555775 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.3803, 'learning_rate': 1.7992730936701573e-07, 'epoch': 0.02}\n",
      "{'loss': 6.3473, 'learning_rate': 3.5985461873403145e-07, 'epoch': 0.04}\n",
      "{'loss': 6.35, 'learning_rate': 5.397819281010472e-07, 'epoch': 0.07}\n",
      "{'loss': 6.323, 'learning_rate': 7.197092374680629e-07, 'epoch': 0.09}\n",
      "{'loss': 6.3279, 'learning_rate': 8.996365468350787e-07, 'epoch': 0.11}\n",
      "{'loss': 6.3154, 'learning_rate': 1.0795638562020944e-06, 'epoch': 0.13}\n",
      "{'loss': 6.3205, 'learning_rate': 1.2594911655691102e-06, 'epoch': 0.16}\n",
      "{'loss': 6.2958, 'learning_rate': 1.4394184749361258e-06, 'epoch': 0.18}\n",
      "{'loss': 6.2937, 'learning_rate': 1.6193457843031416e-06, 'epoch': 0.2}\n",
      "{'loss': 6.2876, 'learning_rate': 1.7992730936701574e-06, 'epoch': 0.22}\n",
      "{'loss': 6.2763, 'learning_rate': 1.9792004030371732e-06, 'epoch': 0.25}\n",
      "{'loss': 6.2674, 'learning_rate': 2.159127712404189e-06, 'epoch': 0.27}\n",
      "{'loss': 6.2492, 'learning_rate': 2.3386951671524703e-06, 'epoch': 0.29}\n",
      "{'loss': 6.2478, 'learning_rate': 2.5186224765194863e-06, 'epoch': 0.31}\n",
      "{'loss': 6.2399, 'learning_rate': 2.6985497858865023e-06, 'epoch': 0.34}\n",
      "{'loss': 6.2287, 'learning_rate': 2.878477095253518e-06, 'epoch': 0.36}\n",
      "{'loss': 6.2275, 'learning_rate': 3.0580445500017998e-06, 'epoch': 0.38}\n",
      "{'loss': 6.2128, 'learning_rate': 3.2379718593688153e-06, 'epoch': 0.4}\n",
      "{'loss': 6.2082, 'learning_rate': 3.417899168735831e-06, 'epoch': 0.43}\n",
      "{'loss': 6.212, 'learning_rate': 3.5978264781028465e-06, 'epoch': 0.45}\n",
      "{'loss': 6.2001, 'learning_rate': 3.7773939328511284e-06, 'epoch': 0.47}\n",
      "{'loss': 6.192, 'learning_rate': 3.957321242218144e-06, 'epoch': 0.49}\n",
      "{'loss': 6.1892, 'learning_rate': 4.1372485515851604e-06, 'epoch': 0.52}\n",
      "{'loss': 6.1756, 'learning_rate': 4.316816006333442e-06, 'epoch': 0.54}\n",
      "{'loss': 6.1625, 'learning_rate': 4.4967433157004575e-06, 'epoch': 0.56}\n",
      "{'loss': 6.1537, 'learning_rate': 4.676670625067473e-06, 'epoch': 0.58}\n",
      "{'loss': 6.1569, 'learning_rate': 4.856597934434489e-06, 'epoch': 0.61}\n",
      "{'loss': 6.1396, 'learning_rate': 5.036525243801504e-06, 'epoch': 0.63}\n",
      "{'loss': 6.1564, 'learning_rate': 5.216452553168521e-06, 'epoch': 0.65}\n",
      "{'loss': 6.1369, 'learning_rate': 5.396020007916802e-06, 'epoch': 0.67}\n",
      "{'loss': 6.1291, 'learning_rate': 5.575947317283818e-06, 'epoch': 0.7}\n",
      "{'loss': 6.1247, 'learning_rate': 5.755874626650833e-06, 'epoch': 0.72}\n",
      "{'loss': 6.1312, 'learning_rate': 5.93580193601785e-06, 'epoch': 0.74}\n",
      "{'loss': 6.1246, 'learning_rate': 6.1157292453848645e-06, 'epoch': 0.76}\n",
      "{'loss': 6.1222, 'learning_rate': 6.295656554751881e-06, 'epoch': 0.79}\n",
      "{'loss': 6.1106, 'learning_rate': 6.4755838641188965e-06, 'epoch': 0.81}\n",
      "{'loss': 6.1199, 'learning_rate': 6.655511173485912e-06, 'epoch': 0.83}\n",
      "{'loss': 6.1083, 'learning_rate': 6.835438482852928e-06, 'epoch': 0.85}\n",
      "{'loss': 6.1067, 'learning_rate': 7.015005937601209e-06, 'epoch': 0.88}\n",
      "{'loss': 6.0965, 'learning_rate': 7.194573392349491e-06, 'epoch': 0.9}\n",
      "{'loss': 6.0977, 'learning_rate': 7.374500701716507e-06, 'epoch': 0.92}\n",
      "{'loss': 6.0904, 'learning_rate': 7.5544280110835235e-06, 'epoch': 0.94}\n",
      "{'loss': 6.0934, 'learning_rate': 7.734355320450538e-06, 'epoch': 0.97}\n",
      "{'loss': 6.0718, 'learning_rate': 7.914282629817554e-06, 'epoch': 0.99}\n",
      "{'loss': 6.0752, 'learning_rate': 8.09420993918457e-06, 'epoch': 1.01}\n",
      "{'loss': 6.0655, 'learning_rate': 8.274137248551585e-06, 'epoch': 1.03}\n",
      "{'loss': 6.0555, 'learning_rate': 8.454064557918602e-06, 'epoch': 1.06}\n",
      "{'loss': 6.0588, 'learning_rate': 8.633632012666884e-06, 'epoch': 1.08}\n",
      "{'loss': 6.0635, 'learning_rate': 8.8135593220339e-06, 'epoch': 1.1}\n",
      "{'loss': 6.0562, 'learning_rate': 8.99312677678218e-06, 'epoch': 1.12}\n",
      "{'loss': 6.0507, 'learning_rate': 9.173054086149196e-06, 'epoch': 1.15}\n",
      "{'loss': 6.0487, 'learning_rate': 9.352981395516212e-06, 'epoch': 1.17}\n",
      "{'loss': 6.0339, 'learning_rate': 9.532908704883228e-06, 'epoch': 1.19}\n",
      "{'loss': 6.0377, 'learning_rate': 9.712836014250245e-06, 'epoch': 1.21}\n",
      "{'loss': 6.0397, 'learning_rate': 9.892763323617259e-06, 'epoch': 1.24}\n",
      "{'loss': 6.0274, 'learning_rate': 1.0072690632984274e-05, 'epoch': 1.26}\n",
      "{'loss': 6.0313, 'learning_rate': 1.025261794235129e-05, 'epoch': 1.28}\n",
      "{'loss': 6.027, 'learning_rate': 1.0432185397099573e-05, 'epoch': 1.3}\n",
      "{'loss': 6.0166, 'learning_rate': 1.0611752851847855e-05, 'epoch': 1.33}\n",
      "{'loss': 6.0151, 'learning_rate': 1.079168016121487e-05, 'epoch': 1.35}\n",
      "{'loss': 6.0192, 'learning_rate': 1.0971607470581886e-05, 'epoch': 1.37}\n",
      "{'loss': 6.0133, 'learning_rate': 1.1151534779948903e-05, 'epoch': 1.39}\n",
      "{'loss': 6.0188, 'learning_rate': 1.1331462089315917e-05, 'epoch': 1.42}\n",
      "{'loss': 6.0129, 'learning_rate': 1.1511389398682932e-05, 'epoch': 1.44}\n",
      "{'loss': 5.9926, 'learning_rate': 1.169131670804995e-05, 'epoch': 1.46}\n",
      "{'loss': 6.0073, 'learning_rate': 1.1870884162798231e-05, 'epoch': 1.48}\n",
      "{'loss': 5.9977, 'learning_rate': 1.2050811472165247e-05, 'epoch': 1.51}\n",
      "{'loss': 5.9984, 'learning_rate': 1.223073878153226e-05, 'epoch': 1.53}\n",
      "{'loss': 5.9782, 'learning_rate': 1.2410666090899276e-05, 'epoch': 1.55}\n",
      "{'loss': 5.9966, 'learning_rate': 1.2590593400266294e-05, 'epoch': 1.57}\n",
      "{'loss': 5.984, 'learning_rate': 1.277052070963331e-05, 'epoch': 1.6}\n",
      "{'loss': 5.9747, 'learning_rate': 1.2950448019000326e-05, 'epoch': 1.62}\n",
      "{'loss': 5.9823, 'learning_rate': 1.313037532836734e-05, 'epoch': 1.64}\n",
      "{'loss': 5.9772, 'learning_rate': 1.3309942783115622e-05, 'epoch': 1.66}\n",
      "{'loss': 5.9766, 'learning_rate': 1.3489870092482637e-05, 'epoch': 1.69}\n",
      "{'loss': 5.976, 'learning_rate': 1.3669797401849653e-05, 'epoch': 1.71}\n",
      "{'loss': 5.9694, 'learning_rate': 1.384972471121667e-05, 'epoch': 1.73}\n",
      "{'loss': 5.989, 'learning_rate': 1.4029292165964952e-05, 'epoch': 1.75}\n",
      "{'loss': 5.9671, 'learning_rate': 1.4209219475331967e-05, 'epoch': 1.78}\n",
      "{'loss': 5.9619, 'learning_rate': 1.4389146784698981e-05, 'epoch': 1.8}\n",
      "{'loss': 5.9679, 'learning_rate': 1.4569074094065999e-05, 'epoch': 1.82}\n",
      "{'loss': 5.9598, 'learning_rate': 1.474864154881428e-05, 'epoch': 1.84}\n",
      "{'loss': 5.9563, 'learning_rate': 1.4928568858181296e-05, 'epoch': 1.87}\n",
      "{'loss': 5.9595, 'learning_rate': 1.5108496167548313e-05, 'epoch': 1.89}\n",
      "{'loss': 5.9734, 'learning_rate': 1.528842347691533e-05, 'epoch': 1.91}\n",
      "{'loss': 5.962, 'learning_rate': 1.546799093166361e-05, 'epoch': 1.93}\n",
      "{'loss': 5.9525, 'learning_rate': 1.5647918241030624e-05, 'epoch': 1.96}\n",
      "{'loss': 5.9524, 'learning_rate': 1.582784555039764e-05, 'epoch': 1.98}\n",
      "{'loss': 5.9526, 'learning_rate': 1.6007772859764655e-05, 'epoch': 2.0}\n",
      "{'loss': 5.9519, 'learning_rate': 1.6187700169131674e-05, 'epoch': 2.02}\n",
      "{'loss': 5.9494, 'learning_rate': 1.6367267623879954e-05, 'epoch': 2.05}\n",
      "{'loss': 5.9453, 'learning_rate': 1.654719493324697e-05, 'epoch': 2.07}\n",
      "{'loss': 5.9444, 'learning_rate': 1.6727122242613985e-05, 'epoch': 2.09}\n",
      "{'loss': 5.9068, 'learning_rate': 1.6907049551981e-05, 'epoch': 2.11}\n",
      "{'loss': 5.9205, 'learning_rate': 1.7086617006729284e-05, 'epoch': 2.14}\n",
      "{'loss': 5.9369, 'learning_rate': 1.72665443160963e-05, 'epoch': 2.16}\n",
      "{'loss': 5.9112, 'learning_rate': 1.7446471625463315e-05, 'epoch': 2.18}\n",
      "{'loss': 5.9123, 'learning_rate': 1.762639893483033e-05, 'epoch': 2.2}\n",
      "{'loss': 5.9296, 'learning_rate': 1.7806326244197346e-05, 'epoch': 2.23}\n",
      "{'loss': 5.9206, 'learning_rate': 1.798625355356436e-05, 'epoch': 2.25}\n",
      "{'loss': 5.9298, 'learning_rate': 1.8166180862931377e-05, 'epoch': 2.27}\n",
      "{'loss': 5.9168, 'learning_rate': 1.8346108172298393e-05, 'epoch': 2.29}\n",
      "{'loss': 5.9197, 'learning_rate': 1.852603548166541e-05, 'epoch': 2.32}\n",
      "{'loss': 5.9222, 'learning_rate': 1.8705602936413688e-05, 'epoch': 2.34}\n",
      "{'loss': 5.9226, 'learning_rate': 1.8885530245780707e-05, 'epoch': 2.36}\n",
      "{'loss': 5.9121, 'learning_rate': 1.9065457555147723e-05, 'epoch': 2.38}\n",
      "{'loss': 5.918, 'learning_rate': 1.9245384864514738e-05, 'epoch': 2.41}\n",
      "{'loss': 5.9043, 'learning_rate': 1.9425312173881754e-05, 'epoch': 2.43}\n",
      "{'loss': 5.8984, 'learning_rate': 1.9604879628630037e-05, 'epoch': 2.45}\n",
      "{'loss': 5.9026, 'learning_rate': 1.978480693799705e-05, 'epoch': 2.47}\n",
      "{'loss': 5.9121, 'learning_rate': 1.9964734247364065e-05, 'epoch': 2.5}\n",
      "{'loss': 5.9107, 'learning_rate': 1.998392633302479e-05, 'epoch': 2.52}\n",
      "{'loss': 5.9019, 'learning_rate': 1.9963934209921293e-05, 'epoch': 2.54}\n",
      "{'loss': 5.8924, 'learning_rate': 1.9943942086817796e-05, 'epoch': 2.56}\n",
      "{'loss': 5.9014, 'learning_rate': 1.9923989947960505e-05, 'epoch': 2.59}\n",
      "{'loss': 5.8989, 'learning_rate': 1.9903997824857008e-05, 'epoch': 2.61}\n",
      "{'loss': 5.8978, 'learning_rate': 1.988400570175351e-05, 'epoch': 2.63}\n",
      "{'loss': 5.892, 'learning_rate': 1.9864013578650013e-05, 'epoch': 2.65}\n",
      "{'loss': 5.8887, 'learning_rate': 1.9844021455546515e-05, 'epoch': 2.68}\n",
      "{'loss': 5.9044, 'learning_rate': 1.9824069316689225e-05, 'epoch': 2.7}\n",
      "{'loss': 5.8801, 'learning_rate': 1.980407719358573e-05, 'epoch': 2.72}\n",
      "{'loss': 5.8937, 'learning_rate': 1.978408507048223e-05, 'epoch': 2.74}\n",
      "{'loss': 5.8887, 'learning_rate': 1.9764092947378736e-05, 'epoch': 2.77}\n",
      "{'loss': 5.8688, 'learning_rate': 1.9744140808521445e-05, 'epoch': 2.79}\n",
      "{'loss': 5.8926, 'learning_rate': 1.9724148685417947e-05, 'epoch': 2.81}\n",
      "{'loss': 5.8664, 'learning_rate': 1.970415656231445e-05, 'epoch': 2.83}\n",
      "{'loss': 5.8708, 'learning_rate': 1.9684164439210952e-05, 'epoch': 2.86}\n",
      "{'loss': 5.8803, 'learning_rate': 1.966421230035366e-05, 'epoch': 2.88}\n",
      "{'loss': 5.8681, 'learning_rate': 1.9644220177250164e-05, 'epoch': 2.9}\n",
      "{'loss': 5.8783, 'learning_rate': 1.9624228054146667e-05, 'epoch': 2.92}\n",
      "{'loss': 5.8666, 'learning_rate': 1.960423593104317e-05, 'epoch': 2.95}\n",
      "{'loss': 5.8645, 'learning_rate': 1.9584243807939672e-05, 'epoch': 2.97}\n",
      "{'loss': 5.8743, 'learning_rate': 1.956429166908238e-05, 'epoch': 2.99}\n",
      "{'loss': 5.8633, 'learning_rate': 1.9544299545978887e-05, 'epoch': 3.01}\n",
      "{'loss': 5.8646, 'learning_rate': 1.952430742287539e-05, 'epoch': 3.04}\n",
      "{'loss': 5.8529, 'learning_rate': 1.9504315299771892e-05, 'epoch': 3.06}\n",
      "{'loss': 5.8475, 'learning_rate': 1.9484323176668395e-05, 'epoch': 3.08}\n",
      "{'loss': 5.8456, 'learning_rate': 1.9464371037811104e-05, 'epoch': 3.1}\n",
      "{'loss': 5.8328, 'learning_rate': 1.9444378914707606e-05, 'epoch': 3.13}\n",
      "{'loss': 5.8594, 'learning_rate': 1.9424386791604112e-05, 'epoch': 3.15}\n",
      "{'loss': 5.8509, 'learning_rate': 1.940439466850061e-05, 'epoch': 3.17}\n",
      "{'loss': 5.8519, 'learning_rate': 1.938444252964332e-05, 'epoch': 3.19}\n",
      "{'loss': 5.833, 'learning_rate': 1.9364450406539827e-05, 'epoch': 3.22}\n",
      "{'loss': 5.8398, 'learning_rate': 1.9344458283436326e-05, 'epoch': 3.24}\n",
      "{'loss': 5.838, 'learning_rate': 1.9324466160332832e-05, 'epoch': 3.26}\n",
      "{'loss': 5.8391, 'learning_rate': 1.9304474037229334e-05, 'epoch': 3.28}\n",
      "{'loss': 5.8426, 'learning_rate': 1.9284521898372043e-05, 'epoch': 3.31}\n",
      "{'loss': 5.8362, 'learning_rate': 1.9264529775268546e-05, 'epoch': 3.33}\n",
      "{'loss': 5.83, 'learning_rate': 1.924453765216505e-05, 'epoch': 3.35}\n",
      "{'loss': 5.8457, 'learning_rate': 1.922454552906155e-05, 'epoch': 3.37}\n",
      "{'loss': 5.854, 'learning_rate': 1.9204553405958054e-05, 'epoch': 3.4}\n",
      "{'loss': 5.8396, 'learning_rate': 1.9184601267100763e-05, 'epoch': 3.42}\n",
      "{'loss': 5.8189, 'learning_rate': 1.9164609143997265e-05, 'epoch': 3.44}\n",
      "{'loss': 5.8442, 'learning_rate': 1.914461702089377e-05, 'epoch': 3.46}\n",
      "{'loss': 5.8365, 'learning_rate': 1.912462489779027e-05, 'epoch': 3.49}\n",
      "{'loss': 5.8285, 'learning_rate': 1.9104632774686777e-05, 'epoch': 3.51}\n",
      "{'loss': 5.8374, 'learning_rate': 1.9084640651583276e-05, 'epoch': 3.53}\n",
      "{'loss': 5.8388, 'learning_rate': 1.9064648528479782e-05, 'epoch': 3.55}\n",
      "{'loss': 5.8382, 'learning_rate': 1.9044656405376284e-05, 'epoch': 3.58}\n",
      "{'loss': 5.8334, 'learning_rate': 1.90247442507652e-05, 'epoch': 3.6}\n",
      "{'loss': 5.8209, 'learning_rate': 1.9004752127661702e-05, 'epoch': 3.62}\n",
      "{'loss': 5.8257, 'learning_rate': 1.8984760004558205e-05, 'epoch': 3.64}\n",
      "{'loss': 5.8302, 'learning_rate': 1.8964767881454708e-05, 'epoch': 3.67}\n",
      "{'loss': 5.8326, 'learning_rate': 1.894477575835121e-05, 'epoch': 3.69}\n",
      "{'loss': 5.8158, 'learning_rate': 1.8924823619493923e-05, 'epoch': 3.71}\n",
      "{'loss': 5.822, 'learning_rate': 1.8904831496390422e-05, 'epoch': 3.73}\n",
      "{'loss': 5.818, 'learning_rate': 1.8884839373286928e-05, 'epoch': 3.76}\n",
      "{'loss': 5.83, 'learning_rate': 1.886484725018343e-05, 'epoch': 3.78}\n",
      "{'loss': 5.8288, 'learning_rate': 1.8844855127079933e-05, 'epoch': 3.8}\n",
      "{'loss': 5.8059, 'learning_rate': 1.8824863003976436e-05, 'epoch': 3.82}\n",
      "{'loss': 5.8235, 'learning_rate': 1.8804870880872938e-05, 'epoch': 3.85}\n",
      "{'loss': 5.8088, 'learning_rate': 1.878487875776944e-05, 'epoch': 3.87}\n",
      "{'loss': 5.8061, 'learning_rate': 1.876492661891215e-05, 'epoch': 3.89}\n",
      "{'loss': 5.8052, 'learning_rate': 1.8744934495808652e-05, 'epoch': 3.91}\n",
      "{'loss': 5.8067, 'learning_rate': 1.872498235695136e-05, 'epoch': 3.94}\n",
      "{'loss': 5.7934, 'learning_rate': 1.8704990233847867e-05, 'epoch': 3.96}\n",
      "{'loss': 5.8041, 'learning_rate': 1.8684998110744367e-05, 'epoch': 3.98}\n",
      "{'loss': 5.8108, 'learning_rate': 1.8665005987640873e-05, 'epoch': 4.0}\n",
      "{'loss': 5.7958, 'learning_rate': 1.864505384878358e-05, 'epoch': 4.03}\n",
      "{'loss': 5.7921, 'learning_rate': 1.8625061725680084e-05, 'epoch': 4.05}\n",
      "{'loss': 5.7881, 'learning_rate': 1.8605069602576587e-05, 'epoch': 4.07}\n",
      "{'loss': 5.7938, 'learning_rate': 1.858507747947309e-05, 'epoch': 4.09}\n",
      "{'loss': 5.7963, 'learning_rate': 1.8565085356369592e-05, 'epoch': 4.12}\n",
      "{'loss': 5.7898, 'learning_rate': 1.85451332175123e-05, 'epoch': 4.14}\n",
      "{'loss': 5.8048, 'learning_rate': 1.8525141094408804e-05, 'epoch': 4.16}\n",
      "{'loss': 5.8035, 'learning_rate': 1.8505148971305306e-05, 'epoch': 4.18}\n",
      "{'loss': 5.8051, 'learning_rate': 1.8485156848201812e-05, 'epoch': 4.21}\n",
      "{'loss': 5.7981, 'learning_rate': 1.846516472509831e-05, 'epoch': 4.23}\n",
      "{'loss': 5.8006, 'learning_rate': 1.8445212586241024e-05, 'epoch': 4.25}\n",
      "{'loss': 5.7853, 'learning_rate': 1.8425220463137526e-05, 'epoch': 4.27}\n",
      "{'loss': 5.7904, 'learning_rate': 1.8405228340034026e-05, 'epoch': 4.3}\n",
      "{'loss': 5.7861, 'learning_rate': 1.838523621693053e-05, 'epoch': 4.32}\n",
      "{'loss': 5.7924, 'learning_rate': 1.836528407807324e-05, 'epoch': 4.34}\n",
      "{'loss': 5.7991, 'learning_rate': 1.8345291954969743e-05, 'epoch': 4.36}\n",
      "{'loss': 5.7934, 'learning_rate': 1.8325299831866246e-05, 'epoch': 4.39}\n",
      "{'loss': 5.78, 'learning_rate': 1.830530770876275e-05, 'epoch': 4.41}\n",
      "{'loss': 5.796, 'learning_rate': 1.828531558565925e-05, 'epoch': 4.43}\n",
      "{'loss': 5.7778, 'learning_rate': 1.8265323462555754e-05, 'epoch': 4.45}\n",
      "{'loss': 5.7877, 'learning_rate': 1.8245371323698463e-05, 'epoch': 4.48}\n",
      "{'loss': 5.7768, 'learning_rate': 1.822537920059497e-05, 'epoch': 4.5}\n",
      "{'loss': 5.7926, 'learning_rate': 1.820538707749147e-05, 'epoch': 4.52}\n",
      "{'loss': 5.7795, 'learning_rate': 1.818539495438797e-05, 'epoch': 4.54}\n",
      "{'loss': 5.7818, 'learning_rate': 1.8165402831284476e-05, 'epoch': 4.57}\n",
      "{'loss': 5.774, 'learning_rate': 1.8145450692427185e-05, 'epoch': 4.59}\n",
      "{'loss': 5.7717, 'learning_rate': 1.8125458569323688e-05, 'epoch': 4.61}\n",
      "{'loss': 5.7814, 'learning_rate': 1.810546644622019e-05, 'epoch': 4.63}\n",
      "{'loss': 5.767, 'learning_rate': 1.8085474323116693e-05, 'epoch': 4.66}\n",
      "{'loss': 5.7708, 'learning_rate': 1.8065522184259402e-05, 'epoch': 4.68}\n",
      "{'loss': 5.7811, 'learning_rate': 1.8045530061155908e-05, 'epoch': 4.7}\n",
      "{'loss': 5.7715, 'learning_rate': 1.8025537938052407e-05, 'epoch': 4.72}\n",
      "{'loss': 5.7813, 'learning_rate': 1.8005545814948913e-05, 'epoch': 4.75}\n",
      "{'loss': 5.7807, 'learning_rate': 1.7985593676091622e-05, 'epoch': 4.77}\n",
      "{'loss': 5.7707, 'learning_rate': 1.7965601552988125e-05, 'epoch': 4.79}\n",
      "{'loss': 5.7614, 'learning_rate': 1.7945609429884628e-05, 'epoch': 4.81}\n",
      "{'loss': 5.7688, 'learning_rate': 1.792561730678113e-05, 'epoch': 4.84}\n",
      "{'loss': 5.7557, 'learning_rate': 1.7905625183677633e-05, 'epoch': 4.86}\n",
      "{'loss': 5.7723, 'learning_rate': 1.7885633060574135e-05, 'epoch': 4.88}\n",
      "{'loss': 5.7717, 'learning_rate': 1.7865640937470638e-05, 'epoch': 4.9}\n",
      "{'loss': 5.7624, 'learning_rate': 1.784564881436714e-05, 'epoch': 4.93}\n",
      "{'loss': 5.7683, 'learning_rate': 1.7825736659756056e-05, 'epoch': 4.95}\n",
      "{'loss': 5.7689, 'learning_rate': 1.7805744536652562e-05, 'epoch': 4.97}\n",
      "{'loss': 5.761, 'learning_rate': 1.778575241354906e-05, 'epoch': 4.99}\n",
      "{'loss': 5.7497, 'learning_rate': 1.7765760290445567e-05, 'epoch': 5.02}\n",
      "{'loss': 5.7483, 'learning_rate': 1.7745768167342066e-05, 'epoch': 5.04}\n",
      "{'loss': 5.7598, 'learning_rate': 1.7725776044238572e-05, 'epoch': 5.06}\n",
      "{'loss': 5.7593, 'learning_rate': 1.770582390538128e-05, 'epoch': 5.08}\n",
      "{'loss': 5.7646, 'learning_rate': 1.7685831782277784e-05, 'epoch': 5.11}\n",
      "{'loss': 5.7574, 'learning_rate': 1.7665839659174287e-05, 'epoch': 5.13}\n",
      "{'loss': 5.7526, 'learning_rate': 1.764584753607079e-05, 'epoch': 5.15}\n",
      "{'loss': 5.7725, 'learning_rate': 1.7625855412967292e-05, 'epoch': 5.17}\n",
      "{'loss': 5.7471, 'learning_rate': 1.760590327411e-05, 'epoch': 5.2}\n",
      "{'loss': 5.7535, 'learning_rate': 1.7585911151006503e-05, 'epoch': 5.22}\n",
      "{'loss': 5.7537, 'learning_rate': 1.7565919027903006e-05, 'epoch': 5.24}\n",
      "{'loss': 5.7475, 'learning_rate': 1.7545926904799512e-05, 'epoch': 5.26}\n",
      "{'loss': 5.7407, 'learning_rate': 1.752593478169601e-05, 'epoch': 5.29}\n",
      "{'loss': 5.744, 'learning_rate': 1.7505942658592517e-05, 'epoch': 5.31}\n",
      "{'loss': 5.7426, 'learning_rate': 1.7485990519735226e-05, 'epoch': 5.33}\n",
      "{'loss': 5.7559, 'learning_rate': 1.746599839663173e-05, 'epoch': 5.35}\n",
      "{'loss': 5.7539, 'learning_rate': 1.744600627352823e-05, 'epoch': 5.38}\n",
      "{'loss': 5.7535, 'learning_rate': 1.7426014150424734e-05, 'epoch': 5.4}\n",
      "{'loss': 5.736, 'learning_rate': 1.7406022027321237e-05, 'epoch': 5.42}\n",
      "{'loss': 5.7482, 'learning_rate': 1.7386069888463946e-05, 'epoch': 5.44}\n",
      "{'loss': 5.7594, 'learning_rate': 1.7366077765360448e-05, 'epoch': 5.47}\n",
      "{'loss': 5.7303, 'learning_rate': 1.734608564225695e-05, 'epoch': 5.49}\n",
      "{'loss': 5.753, 'learning_rate': 1.7326093519153453e-05, 'epoch': 5.51}\n",
      "{'loss': 5.736, 'learning_rate': 1.7306141380296166e-05, 'epoch': 5.53}\n",
      "{'loss': 5.7558, 'learning_rate': 1.728614925719267e-05, 'epoch': 5.56}\n",
      "{'loss': 5.7533, 'learning_rate': 1.726615713408917e-05, 'epoch': 5.58}\n",
      "{'loss': 5.751, 'learning_rate': 1.7246165010985674e-05, 'epoch': 5.6}\n",
      "{'loss': 5.7453, 'learning_rate': 1.7226212872128383e-05, 'epoch': 5.62}\n",
      "{'loss': 5.7384, 'learning_rate': 1.7206220749024885e-05, 'epoch': 5.65}\n",
      "{'loss': 5.7497, 'learning_rate': 1.7186228625921388e-05, 'epoch': 5.67}\n",
      "{'loss': 5.7413, 'learning_rate': 1.716623650281789e-05, 'epoch': 5.69}\n",
      "{'loss': 5.7491, 'learning_rate': 1.7146244379714393e-05, 'epoch': 5.71}\n",
      "{'loss': 5.7374, 'learning_rate': 1.7126292240857102e-05, 'epoch': 5.74}\n",
      "{'loss': 5.7591, 'learning_rate': 1.7106300117753608e-05, 'epoch': 5.76}\n",
      "{'loss': 5.7403, 'learning_rate': 1.7086307994650107e-05, 'epoch': 5.78}\n",
      "{'loss': 5.7454, 'learning_rate': 1.7066315871546613e-05, 'epoch': 5.8}\n",
      "{'loss': 5.7443, 'learning_rate': 1.7046363732689322e-05, 'epoch': 5.83}\n",
      "{'loss': 5.7574, 'learning_rate': 1.7026371609585825e-05, 'epoch': 5.85}\n",
      "{'loss': 5.7547, 'learning_rate': 1.7006379486482328e-05, 'epoch': 5.87}\n",
      "{'loss': 5.7456, 'learning_rate': 1.698638736337883e-05, 'epoch': 5.89}\n",
      "{'loss': 5.7441, 'learning_rate': 1.696643522452154e-05, 'epoch': 5.92}\n",
      "{'loss': 5.7353, 'learning_rate': 1.6946443101418042e-05, 'epoch': 5.94}\n",
      "{'loss': 5.739, 'learning_rate': 1.6926450978314544e-05, 'epoch': 5.96}\n",
      "{'loss': 5.7363, 'learning_rate': 1.6906458855211047e-05, 'epoch': 5.98}\n",
      "{'loss': 5.7486, 'learning_rate': 1.6886466732107553e-05, 'epoch': 6.01}\n",
      "{'loss': 5.7321, 'learning_rate': 1.6866474609004052e-05, 'epoch': 6.03}\n",
      "{'loss': 5.7166, 'learning_rate': 1.6846482485900558e-05, 'epoch': 6.05}\n",
      "{'loss': 5.7387, 'learning_rate': 1.6826530347043267e-05, 'epoch': 6.07}\n",
      "{'loss': 5.7131, 'learning_rate': 1.680653822393977e-05, 'epoch': 6.1}\n",
      "{'loss': 5.7435, 'learning_rate': 1.6786546100836272e-05, 'epoch': 6.12}\n",
      "{'loss': 5.7343, 'learning_rate': 1.6766553977732775e-05, 'epoch': 6.14}\n",
      "{'loss': 5.7218, 'learning_rate': 1.6746561854629278e-05, 'epoch': 6.16}\n",
      "{'loss': 5.731, 'learning_rate': 1.672656973152578e-05, 'epoch': 6.19}\n",
      "{'loss': 5.7347, 'learning_rate': 1.6706577608422283e-05, 'epoch': 6.21}\n",
      "{'loss': 5.7177, 'learning_rate': 1.6686585485318785e-05, 'epoch': 6.23}\n",
      "{'loss': 5.7347, 'learning_rate': 1.6666673330707704e-05, 'epoch': 6.25}\n",
      "{'loss': 5.7079, 'learning_rate': 1.6646681207604203e-05, 'epoch': 6.28}\n",
      "{'loss': 5.7215, 'learning_rate': 1.662668908450071e-05, 'epoch': 6.3}\n",
      "{'loss': 5.7227, 'learning_rate': 1.6606696961397212e-05, 'epoch': 6.32}\n",
      "{'loss': 5.7086, 'learning_rate': 1.658674482253992e-05, 'epoch': 6.34}\n",
      "{'loss': 5.7183, 'learning_rate': 1.6566752699436424e-05, 'epoch': 6.36}\n",
      "{'loss': 5.7187, 'learning_rate': 1.6546760576332926e-05, 'epoch': 6.39}\n",
      "{'loss': 5.7398, 'learning_rate': 1.652676845322943e-05, 'epoch': 6.41}\n",
      "{'loss': 5.732, 'learning_rate': 1.650677633012593e-05, 'epoch': 6.43}\n",
      "{'loss': 5.7191, 'learning_rate': 1.6486824191268644e-05, 'epoch': 6.45}\n",
      "{'loss': 5.73, 'learning_rate': 1.6466832068165143e-05, 'epoch': 6.48}\n",
      "{'loss': 5.7148, 'learning_rate': 1.644683994506165e-05, 'epoch': 6.5}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = \"peraturan-dataset-final-fifth.txt\"\n",
    "tokenizer_file = \"/media/agus/DATA/DDALM/script/IndoGovBERT-final/vocab/persuratan/\"\n",
    "batch_size = 18\n",
    "model_checkpoint = \"../../script/IndoGovBERT-final/models/persuratan-final-25/\"\n",
    "model_name = \"persuratan-finetuned-peraturan-25\"\n",
    "\n",
    "run_finetune(data,tokenizer_file, batch_size, model_checkpoint, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/agus/.cache/huggingface/datasets/text/suffix_array-0bb18389d41e00ae/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87488cc1af847768215812f9170c5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 17750\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 4438\n",
      "    })\n",
      "})\n",
      "The max length for the tokenizer is: 1000000000000000019884624838656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38b790299c34625a612db36cd6db284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/17750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52be7deecf314ef98fbd9f0e7e3f49d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/4438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409c13c917af42089f741df1286a1323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/17750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a05e3464c524acda8ec6d891cf80775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/4438 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_dataset DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 147032\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 37197\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d053c137c3bb47939df5269e7b753b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_284199/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1243277142.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_284199/1243277142.py'</span>                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_284199/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3532233289.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">92</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run_finetune</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_284199/3532233289.py'</span>                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1645</span> in     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1642       </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1643          </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1644       </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1645 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1646          </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1647          </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1648          </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1938</span> in     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1935                </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_step_begin(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state,  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1936             </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937             </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.accelerator.accumulate(model):                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1938 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939             </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1940             </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941                </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2759</span> in     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2756          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss_mb.reduce_mean().detach().to(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.device)                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2757       </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2758       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_loss_context_manager():                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>2759 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_loss(model, inputs)                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2760       </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2761       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.n_gpu &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2762          </span>loss = loss.mean()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># mean() to average on multi-gpu parallel training</span>        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2784</span> in     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_loss</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2781          </span>labels = inputs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>)                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2782       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2783          </span>labels = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>2784 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>outputs = model(**inputs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2785       # Save past state if it exists</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2786       # TODO: this needs to be fixed and made cleaner later.</span>                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2787       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.past_index &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502       # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503       </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504       </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/accelerate/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">operations.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">553</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">550    </span>model_forward = ConvertOutputsToFp32(model_forward)                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">551    </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">552    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(*args, **kwargs):                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>553 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> model_forward(*args, **kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">554    </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">555    # To act like a decorator so that it can be popped when doing `extract_model_from_pa</span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">556    </span>forward.__wrapped__ = model_forward                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/accelerate/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">operations.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">541</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">538       </span>update_wrapper(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, model_forward)                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">539    </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">540    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs):                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>541 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> convert_to_fp32(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model_forward(*args, **kwargs))                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">542    </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">543    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getstate__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">544       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> pickle.PicklingError(                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/amp/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">autocast_mode.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">14</span> in    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_autocast</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11    </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@functools</span>.wraps(func)                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decorate_autocast</span>(*args, **kwargs):                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> autocast_instance:                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 14 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15    </span>decorate_autocast.__script_unsupported = <span style=\"color: #808000; text-decoration-color: #808000\">'@autocast() decorator is not supported in </span>   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 16    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> decorate_autocast                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 17 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_b</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1358</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1355       </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1356       </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1357       </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1358 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bert(                                                              <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1359          </span>input_ids,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1360          </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1361          </span>token_type_ids=token_type_ids,                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502       # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503       </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504       </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_b</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1020</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1017          </span>inputs_embeds=inputs_embeds,                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1018          </span>past_key_values_length=past_key_values_length,                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1019       </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1020 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>encoder_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.encoder(                                                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1021          </span>embedding_output,                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1022          </span>attention_mask=extended_attention_mask,                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1023          </span>head_mask=head_mask,                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502       # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503       </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504       </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_b</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">610</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 607                </span>encoder_attention_mask,                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 608             </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 609          </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 610 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">            </span>layer_outputs = layer_module(                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 611                </span>hidden_states,                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 612                </span>attention_mask,                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 613                </span>layer_head_mask,                                                      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502       # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503       </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504       </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_b</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">495</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 492    </span>) -&gt; Tuple[torch.Tensor]:                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 493       # decoder uni-directional self-attention cached key/values tuple is at positions</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 494       </span>self_attn_past_key_value = past_key_value[:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> past_key_value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 495 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>self_attention_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attention(                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 496          </span>hidden_states,                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 497          </span>attention_mask,                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 498          </span>head_mask,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502       # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503       </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504       </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_b</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">425</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 422       </span>past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 423       </span>output_attentions: Optional[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span>] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 424    </span>) -&gt; Tuple[torch.Tensor]:                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 425 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>self_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.self(                                                         <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 426          </span>hidden_states,                                                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 427          </span>attention_mask,                                                               <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 428          </span>head_mask,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498       </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500             </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">         </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502       # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503       </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504       </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_b</span> <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ert.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">353</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 350          </span>attention_scores = attention_scores + attention_mask                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 351       </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 352       # Normalize the attention scores to probabilities.</span>                                <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span> 353 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>attention_probs = nn.functional.softmax(attention_scores, dim=-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>)                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 354       </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 355       # This is actually dropping out entire tokens to attend to, which might</span>           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 356       # seem a bit unusual, but is taken from the original Transformer paper.</span>           <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1843</span> in      <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">softmax</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1840    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dim <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1841       </span>dim = _get_softmax_dim(<span style=\"color: #808000; text-decoration-color: #808000\">\"softmax\"</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.dim(), _stacklevel)                       <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1842    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> dtype <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1843 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">      </span>ret = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.softmax(dim)                                                          <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1844    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1845       </span>ret = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>.softmax(dim, dtype=dtype)                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1846    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> ret                                                                            <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">216.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.65</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.53</span> GiB \n",
       "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">229.25</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21.70</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \n",
       "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/tmp/ipykernel_284199/\u001b[0m\u001b[1;33m1243277142.py\u001b[0m:\u001b[94m6\u001b[0m in \u001b[92m<module>\u001b[0m                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_284199/1243277142.py'\u001b[0m                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/tmp/ipykernel_284199/\u001b[0m\u001b[1;33m3532233289.py\u001b[0m:\u001b[94m92\u001b[0m in \u001b[92mrun_finetune\u001b[0m                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_284199/3532233289.py'\u001b[0m                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1645\u001b[0m in     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mtrain\u001b[0m                                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1642 \u001b[0m\u001b[2m      \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1643 \u001b[0m\u001b[2m         \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1644 \u001b[0m\u001b[2m      \u001b[0m)                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1645 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1646 \u001b[0m\u001b[2m         \u001b[0margs=args,                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1647 \u001b[0m\u001b[2m         \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1648 \u001b[0m\u001b[2m         \u001b[0mtrial=trial,                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1938\u001b[0m in     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_inner_training_loop\u001b[0m                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1935 \u001b[0m\u001b[2m               \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_step_begin(args, \u001b[96mself\u001b[0m.state,  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1936 \u001b[0m\u001b[2m            \u001b[0m                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1937 \u001b[0m\u001b[2m            \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.accelerator.accumulate(model):                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1938 \u001b[2m               \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1939 \u001b[0m\u001b[2m            \u001b[0m                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1940 \u001b[0m\u001b[2m            \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1941 \u001b[0m\u001b[2m               \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2759\u001b[0m in     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mtraining_step\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2756 \u001b[0m\u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m loss_mb.reduce_mean().detach().to(\u001b[96mself\u001b[0m.args.device)                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2757 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2758 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.compute_loss_context_manager():                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m2759 \u001b[2m         \u001b[0mloss = \u001b[96mself\u001b[0m.compute_loss(model, inputs)                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2760 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2761 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.n_gpu > \u001b[94m1\u001b[0m:                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2762 \u001b[0m\u001b[2m         \u001b[0mloss = loss.mean()  \u001b[2m# mean() to average on multi-gpu parallel training\u001b[0m        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2784\u001b[0m in     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mcompute_loss\u001b[0m                                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2781 \u001b[0m\u001b[2m         \u001b[0mlabels = inputs.pop(\u001b[33m\"\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m\"\u001b[0m)                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2782 \u001b[0m\u001b[2m      \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2783 \u001b[0m\u001b[2m         \u001b[0mlabels = \u001b[94mNone\u001b[0m                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m2784 \u001b[2m      \u001b[0moutputs = model(**inputs)                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2785 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Save past state if it exists\u001b[0m                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2786 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# TODO: this needs to be fixed and made cleaner later.\u001b[0m                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2787 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.past_index >= \u001b[94m0\u001b[0m:                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1501 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m      \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/accelerate/utils/\u001b[0m\u001b[1;33moperations.py\u001b[0m:\u001b[94m553\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92mforward\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m550 \u001b[0m\u001b[2m   \u001b[0mmodel_forward = ConvertOutputsToFp32(model_forward)                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m551 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m552 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(*args, **kwargs):                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m553 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m model_forward(*args, **kwargs)                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m554 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m555 \u001b[0m\u001b[2m   \u001b[0m\u001b[2m# To act like a decorator so that it can be popped when doing `extract_model_from_pa\u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m556 \u001b[0m\u001b[2m   \u001b[0mforward.__wrapped__ = model_forward                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/accelerate/utils/\u001b[0m\u001b[1;33moperations.py\u001b[0m:\u001b[94m541\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m__call__\u001b[0m                                                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m538 \u001b[0m\u001b[2m      \u001b[0mupdate_wrapper(\u001b[96mself\u001b[0m, model_forward)                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m539 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m540 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, *args, **kwargs):                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m541 \u001b[2m      \u001b[0m\u001b[94mreturn\u001b[0m convert_to_fp32(\u001b[96mself\u001b[0m.model_forward(*args, **kwargs))                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m542 \u001b[0m\u001b[2m   \u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m543 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__getstate__\u001b[0m(\u001b[96mself\u001b[0m):                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m544 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mraise\u001b[0m pickle.PicklingError(                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/amp/\u001b[0m\u001b[1;33mautocast_mode.py\u001b[0m:\u001b[94m14\u001b[0m in    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92mdecorate_autocast\u001b[0m                                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 11 \u001b[0m\u001b[2m   \u001b[0m\u001b[1;95m@functools\u001b[0m.wraps(func)                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 12 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mdecorate_autocast\u001b[0m(*args, **kwargs):                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 13 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mwith\u001b[0m autocast_instance:                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 14 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 15 \u001b[0m\u001b[2m   \u001b[0mdecorate_autocast.__script_unsupported = \u001b[33m'\u001b[0m\u001b[33m@autocast() decorator is not supported in \u001b[0m   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 16 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m decorate_autocast                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 17 \u001b[0m                                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/\u001b[0m\u001b[1;33mmodeling_b\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mert.py\u001b[0m:\u001b[94m1358\u001b[0m in \u001b[92mforward\u001b[0m                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1355 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1356 \u001b[0m\u001b[2m      \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1357 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1358 \u001b[2m      \u001b[0moutputs = \u001b[96mself\u001b[0m.bert(                                                              \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1359 \u001b[0m\u001b[2m         \u001b[0minput_ids,                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1360 \u001b[0m\u001b[2m         \u001b[0mattention_mask=attention_mask,                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1361 \u001b[0m\u001b[2m         \u001b[0mtoken_type_ids=token_type_ids,                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1501 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m      \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/\u001b[0m\u001b[1;33mmodeling_b\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mert.py\u001b[0m:\u001b[94m1020\u001b[0m in \u001b[92mforward\u001b[0m                                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1017 \u001b[0m\u001b[2m         \u001b[0minputs_embeds=inputs_embeds,                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1018 \u001b[0m\u001b[2m         \u001b[0mpast_key_values_length=past_key_values_length,                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1019 \u001b[0m\u001b[2m      \u001b[0m)                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1020 \u001b[2m      \u001b[0mencoder_outputs = \u001b[96mself\u001b[0m.encoder(                                                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1021 \u001b[0m\u001b[2m         \u001b[0membedding_output,                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1022 \u001b[0m\u001b[2m         \u001b[0mattention_mask=extended_attention_mask,                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1023 \u001b[0m\u001b[2m         \u001b[0mhead_mask=head_mask,                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1501 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m      \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/\u001b[0m\u001b[1;33mmodeling_b\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mert.py\u001b[0m:\u001b[94m610\u001b[0m in \u001b[92mforward\u001b[0m                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 607 \u001b[0m\u001b[2m               \u001b[0mencoder_attention_mask,                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 608 \u001b[0m\u001b[2m            \u001b[0m)                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 609 \u001b[0m\u001b[2m         \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 610 \u001b[2m            \u001b[0mlayer_outputs = layer_module(                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 611 \u001b[0m\u001b[2m               \u001b[0mhidden_states,                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 612 \u001b[0m\u001b[2m               \u001b[0mattention_mask,                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 613 \u001b[0m\u001b[2m               \u001b[0mlayer_head_mask,                                                      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1501 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m      \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/\u001b[0m\u001b[1;33mmodeling_b\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mert.py\u001b[0m:\u001b[94m495\u001b[0m in \u001b[92mforward\u001b[0m                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 492 \u001b[0m\u001b[2m   \u001b[0m) -> Tuple[torch.Tensor]:                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 493 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# decoder uni-directional self-attention cached key/values tuple is at positions\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 494 \u001b[0m\u001b[2m      \u001b[0mself_attn_past_key_value = past_key_value[:\u001b[94m2\u001b[0m] \u001b[94mif\u001b[0m past_key_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 495 \u001b[2m      \u001b[0mself_attention_outputs = \u001b[96mself\u001b[0m.attention(                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 496 \u001b[0m\u001b[2m         \u001b[0mhidden_states,                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 497 \u001b[0m\u001b[2m         \u001b[0mattention_mask,                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 498 \u001b[0m\u001b[2m         \u001b[0mhead_mask,                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1501 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m      \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/\u001b[0m\u001b[1;33mmodeling_b\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mert.py\u001b[0m:\u001b[94m425\u001b[0m in \u001b[92mforward\u001b[0m                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 422 \u001b[0m\u001b[2m      \u001b[0mpast_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = \u001b[94mNone\u001b[0m,                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 423 \u001b[0m\u001b[2m      \u001b[0moutput_attentions: Optional[\u001b[96mbool\u001b[0m] = \u001b[94mFalse\u001b[0m,                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 424 \u001b[0m\u001b[2m   \u001b[0m) -> Tuple[torch.Tensor]:                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 425 \u001b[2m      \u001b[0mself_outputs = \u001b[96mself\u001b[0m.self(                                                         \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 426 \u001b[0m\u001b[2m         \u001b[0mhidden_states,                                                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 427 \u001b[0m\u001b[2m         \u001b[0mattention_mask,                                                               \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 428 \u001b[0m\u001b[2m         \u001b[0mhead_mask,                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92m_call_impl\u001b[0m                                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m      \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m            \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1501 \u001b[2m         \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m      \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m      \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/models/bert/\u001b[0m\u001b[1;33mmodeling_b\u001b[0m \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[1;33mert.py\u001b[0m:\u001b[94m353\u001b[0m in \u001b[92mforward\u001b[0m                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 350 \u001b[0m\u001b[2m         \u001b[0mattention_scores = attention_scores + attention_mask                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 351 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 352 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# Normalize the attention scores to probabilities.\u001b[0m                                \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m 353 \u001b[2m      \u001b[0mattention_probs = nn.functional.softmax(attention_scores, dim=-\u001b[94m1\u001b[0m)                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 354 \u001b[0m\u001b[2m      \u001b[0m                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 355 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# This is actually dropping out entire tokens to attend to, which might\u001b[0m           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m 356 \u001b[0m\u001b[2m      \u001b[0m\u001b[2m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m           \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[2;33m/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m1843\u001b[0m in      \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[92msoftmax\u001b[0m                                                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1840 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mif\u001b[0m dim \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1841 \u001b[0m\u001b[2m      \u001b[0mdim = _get_softmax_dim(\u001b[33m\"\u001b[0m\u001b[33msoftmax\u001b[0m\u001b[33m\"\u001b[0m, \u001b[96minput\u001b[0m.dim(), _stacklevel)                       \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1842 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mif\u001b[0m dtype \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                     \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1843 \u001b[2m      \u001b[0mret = \u001b[96minput\u001b[0m.softmax(dim)                                                          \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1844 \u001b[0m\u001b[2m   \u001b[0m\u001b[94melse\u001b[0m:                                                                                 \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1845 \u001b[0m\u001b[2m      \u001b[0mret = \u001b[96minput\u001b[0m.softmax(dim, dtype=dtype)                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m1846 \u001b[0m\u001b[2m   \u001b[0m\u001b[94mreturn\u001b[0m ret                                                                            \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m216.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m23.65\u001b[0m GiB total capacity; \u001b[1;36m21.53\u001b[0m GiB \n",
       "already allocated; \u001b[1;36m229.25\u001b[0m MiB free; \u001b[1;36m21.70\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \n",
       "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "data = \"persuratan-dataset-final-fourth.txt\"\n",
    "tokenizer_file = \"/media/agus/DATA/DDALM/script/IndoGovBERT-final/vocab/persuratan/\"\n",
    "batch_size = 18\n",
    "model_name = \"indobenchmark/indobert-base-p2\"\n",
    "\n",
    "run_finetune(data,tokenizer_file, batch_size, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset text (/home/agus/.cache/huggingface/datasets/text/suffix_array-d7f0f78939d37770/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61bfc07beae4c3db52073e6b7fabc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1632\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "})\n",
      "The max length for the tokenizer is: 1000000000000000019884624838656\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac0273683564862bd7f161b23736d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfdb5789c9a41b39fad9ee8f43e470e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98461fac3af2407082af8857a6cd52b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/1632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4b1afd082e493bbd03b4e0c23d386b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=28):   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_dataset DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 35490\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'labels'],\n",
      "        num_rows: 7001\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/media/agus/DATA/DDALM/venv_sdgs/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bae053c04eb4ebb93c7d1adbfd72480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36975 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 9.1524, 'learning_rate': 2.69875608436993e-06, 'epoch': 0.34}\n",
      "{'loss': 7.9448, 'learning_rate': 5.402920497566252e-06, 'epoch': 0.68}\n",
      "{'loss': 7.4467, 'learning_rate': 8.107084910762575e-06, 'epoch': 1.01}\n",
      "{'loss': 6.9616, 'learning_rate': 1.0811249323958897e-05, 'epoch': 1.35}\n",
      "{'loss': 6.3787, 'learning_rate': 1.351541373715522e-05, 'epoch': 1.69}\n",
      "{'loss': 5.6307, 'learning_rate': 1.6219578150351543e-05, 'epoch': 2.03}\n",
      "{'loss': 5.1842, 'learning_rate': 1.8923742563547864e-05, 'epoch': 2.37}\n",
      "{'loss': 4.9742, 'learning_rate': 1.9819094269315144e-05, 'epoch': 2.7}\n",
      "{'loss': 4.8128, 'learning_rate': 1.951858641103465e-05, 'epoch': 3.04}\n",
      "{'loss': 4.682, 'learning_rate': 1.9218078552754157e-05, 'epoch': 3.38}\n",
      "{'loss': 4.6125, 'learning_rate': 1.891757069447366e-05, 'epoch': 3.72}\n",
      "{'loss': 4.5158, 'learning_rate': 1.8617062836193166e-05, 'epoch': 4.06}\n",
      "{'loss': 4.4613, 'learning_rate': 1.8316554977912674e-05, 'epoch': 4.39}\n",
      "{'loss': 4.4027, 'learning_rate': 1.801604711963218e-05, 'epoch': 4.73}\n",
      "{'loss': 4.3572, 'learning_rate': 1.7715539261351687e-05, 'epoch': 5.07}\n",
      "{'loss': 4.3017, 'learning_rate': 1.7415031403071192e-05, 'epoch': 5.41}\n",
      "{'loss': 4.2696, 'learning_rate': 1.7114523544790697e-05, 'epoch': 5.75}\n",
      "{'loss': 4.2137, 'learning_rate': 1.6814015686510205e-05, 'epoch': 6.09}\n",
      "{'loss': 4.1756, 'learning_rate': 1.651350782822971e-05, 'epoch': 6.42}\n",
      "{'loss': 4.1486, 'learning_rate': 1.6212999969949215e-05, 'epoch': 6.76}\n",
      "{'loss': 4.1038, 'learning_rate': 1.591309312738528e-05, 'epoch': 7.1}\n",
      "{'loss': 4.0979, 'learning_rate': 1.561258526910479e-05, 'epoch': 7.44}\n",
      "{'loss': 4.0793, 'learning_rate': 1.5312077410824294e-05, 'epoch': 7.78}\n",
      "{'loss': 4.0499, 'learning_rate': 1.501217056826036e-05, 'epoch': 8.11}\n",
      "{'loss': 4.0228, 'learning_rate': 1.4711662709979868e-05, 'epoch': 8.45}\n",
      "{'loss': 4.0139, 'learning_rate': 1.4411154851699373e-05, 'epoch': 8.79}\n",
      "{'loss': 3.98, 'learning_rate': 1.411064699341888e-05, 'epoch': 9.13}\n",
      "{'loss': 3.9768, 'learning_rate': 1.3810139135138384e-05, 'epoch': 9.47}\n",
      "{'loss': 3.9559, 'learning_rate': 1.350963127685789e-05, 'epoch': 9.8}\n",
      "{'loss': 3.9242, 'learning_rate': 1.3209123418577397e-05, 'epoch': 10.14}\n",
      "{'loss': 3.9206, 'learning_rate': 1.2908615560296902e-05, 'epoch': 10.48}\n",
      "{'loss': 3.8926, 'learning_rate': 1.260870871773297e-05, 'epoch': 10.82}\n",
      "{'loss': 3.8989, 'learning_rate': 1.2308200859452475e-05, 'epoch': 11.16}\n",
      "{'loss': 3.8803, 'learning_rate': 1.2007693001171981e-05, 'epoch': 11.49}\n",
      "{'loss': 3.8669, 'learning_rate': 1.1707786158608048e-05, 'epoch': 11.83}\n",
      "{'loss': 3.8393, 'learning_rate': 1.1407278300327556e-05, 'epoch': 12.17}\n",
      "{'loss': 3.8325, 'learning_rate': 1.110677044204706e-05, 'epoch': 12.51}\n",
      "{'loss': 3.85, 'learning_rate': 1.0806262583766567e-05, 'epoch': 12.85}\n",
      "{'loss': 3.8486, 'learning_rate': 1.0505754725486072e-05, 'epoch': 13.18}\n",
      "{'loss': 3.8057, 'learning_rate': 1.0205246867205578e-05, 'epoch': 13.52}\n",
      "{'loss': 3.8065, 'learning_rate': 9.904739008925083e-06, 'epoch': 13.86}\n",
      "{'loss': 3.7863, 'learning_rate': 9.604231150644591e-06, 'epoch': 14.2}\n",
      "{'loss': 3.7885, 'learning_rate': 9.304324308080656e-06, 'epoch': 14.54}\n",
      "{'loss': 3.7745, 'learning_rate': 9.003816449800164e-06, 'epoch': 14.87}\n",
      "{'loss': 3.7754, 'learning_rate': 8.703308591519669e-06, 'epoch': 15.21}\n",
      "{'loss': 3.7684, 'learning_rate': 8.402800733239175e-06, 'epoch': 15.55}\n",
      "{'loss': 3.7349, 'learning_rate': 8.102893890675242e-06, 'epoch': 15.89}\n",
      "{'loss': 3.7578, 'learning_rate': 7.802386032394748e-06, 'epoch': 16.23}\n",
      "{'loss': 3.7473, 'learning_rate': 7.501878174114253e-06, 'epoch': 16.57}\n",
      "{'loss': 3.7409, 'learning_rate': 7.20137031583376e-06, 'epoch': 16.9}\n",
      "{'loss': 3.736, 'learning_rate': 6.9014634732698264e-06, 'epoch': 17.24}\n",
      "{'loss': 3.7225, 'learning_rate': 6.600955614989333e-06, 'epoch': 17.58}\n",
      "{'loss': 3.7176, 'learning_rate': 6.3004477567088385e-06, 'epoch': 17.92}\n",
      "{'loss': 3.7065, 'learning_rate': 5.999939898428344e-06, 'epoch': 18.26}\n",
      "{'loss': 3.7116, 'learning_rate': 5.700033055864411e-06, 'epoch': 18.59}\n",
      "{'loss': 3.7092, 'learning_rate': 5.399525197583917e-06, 'epoch': 18.93}\n",
      "{'loss': 3.6988, 'learning_rate': 5.099017339303423e-06, 'epoch': 19.27}\n",
      "{'loss': 3.6895, 'learning_rate': 4.798509481022929e-06, 'epoch': 19.61}\n",
      "{'loss': 3.7057, 'learning_rate': 4.498602638458996e-06, 'epoch': 19.95}\n",
      "{'loss': 3.6843, 'learning_rate': 4.198094780178502e-06, 'epoch': 20.28}\n",
      "{'loss': 3.693, 'learning_rate': 3.8975869218980074e-06, 'epoch': 20.62}\n",
      "{'loss': 3.6794, 'learning_rate': 3.597079063617514e-06, 'epoch': 20.96}\n",
      "{'loss': 3.6873, 'learning_rate': 3.2971722210535806e-06, 'epoch': 21.3}\n",
      "{'loss': 3.6708, 'learning_rate': 2.9966643627730867e-06, 'epoch': 21.64}\n",
      "{'loss': 3.6723, 'learning_rate': 2.6961565044925923e-06, 'epoch': 21.97}\n",
      "{'loss': 3.6701, 'learning_rate': 2.3962496619286595e-06, 'epoch': 22.31}\n",
      "{'loss': 3.6706, 'learning_rate': 2.0957418036481655e-06, 'epoch': 22.65}\n",
      "{'loss': 3.6598, 'learning_rate': 1.7952339453676716e-06, 'epoch': 22.99}\n",
      "{'loss': 3.6693, 'learning_rate': 1.4947260870871774e-06, 'epoch': 23.33}\n",
      "{'loss': 3.6583, 'learning_rate': 1.1942182288066835e-06, 'epoch': 23.66}\n",
      "{'loss': 3.6525, 'learning_rate': 8.937103705261893e-07, 'epoch': 24.0}\n",
      "{'loss': 3.6738, 'learning_rate': 5.932025122456952e-07, 'epoch': 24.34}\n",
      "{'loss': 3.646, 'learning_rate': 2.9269465396520124e-07, 'epoch': 24.68}\n",
      "{'train_runtime': 10287.0245, 'train_samples_per_second': 86.249, 'train_steps_per_second': 3.594, 'train_loss': 4.211079679312458, 'epoch': 25.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8f1f953925496c9b35322fec14cbb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 39.39\n"
     ]
    }
   ],
   "source": [
    "data = \"cofog-persuratan.txt\"\n",
    "tokenizer_file = \"/media/agus/DATA/DDALM/script/IndoGovBERT-final/vocab/persuratan/\"\n",
    "batch_size = 24\n",
    "model_name = \"indobenchmark/indobert-base-p2\"\n",
    "\n",
    "run_finetune(data,tokenizer_file, batch_size, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sdgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
