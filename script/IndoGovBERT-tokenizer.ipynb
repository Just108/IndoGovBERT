{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-01 08:15:16.371217: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-01 08:15:18.736987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import BertTokenizerFast, BertForMaskedLM, pipeline\n",
    "from transformers import BertConfig, AutoConfig\n",
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.cuda.device at 0x7fd601f86790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "torch.cuda.device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tokenizer(filenames, file_save, model_path):\n",
    "\n",
    "    # Initialize a tokenizer\n",
    "    tokenizer = BertWordPieceTokenizer()  # Bert\n",
    "    # Customize training\n",
    "\n",
    "    # Bert\n",
    "    tokenizer.train(files=filenames, \n",
    "                    vocab_size=50_000, min_frequency=2, special_tokens=[\n",
    "        \"[UNK]\",\n",
    "        \"[SEP]\",\n",
    "        \"[PAD]\",\n",
    "        \"[CLS]\",\n",
    "        \"[MASK]\",\n",
    "    ])\n",
    "    \n",
    "    tokenizer.save_model(file_save)\n",
    "    \n",
    "    max_length = 512\n",
    "    \n",
    "    with open(os.path.join(model_path, \"config.json\"), \"w\") as f:\n",
    "        tokenizer_cfg = {\n",
    "            \"do_lower_case\": True,\n",
    "            \"unk_token\": \"[UNK]\",\n",
    "            \"sep_token\": \"[SEP]\",\n",
    "            \"pad_token\": \"[PAD]\",\n",
    "            \"cls_token\": \"[CLS]\",\n",
    "            \"mask_token\": \"[MASK]\",\n",
    "            \"model_max_length\": max_length,\n",
    "            \"max_len\": max_length,\n",
    "        }\n",
    "        json.dump(tokenizer_cfg, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['/media/agus/DATA/DDALM/output/suffix_array/persuratan-dataset-final-fourth.txt']\n",
    "file_save = 'vocab/persuratan/'\n",
    "model_path = \"/media/agus/DATA/DDALM/script/IndoGovBERT-final/vocab/persuratan/\"\n",
    "build_tokenizer(filenames, file_save, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vocab/persuratan/vocab.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vocab/peraturan/vocab.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bert\n",
    "tokenizer.train(files=['/media/agus/DATA/DDALM/output/suffix_array/peraturan-dataset-final-fifth.txt'], \n",
    "                vocab_size=50_000, min_frequency=2, special_tokens=[\n",
    "    \"[UNK]\",\n",
    "    \"[SEP]\",\n",
    "    \"[PAD]\",\n",
    "    \"[CLS]\",\n",
    "    \"[MASK]\",\n",
    "])\n",
    "tokenizer.save_model('vocab/peraturan/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vocab/all_dataset/vocab.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bert\n",
    "tokenizer.train(files=['/media/agus/DATA/DDALM/output/suffix_array/peraturan-dataset-final-fifth.txt',\n",
    "                       '/media/agus/DATA/DDALM/output/suffix_array/persuratan-dataset-final-fourth.txt'], \n",
    "                vocab_size=50_000, min_frequency=2, special_tokens=[\n",
    "    \"[UNK]\",\n",
    "    \"[SEP]\",\n",
    "    \"[PAD]\",\n",
    "    \"[CLS]\",\n",
    "    \"[MASK]\",\n",
    "])\n",
    "tokenizer.save_model('vocab/all_dataset/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/media/agus/DATA/DDALM/script/IndoGovBERT-final/vocab/all_dataset/\"\n",
    "with open(os.path.join(model_path, \"config.json\"), \"w\") as f:\n",
    "  tokenizer_cfg = {\n",
    "      \"do_lower_case\": True,\n",
    "      \"unk_token\": \"[UNK]\",\n",
    "      \"sep_token\": \"[SEP]\",\n",
    "      \"pad_token\": \"[PAD]\",\n",
    "      \"cls_token\": \"[CLS]\",\n",
    "      \"mask_token\": \"[MASK]\",\n",
    "      \"model_max_length\": max_length,\n",
    "      \"max_len\": max_length,\n",
    "  }\n",
    "  json.dump(tokenizer_cfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/media/agus/DATA/DDALM/script/IndoGovBERT-final/vocab/peraturan/\"\n",
    "with open(os.path.join(model_path, \"config.json\"), \"w\") as f:\n",
    "  tokenizer_cfg = {\n",
    "      \"do_lower_case\": True,\n",
    "      \"unk_token\": \"[UNK]\",\n",
    "      \"sep_token\": \"[SEP]\",\n",
    "      \"pad_token\": \"[PAD]\",\n",
    "      \"cls_token\": \"[CLS]\",\n",
    "      \"mask_token\": \"[MASK]\",\n",
    "      \"model_max_length\": max_length,\n",
    "      \"max_len\": max_length,\n",
    "  }\n",
    "  json.dump(tokenizer_cfg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/media/agus/DATA/DDALM/script/IndoGovBERT-final/vocab/persuratan/\"\n",
    "with open(os.path.join(model_path, \"config.json\"), \"w\") as f:\n",
    "  tokenizer_cfg = {\n",
    "      \"do_lower_case\": True,\n",
    "      \"unk_token\": \"[UNK]\",\n",
    "      \"sep_token\": \"[SEP]\",\n",
    "      \"pad_token\": \"[PAD]\",\n",
    "      \"cls_token\": \"[CLS]\",\n",
    "      \"mask_token\": \"[MASK]\",\n",
    "      \"model_max_length\": max_length,\n",
    "      \"max_len\": max_length,\n",
    "  }\n",
    "  json.dump(tokenizer_cfg, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sdgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
