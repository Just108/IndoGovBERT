{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('bphn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new= df[[\"link\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all files from a website sequentially\n",
    "import requests\n",
    "from os import makedirs\n",
    "from os.path import basename\n",
    "from os.path import join\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urljoin\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed\n",
    "from concurrent.futures import wait\n",
    "from random import randint\n",
    "from time import sleep\n",
    " \n",
    "# load a file from a URL, returns content of downloaded file\n",
    "def download_url(urlpath):\n",
    "    # open a connection to the server\n",
    "    with urlopen(urlpath) as connection:\n",
    "        # read the contents of the url as bytes and return it\n",
    "        return connection.read()\n",
    "\n",
    "# save provided content to the local path\n",
    "def save_file(path, data):\n",
    "    # open the local file for writing\n",
    "    with open(path, 'wb') as file:\n",
    "        # write all provided data to the file\n",
    "        file.write(data)\n",
    "\n",
    "# download one file to a local directory\n",
    "def download_url_to_file(url, link, path):\n",
    "    sleep(randint(1,5))\n",
    "    r= requests.get(link,allow_redirects=True)\n",
    "    link = r.url\n",
    "    print('trying '+link)\n",
    "\n",
    "    if not exists(link):\n",
    "        print('URL Not exist')\n",
    "        return None\n",
    "    # skip bad urls or bad filenames\n",
    "    if link is None or link == '../':\n",
    "        print('Link is None')\n",
    "        return (link, None)\n",
    "    # check for no file extension\n",
    "    if not (link[-4] == '.' or link[-3] == '.' ):\n",
    "        print('Link is not a file')\n",
    "        return (link, None)\n",
    "    # convert relative link to absolute link\n",
    "    absurl = link #urljoin(url, link)\n",
    "    # download the content of the file\n",
    "\n",
    "    # get the filename\n",
    "    filename = basename(absurl)\n",
    "    # construct the output path\n",
    "    outpath = join(path, filename)\n",
    "\n",
    "    if(exists(outpath)):\n",
    "        print('File already exist')\n",
    "        return (link, None)\n",
    "    data = download_url(absurl)\n",
    "    \n",
    "    # save to file\n",
    "    save_file(outpath, data)\n",
    "    # return results\n",
    "    return (link, outpath)\n",
    "\n",
    "def exists(path):\n",
    "    r = requests.head(path)\n",
    "    return r.status_code == requests.codes.ok\n",
    "\n",
    "# download all files on the provided webpage to the provided path\n",
    "def download_all_files(mydf, path):\n",
    "    # create a local directory to save files\n",
    "    makedirs(path, exist_ok=True)\n",
    "    # parse html and retrieve all href urls listed\n",
    "    links = mydf.link\n",
    "    # report progress\n",
    "    print(f'Found {len(links)} links in data')\n",
    "    # create the pool of worker threads\n",
    "    with ThreadPoolExecutor(max_workers=5) as exe:\n",
    "        # dispatch all download tasks to worker threads\n",
    "\n",
    "        futures = [exe.submit(download_url_to_file, 'https://jdihn.go.id/', link, path) for link in links]\n",
    "        # report results as they become available\n",
    "        for future in as_completed(futures):\n",
    "            # retrieve result\n",
    "            link, outpath = future.result()\n",
    "            print(outpath)\n",
    "            # check for a link that was skipped\n",
    "            if outpath is None:\n",
    "                print(f'>skipped {link}')\n",
    "            else:\n",
    "                print(f'Downloaded {link} to {outpath}')\n",
    "        wait(futures)  \n",
    "        print('All tasks are done!')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'bphn'\n",
    "# download all files on df link\n",
    "download_all_files(df_new,PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a3b7509ebdcf43811d3d9c95007d85565ecdcb3e16afeda183944cc0455e408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
